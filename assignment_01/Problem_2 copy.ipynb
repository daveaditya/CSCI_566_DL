{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Incorporating CNNs\n",
    "\n",
    "* Learning Objective: In this problem, you will learn how to deeply understand how Convolutional Neural Networks work by implementing one.\n",
    "* Provided Code: We provide the skeletons of classes you need to complete. Forward checking and gradient checkings are provided for verifying your implementation as well.\n",
    "* TODOs: you will implement a Convolutional Layer and a MaxPooling Layer to improve on your classification results in part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from lib.mlp.fully_conn import *\n",
    "from lib.mlp.layer_utils import *\n",
    "from lib.mlp.datasets import *\n",
    "from lib.mlp.train import *\n",
    "from lib.cnn.layer_utils import *\n",
    "from lib.cnn.cnn_models import *\n",
    "from lib.grad_check import *\n",
    "from lib.optim import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data (SVHN)\n",
    "Run the following code block to download SVHN dataset and load in the properly splitted SVHN data. The script `get_datasets.sh` use `wget` to download the SVHN dataset. If you have a trouble with executing `get_datasets.sh`, you can manually download the dataset and extract files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-20 18:53:53--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
      "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
      "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 182040794 (174M) [text/plain]\n",
      "Saving to: ‘data/train_32x32.mat’\n",
      "\n",
      "train_32x32.mat     100%[===================>] 173.61M   657KB/s    in 5m 5s   \n",
      "\n",
      "2022-02-20 18:58:58 (583 KB/s) - ‘data/train_32x32.mat’ saved [182040794/182040794]\n",
      "\n",
      "--2022-02-20 18:58:58--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
      "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
      "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 64275384 (61M) [text/plain]\n",
      "Saving to: ‘data/test_32x32.mat’\n",
      "\n",
      "test_32x32.mat      100%[===================>]  61.30M   591KB/s    in 1m 51s  \n",
      "\n",
      "2022-02-20 19:00:49 (567 KB/s) - ‘data/test_32x32.mat’ saved [64275384/64275384]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./get_datasets.sh\n",
    "# !get_datasets.sh for windows users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: data_train Shape: (70000, 32, 32, 3)\n",
      "Name: labels_train Shape: (70000,)\n",
      "Name: data_val Shape: (3257, 32, 32, 3)\n",
      "Name: labels_val Shape: (3257,)\n",
      "Name: data_test Shape: (26032, 32, 32, 3)\n",
      "Name: labels_test Shape: (26032,)\n"
     ]
    }
   ],
   "source": [
    "data = SVHN_data()\n",
    "for k, v in data.items():\n",
    "    print (\"Name: {} Shape: {}\".format(k, v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "We will use convolutional neural networks to try to improve on the results from Problem 1. Convolutional layers make the assumption that local pixels are more important for prediction than far-away pixels. This allows us to form networks that are robust to small changes in positioning in images.\n",
    "\n",
    "### Convolutional Layer Output size calculation [2pts]\n",
    "\n",
    "As you have learned, two important parameters of a convolutional layer are its stride and padding. To warm up, we will need to calculate the output size of a convolutional layer given its stride and padding. To do this, open the `lib/cnn/layer_utils.py` file and fill out the TODO section in the `get_output_size` function in the ConvLayer2D class. \n",
    "\n",
    "Implement your function so that it returns the correct size as indicated by the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received [32, 16, 16, 16] and expected [32, 16, 16, 16]\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "input_image = np.zeros([32, 28, 28, 3]) # a stack of 32 28 by 28 rgb images\n",
    "\n",
    "in_channels = input_image.shape[-1] #must agree with the last dimension of the input image\n",
    "k_size = 4 \n",
    "n_filt = 16\n",
    "\n",
    "conv_layer = ConvLayer2D(in_channels, k_size, n_filt, stride=2, padding=3)\n",
    "output_size = conv_layer.get_output_size(input_image.shape) \n",
    "\n",
    "print(\"Received {} and expected [32, 16, 16, 16]\".format(output_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer Forward Pass [5pts]\n",
    "\n",
    "Now, we will implement the forward pass of a convolutional layer. Fill in the TODO block in the `forward` function of the ConvLayer2D class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received output shape: (1, 4, 4, 2), Expected output shape: (1, 4, 4, 2)\n",
      "Difference:  5.110565335399418e-08\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "# Test the convolutional forward function\n",
    "input_image = np.linspace(-0.1, 0.4, num=1*8*8*1).reshape([1, 8, 8, 1]) # a single 8 by 8 grayscale image\n",
    "in_channels, k_size, n_filt = 1, 5, 2\n",
    "\n",
    "weight_size = k_size*k_size*in_channels*n_filt\n",
    "bias_size = n_filt\n",
    "\n",
    "single_conv = ConvLayer2D(in_channels, k_size, n_filt, stride=1, padding=0, name=\"conv_test\")\n",
    "\n",
    "w = np.linspace(-0.2, 0.2, num=weight_size).reshape(k_size, k_size, in_channels, n_filt)\n",
    "b = np.linspace(-0.3, 0.3, num=bias_size)\n",
    "\n",
    "single_conv.params[single_conv.w_name] = w\n",
    "single_conv.params[single_conv.b_name] = b\n",
    "\n",
    "out = single_conv.forward(input_image)\n",
    "\n",
    "print(\"Received output shape: {}, Expected output shape: (1, 4, 4, 2)\".format(out.shape))\n",
    "\n",
    "correct_out = np.array([[\n",
    "   [[-0.03874312, 0.57000324],\n",
    "   [-0.03955296, 0.57081309],\n",
    "   [-0.04036281, 0.57162293],\n",
    "   [-0.04117266, 0.57243278]],\n",
    "\n",
    "  [[-0.0452219, 0.57648202],\n",
    "   [-0.04603175, 0.57729187],\n",
    "   [-0.04684159, 0.57810172],\n",
    "   [-0.04765144, 0.57891156]],\n",
    "\n",
    "  [[-0.05170068, 0.5829608 ],\n",
    "   [-0.05251053, 0.58377065],\n",
    "   [-0.05332038, 0.5845805 ],\n",
    "   [-0.05413022, 0.58539035]],\n",
    "\n",
    "  [[-0.05817946, 0.58943959],\n",
    "   [-0.05898931, 0.59024943],\n",
    "   [-0.05979916, 0.59105928],\n",
    "   [-0.06060901, 0.59186913]]]])\n",
    "\n",
    "\n",
    "# Compare your output with the above pre-computed ones. \n",
    "# The difference should not be larger than 1e-8\n",
    "print (\"Difference: \", rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Layer Backward [5pts]\n",
    "\n",
    "Now complete the backward pass of a convolutional layer. Fill in the TODO block in the `backward` function of the ConvLayer2D class. Check you results with this code and expect differences of less than 1e-6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimg Error:  2.6294797003498437e-07\n",
      "dw Error:  1.5793360396074264e-08\n",
      "db Error:  3.029810082779965e-10\n",
      "dimg Shape:  (15, 8, 8, 3) (15, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "# Test the conv backward function\n",
    "img = np.random.randn(15, 8, 8, 3)\n",
    "w = np.random.randn(4, 4, 3, 12)\n",
    "b = np.random.randn(12)\n",
    "dout = np.random.randn(15, 4, 4, 12)\n",
    "\n",
    "single_conv = ConvLayer2D(input_channels=3, kernel_size=4, number_filters=12, stride=2, padding=1, name=\"conv_test\")\n",
    "single_conv.params[single_conv.w_name] = w\n",
    "single_conv.params[single_conv.b_name] = b\n",
    "\n",
    "dimg_num = eval_numerical_gradient_array(lambda x: single_conv.forward(img), img, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: single_conv.forward(img), w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: single_conv.forward(img), b, dout)\n",
    "\n",
    "out = single_conv.forward(img)\n",
    "\n",
    "dimg = single_conv.backward(dout)\n",
    "dw = single_conv.grads[single_conv.w_name]\n",
    "db = single_conv.grads[single_conv.b_name]\n",
    "\n",
    "# The error should be around 1e-8\n",
    "print(\"dimg Error: \", rel_error(dimg_num, dimg))\n",
    "# The errors should be around 1e-8\n",
    "print(\"dw Error: \", rel_error(dw_num, dw))\n",
    "print(\"db Error: \", rel_error(db_num, db))\n",
    "# The shapes should be same\n",
    "print(\"dimg Shape: \", dimg.shape, img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max pooling Layer\n",
    "Now we will implement maxpooling layers, which can help to reduce the image size while preserving the overall structure of the image.\n",
    "\n",
    "### Forward Pass max pooling [5pts]\n",
    "Fill out the TODO block in the `forward` function of the MaxPoolingLayer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received output shape: (1, 3, 3, 1), Expected output shape: (1, 3, 3, 1)\n",
      "Difference:  1.8750000280978013e-08\n"
     ]
    }
   ],
   "source": [
    "# Test the convolutional forward function\n",
    "input_image = np.linspace(-0.1, 0.4, num=64).reshape([1, 8, 8, 1]) # a single 8 by 8 grayscale image\n",
    "\n",
    "maxpool= MaxPoolingLayer(pool_size=4, stride=2, name=\"maxpool_test\")\n",
    "out = maxpool.forward(input_image)\n",
    "\n",
    "print(\"Received output shape: {}, Expected output shape: (1, 3, 3, 1)\".format(out.shape))\n",
    "\n",
    "correct_out = np.array([[\n",
    "   [[0.11428571],\n",
    "   [0.13015873],\n",
    "   [0.14603175]],\n",
    "\n",
    "  [[0.24126984],\n",
    "   [0.25714286],\n",
    "   [0.27301587]],\n",
    "\n",
    "  [[0.36825397],\n",
    "   [0.38412698],\n",
    "   [0.4       ]]]])\n",
    "\n",
    "# Compare your output with the above pre-computed ones. \n",
    "# The difference should not be larger than 1e-8\n",
    "print (\"Difference: \", rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Pass Max pooling [5pts]\n",
    "Fill out the `backward` function in the MaxPoolingLayer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimg Error:  3.2772667075661996e-12\n",
      "dimg Shape:  (15, 8, 8, 3) (15, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "img = np.random.randn(15, 8, 8, 3)\n",
    "\n",
    "dout = np.random.randn(15, 3, 3, 3)\n",
    "\n",
    "maxpool= MaxPoolingLayer(pool_size=4, stride=2, name=\"maxpool_test\")\n",
    "\n",
    "dimg_num = eval_numerical_gradient_array(lambda x: maxpool.forward(img), img, dout)\n",
    "\n",
    "out = maxpool.forward(img)\n",
    "dimg = maxpool.backward(dout)\n",
    "\n",
    "# The error should be around 1e-8\n",
    "print(\"dimg Error: \", rel_error(dimg_num, dimg))\n",
    "# The shapes should be same\n",
    "print(\"dimg Shape: \", dimg.shape, img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a Small Fully Connected Network [3pts]\n",
    "Please find the `TestCNN` class in `lib/cnn/cnn_models.py`.\n",
    "Again you only need to complete few lines of code in the TODO block.\n",
    "Please design a Convolutional --> Maxpool --> flatten --> fc network where the shapes of parameters match the given shapes.\n",
    "Please insert the corresponding names you defined for each layer to param_name_w, and param_name_b respectively.\n",
    "Here you only modify the param_name part, the _w, and _b are automatically assigned during network setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ... \n",
      "Passed!\n",
      "Testing test-time forward pass ... \n",
      "Passed!\n",
      "Testing the loss ...\n",
      "Passed!\n",
      "Testing the gradients (error should be no larger than 1e-6) ...\n",
      "conv_b relative error: 3.95e-09\n",
      "conv_w relative error: 9.10e-10\n",
      "fc_b relative error: 9.76e-11\n",
      "fc_w relative error: 3.89e-07\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "model = TestCNN()\n",
    "loss_func = cross_entropy()\n",
    "\n",
    "B, H, W, iC = 4, 8, 8, 3 #batch, height, width, in_channels\n",
    "k = 3 #kernel size\n",
    "oC, Hi, O = 3, 27, 5 # out channels, Hidden Layer input, Output size\n",
    "std = 0.02\n",
    "x = np.random.randn(B,H,W,iC)\n",
    "y = np.random.randint(O, size=B)\n",
    "\n",
    "print (\"Testing initialization ... \")\n",
    "\n",
    "###################################################\n",
    "# TODO: param_name should be replaced accordingly  #\n",
    "###################################################\n",
    "w1_std = abs(model.net.get_params(\"conv_w\").std() - std)\n",
    "b1 = model.net.get_params(\"conv_b\").std()\n",
    "w2_std = abs(model.net.get_params(\"fc_w\").std() - std)\n",
    "b2 = model.net.get_params(\"fc_b\").std()\n",
    "###################################################\n",
    "#                END OF YOUR CODE                 #\n",
    "###################################################\n",
    "\n",
    "assert w1_std < std / 10, \"First layer weights do not seem right\"\n",
    "assert np.all(b1 == 0), \"First layer biases do not seem right\"\n",
    "assert w2_std < std / 10, \"Second layer weights do not seem right\"\n",
    "assert np.all(b2 == 0), \"Second layer biases do not seem right\"\n",
    "print (\"Passed!\")\n",
    "\n",
    "print (\"Testing test-time forward pass ... \")\n",
    "w1 = np.linspace(-0.7, 0.3, num=k*k*iC*oC).reshape(k,k,iC,oC)\n",
    "w2 = np.linspace(-0.2, 0.2, num=Hi*O).reshape(Hi, O)\n",
    "b1 = np.linspace(-0.6, 0.2, num=oC)\n",
    "b2 = np.linspace(-0.9, 0.1, num=O)\n",
    "\n",
    "###################################################\n",
    "# TODO: param_name should be replaced accordingly  #\n",
    "###################################################\n",
    "model.net.assign(\"conv_w\", w1)\n",
    "model.net.assign(\"conv_b\", b1)\n",
    "model.net.assign(\"fc_w\", w2)\n",
    "model.net.assign(\"fc_b\", b2)\n",
    "###################################################\n",
    "#                END OF YOUR CODE                 #\n",
    "###################################################\n",
    "\n",
    "feats = np.linspace(-5.5, 4.5, num=B*H*W*iC).reshape(B,H,W,iC)\n",
    "scores = model.forward(feats)\n",
    "correct_scores = np.asarray([[-13.85107294, -11.52845818,  -9.20584342,  -6.88322866,  -4.5606139 ],\n",
    " [-11.44514171, -10.21200524 , -8.97886878 , -7.74573231 , -6.51259584],\n",
    " [ -9.03921048,  -8.89555231 , -8.75189413 , -8.60823596,  -8.46457778],\n",
    " [ -6.63327925 , -7.57909937 , -8.52491949 , -9.4707396 , -10.41655972]])\n",
    "scores_diff = np.sum(np.abs(scores - correct_scores))\n",
    "assert scores_diff < 1e-6, \"Your implementation might be wrong!\"\n",
    "print (\"Passed!\")\n",
    "\n",
    "print (\"Testing the loss ...\",)\n",
    "y = np.asarray([0, 2, 1, 4])\n",
    "loss = loss_func.forward(scores, y)\n",
    "dLoss = loss_func.backward()\n",
    "correct_loss = 4.56046848799693\n",
    "assert abs(loss - correct_loss) < 1e-10, \"Your implementation might be wrong!\"\n",
    "print (\"Passed!\")\n",
    "\n",
    "print (\"Testing the gradients (error should be no larger than 1e-6) ...\")\n",
    "din = model.backward(dLoss)\n",
    "for layer in model.net.layers:\n",
    "    if not layer.params:\n",
    "        continue\n",
    "    for name in sorted(layer.grads):\n",
    "        f = lambda _: loss_func.forward(model.forward(feats), y)\n",
    "        grad_num = eval_numerical_gradient(f, layer.params[name], verbose=False)\n",
    "        print ('%s relative error: %.2e' % (name, rel_error(grad_num, layer.grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Network [25pts]\n",
    "In this section, we defined a `SmallConvolutionalNetwork` class for you to fill in the TODO block in `lib/cnn/cnn_models.py`.\n",
    "\n",
    "Here please design a network with at most two convolutions and two maxpooling layers (you may use less).\n",
    "You can adjust the parameters for any layer, and include layers other than those listed above that you have implemented.\n",
    "You are also free to select any optimizer you have implemented (with any learning rate).\n",
    "\n",
    "Try to find a combination that is able to achieve 88% validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange the data\n",
    "data_dict = {\n",
    "    \"data_train\": (data[\"data_train\"], data[\"labels_train\"]),\n",
    "    \"data_val\": (data[\"data_val\"], data[\"labels_val\"]),\n",
    "    \"data_test\": (data[\"data_test\"], data[\"labels_test\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (70000, 32, 32, 3)\n",
      "Flattened data input size: 3072\n",
      "Number of data classes: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape:\", data_dict[\"data_train\"][0].shape)\n",
    "print(\"Flattened data input size:\", np.prod(data[\"data_train\"].shape[1:]))\n",
    "print(\"Number of data classes:\", max(data['labels_train']) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 8736) loss: 2.3025692361523573\n",
      "(Iteration 11 / 8736) loss: 2.301131189418036\n",
      "(Iteration 21 / 8736) loss: 2.2860649533493866\n",
      "(Iteration 31 / 8736) loss: 2.221109912842827\n",
      "(Iteration 41 / 8736) loss: 2.2290769569746334\n",
      "(Iteration 51 / 8736) loss: 2.2400685617898093\n",
      "(Iteration 61 / 8736) loss: 2.250430597875989\n",
      "(Iteration 71 / 8736) loss: 2.26803713314918\n",
      "(Iteration 81 / 8736) loss: 2.2160666061241687\n",
      "(Iteration 91 / 8736) loss: 2.2303456716343573\n",
      "(Iteration 101 / 8736) loss: 2.2709827590455194\n",
      "(Iteration 111 / 8736) loss: 2.2109240321973247\n",
      "(Iteration 121 / 8736) loss: 2.2655509932366904\n",
      "(Iteration 131 / 8736) loss: 2.2314824013070957\n",
      "(Iteration 141 / 8736) loss: 2.2716762084580573\n",
      "(Iteration 151 / 8736) loss: 2.2783913251465964\n",
      "(Iteration 161 / 8736) loss: 2.2574348274719496\n",
      "(Iteration 171 / 8736) loss: 2.1968933477766615\n",
      "(Iteration 181 / 8736) loss: 2.231393260209555\n",
      "(Iteration 191 / 8736) loss: 2.2339351016620395\n",
      "(Iteration 201 / 8736) loss: 2.2872238981398887\n",
      "(Iteration 211 / 8736) loss: 2.286153518173568\n",
      "(Iteration 221 / 8736) loss: 2.228039485440323\n",
      "(Iteration 231 / 8736) loss: 2.2344668687944385\n",
      "(Iteration 241 / 8736) loss: 2.2223279250917987\n",
      "(Iteration 251 / 8736) loss: 2.1796721584185783\n",
      "(Iteration 261 / 8736) loss: 2.254128721067678\n",
      "(Iteration 271 / 8736) loss: 2.1910594086099997\n",
      "(Iteration 281 / 8736) loss: 2.2785287227426694\n",
      "(Iteration 291 / 8736) loss: 2.2837987076825415\n",
      "(Iteration 301 / 8736) loss: 2.187511211563512\n",
      "(Iteration 311 / 8736) loss: 2.2362536676495846\n",
      "(Iteration 321 / 8736) loss: 2.230943088907542\n",
      "(Iteration 331 / 8736) loss: 2.2086938834518297\n",
      "(Iteration 341 / 8736) loss: 2.2106823299877605\n",
      "(Iteration 351 / 8736) loss: 2.201864456166168\n",
      "(Iteration 361 / 8736) loss: 2.224875625187746\n",
      "(Iteration 371 / 8736) loss: 2.288174811785664\n",
      "(Iteration 381 / 8736) loss: 2.2358631455713445\n",
      "(Iteration 391 / 8736) loss: 2.2087666697308346\n",
      "(Iteration 401 / 8736) loss: 2.2258143947950426\n",
      "(Iteration 411 / 8736) loss: 2.188737157828337\n",
      "(Iteration 421 / 8736) loss: 2.2055058362265485\n",
      "(Iteration 431 / 8736) loss: 2.1783088795438066\n",
      "(Iteration 441 / 8736) loss: 2.061659972712775\n",
      "(Iteration 451 / 8736) loss: 2.112531442103179\n",
      "(Iteration 461 / 8736) loss: 2.1634158360936744\n",
      "(Iteration 471 / 8736) loss: 2.0195857737297938\n",
      "(Iteration 481 / 8736) loss: 1.8703983156096595\n",
      "(Iteration 491 / 8736) loss: 2.0360539875296944\n",
      "(Iteration 501 / 8736) loss: 2.1394075381281357\n",
      "(Iteration 511 / 8736) loss: 1.9769670900161334\n",
      "(Iteration 521 / 8736) loss: 2.0140539936105415\n",
      "(Iteration 531 / 8736) loss: 1.8536145266665056\n",
      "(Iteration 541 / 8736) loss: 1.9301064106872328\n",
      "(Epoch 1 / 16) Training Accuracy: 0.29241428571428574, Validation Accuracy: 0.2818544673011974\n",
      "(Iteration 551 / 8736) loss: 1.9027103052401206\n",
      "(Iteration 561 / 8736) loss: 1.8735460951125238\n",
      "(Iteration 571 / 8736) loss: 1.8601377025253076\n",
      "(Iteration 581 / 8736) loss: 2.01971221217273\n",
      "(Iteration 591 / 8736) loss: 1.8178714480309\n",
      "(Iteration 601 / 8736) loss: 1.7539445163699132\n",
      "(Iteration 611 / 8736) loss: 1.9203465406567772\n",
      "(Iteration 621 / 8736) loss: 1.8456493778891747\n",
      "(Iteration 631 / 8736) loss: 1.7189500439116905\n",
      "(Iteration 641 / 8736) loss: 1.749509932588786\n",
      "(Iteration 651 / 8736) loss: 1.6999947568863192\n",
      "(Iteration 661 / 8736) loss: 1.790451739420281\n",
      "(Iteration 671 / 8736) loss: 1.8675805192180885\n",
      "(Iteration 681 / 8736) loss: 1.8459121958894606\n",
      "(Iteration 691 / 8736) loss: 1.718099147073573\n",
      "(Iteration 701 / 8736) loss: 1.6502761032073918\n",
      "(Iteration 711 / 8736) loss: 1.7778785452671322\n",
      "(Iteration 721 / 8736) loss: 1.9255256150905984\n",
      "(Iteration 731 / 8736) loss: 1.7366097366807078\n",
      "(Iteration 741 / 8736) loss: 1.618780329755198\n",
      "(Iteration 751 / 8736) loss: 1.699308207828738\n",
      "(Iteration 761 / 8736) loss: 1.5847953509717367\n",
      "(Iteration 771 / 8736) loss: 1.7066597454993007\n",
      "(Iteration 781 / 8736) loss: 1.8249040205001559\n",
      "(Iteration 791 / 8736) loss: 1.5776565750193856\n",
      "(Iteration 801 / 8736) loss: 1.5855782223233161\n",
      "(Iteration 811 / 8736) loss: 1.7507704151035681\n",
      "(Iteration 821 / 8736) loss: 1.6214296102885677\n",
      "(Iteration 831 / 8736) loss: 1.4653718101299171\n",
      "(Iteration 841 / 8736) loss: 1.6763192478219968\n",
      "(Iteration 851 / 8736) loss: 1.655667783298704\n",
      "(Iteration 861 / 8736) loss: 1.7671881804963792\n",
      "(Iteration 871 / 8736) loss: 1.6990826655007645\n",
      "(Iteration 881 / 8736) loss: 1.6344592310013832\n",
      "(Iteration 891 / 8736) loss: 1.7350024302318001\n",
      "(Iteration 901 / 8736) loss: 1.5993393174363848\n",
      "(Iteration 911 / 8736) loss: 1.5273444137025192\n",
      "(Iteration 921 / 8736) loss: 1.469364533195264\n",
      "(Iteration 931 / 8736) loss: 1.6001585964767695\n",
      "(Iteration 941 / 8736) loss: 1.4179039634437165\n",
      "(Iteration 951 / 8736) loss: 1.3941068882473964\n",
      "(Iteration 961 / 8736) loss: 1.4245139497868733\n",
      "(Iteration 971 / 8736) loss: 1.5189665385083437\n",
      "(Iteration 981 / 8736) loss: 1.5207010841551203\n",
      "(Iteration 991 / 8736) loss: 1.597323595016803\n",
      "(Iteration 1001 / 8736) loss: 1.5883211386414646\n",
      "(Iteration 1011 / 8736) loss: 1.5465343601055888\n",
      "(Iteration 1021 / 8736) loss: 1.3204480490763073\n",
      "(Iteration 1031 / 8736) loss: 1.5309439779506402\n",
      "(Iteration 1041 / 8736) loss: 1.426487648073913\n",
      "(Iteration 1051 / 8736) loss: 1.245173262103121\n",
      "(Iteration 1061 / 8736) loss: 1.4126042902176987\n",
      "(Iteration 1071 / 8736) loss: 1.4949888693341358\n",
      "(Iteration 1081 / 8736) loss: 1.372969809275048\n",
      "(Iteration 1091 / 8736) loss: 1.4521529956608534\n",
      "(Epoch 2 / 16) Training Accuracy: 0.5243571428571429, Validation Accuracy: 0.5118206938900829\n",
      "(Iteration 1101 / 8736) loss: 1.5463913600408734\n",
      "(Iteration 1111 / 8736) loss: 1.3605237310348326\n",
      "(Iteration 1121 / 8736) loss: 1.4104033324000116\n",
      "(Iteration 1131 / 8736) loss: 1.4838855584949462\n",
      "(Iteration 1141 / 8736) loss: 1.2548789809664072\n",
      "(Iteration 1151 / 8736) loss: 1.6041386889470262\n",
      "(Iteration 1161 / 8736) loss: 1.419304811418302\n",
      "(Iteration 1171 / 8736) loss: 1.3337729387351354\n",
      "(Iteration 1181 / 8736) loss: 1.5212879328051347\n",
      "(Iteration 1191 / 8736) loss: 1.3410376721645594\n",
      "(Iteration 1201 / 8736) loss: 1.4387234550665906\n",
      "(Iteration 1211 / 8736) loss: 1.4045360683404742\n",
      "(Iteration 1221 / 8736) loss: 1.4380649636386413\n",
      "(Iteration 1231 / 8736) loss: 1.2889331470450827\n",
      "(Iteration 1241 / 8736) loss: 1.1386397891347764\n",
      "(Iteration 1251 / 8736) loss: 1.364234334910487\n",
      "(Iteration 1261 / 8736) loss: 1.4434664804001187\n",
      "(Iteration 1271 / 8736) loss: 1.1975413766337024\n",
      "(Iteration 1281 / 8736) loss: 1.418619908810123\n",
      "(Iteration 1291 / 8736) loss: 1.192365877659548\n",
      "(Iteration 1301 / 8736) loss: 1.2983454868473046\n",
      "(Iteration 1311 / 8736) loss: 1.3611316200217236\n",
      "(Iteration 1321 / 8736) loss: 1.2971248225891976\n",
      "(Iteration 1331 / 8736) loss: 1.5410382490949663\n",
      "(Iteration 1341 / 8736) loss: 1.4114259044158604\n",
      "(Iteration 1351 / 8736) loss: 1.186268197395739\n",
      "(Iteration 1361 / 8736) loss: 1.4974115090758937\n",
      "(Iteration 1371 / 8736) loss: 1.3060313951138796\n",
      "(Iteration 1381 / 8736) loss: 1.3768526367418306\n",
      "(Iteration 1391 / 8736) loss: 1.1526490751995704\n",
      "(Iteration 1401 / 8736) loss: 1.141907838105803\n",
      "(Iteration 1411 / 8736) loss: 1.1113029211642345\n",
      "(Iteration 1421 / 8736) loss: 1.3201654098503113\n",
      "(Iteration 1431 / 8736) loss: 1.1786264940559503\n",
      "(Iteration 1441 / 8736) loss: 1.1931747291964614\n",
      "(Iteration 1451 / 8736) loss: 1.4653202912303944\n",
      "(Iteration 1461 / 8736) loss: 1.3946246919260556\n",
      "(Iteration 1471 / 8736) loss: 1.3450276979895157\n",
      "(Iteration 1481 / 8736) loss: 1.44920981448007\n",
      "(Iteration 1491 / 8736) loss: 1.283572464771626\n",
      "(Iteration 1501 / 8736) loss: 1.1130780583788193\n",
      "(Iteration 1511 / 8736) loss: 1.4167057958928801\n",
      "(Iteration 1521 / 8736) loss: 1.3124499228455178\n",
      "(Iteration 1531 / 8736) loss: 1.1591715469014832\n",
      "(Iteration 1541 / 8736) loss: 1.1922456771236525\n",
      "(Iteration 1551 / 8736) loss: 1.2667196239178267\n",
      "(Iteration 1561 / 8736) loss: 1.291543216265326\n",
      "(Iteration 1571 / 8736) loss: 1.1056019109335729\n",
      "(Iteration 1581 / 8736) loss: 1.2676766571947453\n",
      "(Iteration 1591 / 8736) loss: 1.5173837733365583\n",
      "(Iteration 1601 / 8736) loss: 1.2356379781378937\n",
      "(Iteration 1611 / 8736) loss: 1.1665661005207981\n",
      "(Iteration 1621 / 8736) loss: 1.2086809750951555\n",
      "(Iteration 1631 / 8736) loss: 1.1924579178322134\n",
      "(Epoch 3 / 16) Training Accuracy: 0.6091285714285715, Validation Accuracy: 0.591341725514277\n",
      "(Iteration 1641 / 8736) loss: 1.1765657203275062\n",
      "(Iteration 1651 / 8736) loss: 1.272532922101043\n",
      "(Iteration 1661 / 8736) loss: 1.2559048156224277\n",
      "(Iteration 1671 / 8736) loss: 1.1429661465814425\n",
      "(Iteration 1681 / 8736) loss: 1.0909738165567526\n",
      "(Iteration 1691 / 8736) loss: 1.097862869481099\n",
      "(Iteration 1701 / 8736) loss: 1.2147437994694663\n",
      "(Iteration 1711 / 8736) loss: 1.1946698863317011\n",
      "(Iteration 1721 / 8736) loss: 1.3080588554367258\n",
      "(Iteration 1731 / 8736) loss: 1.2354487469109996\n",
      "(Iteration 1741 / 8736) loss: 1.2768935117355464\n",
      "(Iteration 1751 / 8736) loss: 1.0238140079739635\n",
      "(Iteration 1761 / 8736) loss: 1.098499110858016\n",
      "(Iteration 1771 / 8736) loss: 1.3392158444849849\n",
      "(Iteration 1781 / 8736) loss: 1.057959850854127\n",
      "(Iteration 1791 / 8736) loss: 1.098649025239243\n",
      "(Iteration 1801 / 8736) loss: 0.9979549813276518\n",
      "(Iteration 1811 / 8736) loss: 1.0385249460963102\n",
      "(Iteration 1821 / 8736) loss: 1.1224804586180193\n",
      "(Iteration 1831 / 8736) loss: 1.2245390882275622\n",
      "(Iteration 1841 / 8736) loss: 1.110056301371146\n",
      "(Iteration 1851 / 8736) loss: 1.4534258590038094\n",
      "(Iteration 1861 / 8736) loss: 1.2103658004357956\n",
      "(Iteration 1871 / 8736) loss: 1.0605063138096735\n",
      "(Iteration 1881 / 8736) loss: 1.1241304991639918\n",
      "(Iteration 1891 / 8736) loss: 1.030355658087689\n",
      "(Iteration 1901 / 8736) loss: 1.2237273396773192\n",
      "(Iteration 1911 / 8736) loss: 1.344483908105939\n",
      "(Iteration 1921 / 8736) loss: 1.3719100041888512\n",
      "(Iteration 1931 / 8736) loss: 1.3107910095897661\n",
      "(Iteration 1941 / 8736) loss: 1.2955298971224571\n",
      "(Iteration 1951 / 8736) loss: 1.1654385070960174\n",
      "(Iteration 1961 / 8736) loss: 1.0674481933373583\n",
      "(Iteration 1971 / 8736) loss: 1.0590994523639818\n",
      "(Iteration 1981 / 8736) loss: 1.1945852470896468\n",
      "(Iteration 1991 / 8736) loss: 1.0310764681382063\n",
      "(Iteration 2001 / 8736) loss: 1.1028351087837605\n",
      "(Iteration 2011 / 8736) loss: 1.0717926967026727\n",
      "(Iteration 2021 / 8736) loss: 1.035714627918232\n",
      "(Iteration 2031 / 8736) loss: 1.0317717233285333\n",
      "(Iteration 2041 / 8736) loss: 0.9805523604849106\n",
      "(Iteration 2051 / 8736) loss: 0.9720143202329509\n",
      "(Iteration 2061 / 8736) loss: 1.0439407426942922\n",
      "(Iteration 2071 / 8736) loss: 1.0631848227208716\n",
      "(Iteration 2081 / 8736) loss: 1.0330913176969752\n",
      "(Iteration 2091 / 8736) loss: 1.0422556289929816\n",
      "(Iteration 2101 / 8736) loss: 1.1400494436015662\n",
      "(Iteration 2111 / 8736) loss: 0.9527996619505411\n",
      "(Iteration 2121 / 8736) loss: 1.1966207452472735\n",
      "(Iteration 2131 / 8736) loss: 1.112239851770165\n",
      "(Iteration 2141 / 8736) loss: 1.039660267088087\n",
      "(Iteration 2151 / 8736) loss: 1.0459772481813208\n",
      "(Iteration 2161 / 8736) loss: 1.1316278016362862\n",
      "(Iteration 2171 / 8736) loss: 1.0122925343736826\n",
      "(Iteration 2181 / 8736) loss: 0.8493363139588131\n",
      "(Epoch 4 / 16) Training Accuracy: 0.6648428571428572, Validation Accuracy: 0.6466073073380412\n",
      "(Iteration 2191 / 8736) loss: 0.9391450983398925\n",
      "(Iteration 2201 / 8736) loss: 0.9434262919119496\n",
      "(Iteration 2211 / 8736) loss: 1.0581091404297551\n",
      "(Iteration 2221 / 8736) loss: 1.0167777962589444\n",
      "(Iteration 2231 / 8736) loss: 1.046642490806569\n",
      "(Iteration 2241 / 8736) loss: 0.983573809164068\n",
      "(Iteration 2251 / 8736) loss: 1.113736268823748\n",
      "(Iteration 2261 / 8736) loss: 0.9407394780656015\n",
      "(Iteration 2271 / 8736) loss: 0.9220458447095927\n",
      "(Iteration 2281 / 8736) loss: 0.9070458493477975\n",
      "(Iteration 2291 / 8736) loss: 1.3114965299867067\n",
      "(Iteration 2301 / 8736) loss: 0.9897527141850159\n",
      "(Iteration 2311 / 8736) loss: 0.9993490533505546\n",
      "(Iteration 2321 / 8736) loss: 0.9721781261589278\n",
      "(Iteration 2331 / 8736) loss: 1.013693847779614\n",
      "(Iteration 2341 / 8736) loss: 0.9652228483541415\n",
      "(Iteration 2351 / 8736) loss: 0.8463087951261494\n",
      "(Iteration 2361 / 8736) loss: 1.075825826698301\n",
      "(Iteration 2371 / 8736) loss: 1.0801992133271814\n",
      "(Iteration 2381 / 8736) loss: 1.007107645786547\n",
      "(Iteration 2391 / 8736) loss: 0.9864189925650666\n",
      "(Iteration 2401 / 8736) loss: 1.1828537522086486\n",
      "(Iteration 2411 / 8736) loss: 1.0206361697776536\n",
      "(Iteration 2421 / 8736) loss: 1.063100491551506\n",
      "(Iteration 2431 / 8736) loss: 1.0709082277845152\n",
      "(Iteration 2441 / 8736) loss: 1.0212942072489701\n",
      "(Iteration 2451 / 8736) loss: 1.1329409208763823\n",
      "(Iteration 2461 / 8736) loss: 1.0519320512507455\n",
      "(Iteration 2471 / 8736) loss: 1.150702720883771\n",
      "(Iteration 2481 / 8736) loss: 0.8725976977042345\n",
      "(Iteration 2491 / 8736) loss: 1.1406890342843392\n",
      "(Iteration 2501 / 8736) loss: 0.9003713319817822\n",
      "(Iteration 2511 / 8736) loss: 0.7902820844062441\n",
      "(Iteration 2521 / 8736) loss: 1.063860867150411\n",
      "(Iteration 2531 / 8736) loss: 0.9003818637478066\n",
      "(Iteration 2541 / 8736) loss: 0.9605277196477222\n",
      "(Iteration 2551 / 8736) loss: 1.1614869651505448\n",
      "(Iteration 2561 / 8736) loss: 1.2793488887251965\n",
      "(Iteration 2571 / 8736) loss: 0.9630773244330744\n",
      "(Iteration 2581 / 8736) loss: 1.2514190837999701\n",
      "(Iteration 2591 / 8736) loss: 0.9586839838209497\n",
      "(Iteration 2601 / 8736) loss: 1.1241466036392234\n",
      "(Iteration 2611 / 8736) loss: 0.9565711140287178\n",
      "(Iteration 2621 / 8736) loss: 1.1132901064920326\n",
      "(Iteration 2631 / 8736) loss: 0.8125488038822332\n",
      "(Iteration 2641 / 8736) loss: 0.9712190493868004\n",
      "(Iteration 2651 / 8736) loss: 1.0622901201565262\n",
      "(Iteration 2661 / 8736) loss: 0.9921088532699519\n",
      "(Iteration 2671 / 8736) loss: 0.820580010520863\n",
      "(Iteration 2681 / 8736) loss: 1.0327582321038322\n",
      "(Iteration 2691 / 8736) loss: 0.9022152256977323\n",
      "(Iteration 2701 / 8736) loss: 1.1651702544682285\n",
      "(Iteration 2711 / 8736) loss: 0.9942678517144021\n",
      "(Iteration 2721 / 8736) loss: 0.9345403762711887\n",
      "(Epoch 5 / 16) Training Accuracy: 0.6901714285714285, Validation Accuracy: 0.6757752533005834\n",
      "(Iteration 2731 / 8736) loss: 1.1422593181398697\n",
      "(Iteration 2741 / 8736) loss: 1.0463956395945702\n",
      "(Iteration 2751 / 8736) loss: 0.9652459899560796\n",
      "(Iteration 2761 / 8736) loss: 0.9513366961674862\n",
      "(Iteration 2771 / 8736) loss: 1.1149804308497127\n",
      "(Iteration 2781 / 8736) loss: 0.9402609513495739\n",
      "(Iteration 2791 / 8736) loss: 0.9833093699732078\n",
      "(Iteration 2801 / 8736) loss: 0.8472626179393519\n",
      "(Iteration 2811 / 8736) loss: 1.1591136057194915\n",
      "(Iteration 2821 / 8736) loss: 0.8351901347179359\n",
      "(Iteration 2831 / 8736) loss: 0.9987045347017955\n",
      "(Iteration 2841 / 8736) loss: 1.0591465905966184\n",
      "(Iteration 2851 / 8736) loss: 0.9897907074835883\n",
      "(Iteration 2861 / 8736) loss: 0.7946610493318748\n",
      "(Iteration 2871 / 8736) loss: 1.0158942028296545\n",
      "(Iteration 2881 / 8736) loss: 0.9625510441216817\n",
      "(Iteration 2891 / 8736) loss: 1.0356792365096934\n",
      "(Iteration 2901 / 8736) loss: 1.0298206356321726\n",
      "(Iteration 2911 / 8736) loss: 0.810578075892136\n",
      "(Iteration 2921 / 8736) loss: 0.8527083697397809\n",
      "(Iteration 2931 / 8736) loss: 0.8272868602880178\n",
      "(Iteration 2941 / 8736) loss: 0.9476234285037971\n",
      "(Iteration 2951 / 8736) loss: 0.9723198626400293\n",
      "(Iteration 2961 / 8736) loss: 0.9839130844688978\n",
      "(Iteration 2971 / 8736) loss: 1.1155847059424404\n",
      "(Iteration 2981 / 8736) loss: 1.1005192648860427\n",
      "(Iteration 2991 / 8736) loss: 0.9185866926660994\n",
      "(Iteration 3001 / 8736) loss: 1.0175914941044888\n",
      "(Iteration 3011 / 8736) loss: 0.9557478723948639\n",
      "(Iteration 3021 / 8736) loss: 1.085320758121958\n",
      "(Iteration 3031 / 8736) loss: 0.9355232613445174\n",
      "(Iteration 3041 / 8736) loss: 1.0688500467429853\n",
      "(Iteration 3051 / 8736) loss: 1.0874127898768333\n",
      "(Iteration 3061 / 8736) loss: 0.9134716488092067\n",
      "(Iteration 3071 / 8736) loss: 0.8933229660893324\n",
      "(Iteration 3081 / 8736) loss: 0.8777241359096652\n",
      "(Iteration 3091 / 8736) loss: 0.9851843683849176\n",
      "(Iteration 3101 / 8736) loss: 1.118831502425514\n",
      "(Iteration 3111 / 8736) loss: 1.1143869444744092\n",
      "(Iteration 3121 / 8736) loss: 0.90744005539141\n",
      "(Iteration 3131 / 8736) loss: 0.8720229311829466\n",
      "(Iteration 3141 / 8736) loss: 0.9733530047777746\n",
      "(Iteration 3151 / 8736) loss: 0.9022060841137789\n",
      "(Iteration 3161 / 8736) loss: 0.9699476112140867\n",
      "(Iteration 3171 / 8736) loss: 0.9472187480035148\n",
      "(Iteration 3181 / 8736) loss: 1.0417942242945442\n",
      "(Iteration 3191 / 8736) loss: 1.1477548423956356\n",
      "(Iteration 3201 / 8736) loss: 0.8472397461782891\n",
      "(Iteration 3211 / 8736) loss: 1.0601572587430825\n",
      "(Iteration 3221 / 8736) loss: 0.7329819965924042\n",
      "(Iteration 3231 / 8736) loss: 0.915728021822132\n",
      "(Iteration 3241 / 8736) loss: 0.8103519481533917\n",
      "(Iteration 3251 / 8736) loss: 1.09254463001814\n",
      "(Iteration 3261 / 8736) loss: 0.9203092224716805\n",
      "(Iteration 3271 / 8736) loss: 0.9165050314293949\n",
      "(Epoch 6 / 16) Training Accuracy: 0.726, Validation Accuracy: 0.7153822536076143\n",
      "(Iteration 3281 / 8736) loss: 0.8031802995800522\n",
      "(Iteration 3291 / 8736) loss: 0.8802411695592761\n",
      "(Iteration 3301 / 8736) loss: 0.8494218156077387\n",
      "(Iteration 3311 / 8736) loss: 0.7919950761078881\n",
      "(Iteration 3321 / 8736) loss: 0.7037203844271049\n",
      "(Iteration 3331 / 8736) loss: 0.7682061187531499\n",
      "(Iteration 3341 / 8736) loss: 0.8550126221534506\n",
      "(Iteration 3351 / 8736) loss: 0.7938199760673453\n",
      "(Iteration 3361 / 8736) loss: 0.846028289357251\n",
      "(Iteration 3371 / 8736) loss: 0.8445031419741036\n",
      "(Iteration 3381 / 8736) loss: 0.9872168992911217\n",
      "(Iteration 3391 / 8736) loss: 0.9637642250379204\n",
      "(Iteration 3401 / 8736) loss: 0.7588812083000547\n",
      "(Iteration 3411 / 8736) loss: 1.0146398495109732\n",
      "(Iteration 3421 / 8736) loss: 0.8243507521811347\n",
      "(Iteration 3431 / 8736) loss: 0.8836389661948468\n",
      "(Iteration 3441 / 8736) loss: 0.9793272652992492\n",
      "(Iteration 3451 / 8736) loss: 0.9124868317636622\n",
      "(Iteration 3461 / 8736) loss: 0.9550304250117349\n",
      "(Iteration 3471 / 8736) loss: 0.8496544680084437\n",
      "(Iteration 3481 / 8736) loss: 0.774527634977978\n",
      "(Iteration 3491 / 8736) loss: 0.7011049214729571\n",
      "(Iteration 3501 / 8736) loss: 0.8808433780229881\n",
      "(Iteration 3511 / 8736) loss: 0.783541791502631\n",
      "(Iteration 3521 / 8736) loss: 0.8654177683983985\n",
      "(Iteration 3531 / 8736) loss: 0.8597703749782694\n",
      "(Iteration 3541 / 8736) loss: 0.9449426475190742\n",
      "(Iteration 3551 / 8736) loss: 0.8039939397804475\n",
      "(Iteration 3561 / 8736) loss: 1.000494641586537\n",
      "(Iteration 3571 / 8736) loss: 1.024942515624191\n",
      "(Iteration 3581 / 8736) loss: 0.71210103722683\n",
      "(Iteration 3591 / 8736) loss: 0.8772684403487048\n",
      "(Iteration 3601 / 8736) loss: 0.7449773270801556\n",
      "(Iteration 3611 / 8736) loss: 0.8011461936131864\n",
      "(Iteration 3621 / 8736) loss: 0.8808036506346538\n",
      "(Iteration 3631 / 8736) loss: 0.8276398451943279\n",
      "(Iteration 3641 / 8736) loss: 0.9050452744016718\n",
      "(Iteration 3651 / 8736) loss: 0.6637416443352715\n",
      "(Iteration 3661 / 8736) loss: 0.802719343969563\n",
      "(Iteration 3671 / 8736) loss: 0.7339288605114966\n",
      "(Iteration 3681 / 8736) loss: 0.9688839419140509\n",
      "(Iteration 3691 / 8736) loss: 0.8652900844940966\n",
      "(Iteration 3701 / 8736) loss: 0.7822592936616326\n",
      "(Iteration 3711 / 8736) loss: 0.8611247674921501\n",
      "(Iteration 3721 / 8736) loss: 0.7920437578074064\n",
      "(Iteration 3731 / 8736) loss: 0.9785576295017262\n",
      "(Iteration 3741 / 8736) loss: 0.9766527605263604\n",
      "(Iteration 3751 / 8736) loss: 0.8564135876675272\n",
      "(Iteration 3761 / 8736) loss: 0.7596367346403204\n",
      "(Iteration 3771 / 8736) loss: 0.7850196324223339\n",
      "(Iteration 3781 / 8736) loss: 0.6946524014513896\n",
      "(Iteration 3791 / 8736) loss: 0.6808919453697663\n",
      "(Iteration 3801 / 8736) loss: 0.8062943002391249\n",
      "(Iteration 3811 / 8736) loss: 0.7739663847951226\n",
      "(Iteration 3821 / 8736) loss: 0.7359809511732518\n",
      "(Epoch 7 / 16) Training Accuracy: 0.7461142857142857, Validation Accuracy: 0.7396377034080442\n",
      "(Iteration 3831 / 8736) loss: 0.8574489084880695\n",
      "(Iteration 3841 / 8736) loss: 0.9015092241639978\n",
      "(Iteration 3851 / 8736) loss: 0.7086171592317284\n",
      "(Iteration 3861 / 8736) loss: 0.9283811919082625\n",
      "(Iteration 3871 / 8736) loss: 0.8837456194632319\n",
      "(Iteration 3881 / 8736) loss: 0.9255032084781194\n",
      "(Iteration 3891 / 8736) loss: 0.7902706781782473\n",
      "(Iteration 3901 / 8736) loss: 0.6781386455181357\n",
      "(Iteration 3911 / 8736) loss: 0.9258195674282272\n",
      "(Iteration 3921 / 8736) loss: 0.964449495271559\n",
      "(Iteration 3931 / 8736) loss: 0.8424820149737969\n",
      "(Iteration 3941 / 8736) loss: 0.6961636117778202\n",
      "(Iteration 3951 / 8736) loss: 0.7934904474706744\n",
      "(Iteration 3961 / 8736) loss: 0.7748611134511623\n",
      "(Iteration 3971 / 8736) loss: 0.8956393761809125\n",
      "(Iteration 3981 / 8736) loss: 0.9770845268650274\n",
      "(Iteration 3991 / 8736) loss: 0.8072896497257344\n",
      "(Iteration 4001 / 8736) loss: 0.8706923964367053\n",
      "(Iteration 4011 / 8736) loss: 0.8189944640137705\n",
      "(Iteration 4021 / 8736) loss: 0.7111337156966073\n",
      "(Iteration 4031 / 8736) loss: 0.8194169966961714\n",
      "(Iteration 4041 / 8736) loss: 0.7584206850878941\n",
      "(Iteration 4051 / 8736) loss: 0.8617175006022499\n",
      "(Iteration 4061 / 8736) loss: 0.9638700156707817\n",
      "(Iteration 4071 / 8736) loss: 0.6581015535757108\n",
      "(Iteration 4081 / 8736) loss: 0.7654582284340882\n",
      "(Iteration 4091 / 8736) loss: 0.7708423708010763\n",
      "(Iteration 4101 / 8736) loss: 0.7852580739055511\n",
      "(Iteration 4111 / 8736) loss: 0.9774994902022605\n",
      "(Iteration 4121 / 8736) loss: 0.916910666910804\n",
      "(Iteration 4131 / 8736) loss: 0.8325010449355764\n",
      "(Iteration 4141 / 8736) loss: 0.8497582712090462\n",
      "(Iteration 4151 / 8736) loss: 0.8976976154843221\n",
      "(Iteration 4161 / 8736) loss: 0.8231745599543295\n",
      "(Iteration 4171 / 8736) loss: 0.9655896884015873\n",
      "(Iteration 4181 / 8736) loss: 0.8050398545832259\n",
      "(Iteration 4191 / 8736) loss: 0.8589794875922131\n",
      "(Iteration 4201 / 8736) loss: 0.6671496533440073\n",
      "(Iteration 4211 / 8736) loss: 0.8130849380186242\n",
      "(Iteration 4221 / 8736) loss: 0.9606494822641378\n",
      "(Iteration 4231 / 8736) loss: 0.6607338272287452\n",
      "(Iteration 4241 / 8736) loss: 1.0418803200378284\n",
      "(Iteration 4251 / 8736) loss: 0.7797324597701\n",
      "(Iteration 4261 / 8736) loss: 0.7601522827038234\n",
      "(Iteration 4271 / 8736) loss: 0.9756150250044635\n",
      "(Iteration 4281 / 8736) loss: 0.8822264331945684\n",
      "(Iteration 4291 / 8736) loss: 0.7447453267283983\n",
      "(Iteration 4301 / 8736) loss: 0.7327007140364614\n",
      "(Iteration 4311 / 8736) loss: 0.7676818611943741\n",
      "(Iteration 4321 / 8736) loss: 0.7149782393347464\n",
      "(Iteration 4331 / 8736) loss: 0.707459786865668\n",
      "(Iteration 4341 / 8736) loss: 0.7396306153284659\n",
      "(Iteration 4351 / 8736) loss: 0.7875624299701051\n",
      "(Iteration 4361 / 8736) loss: 0.9404267659588154\n",
      "(Epoch 8 / 16) Training Accuracy: 0.7656, Validation Accuracy: 0.7617439361375499\n",
      "(Iteration 4371 / 8736) loss: 0.6118274537549915\n",
      "(Iteration 4381 / 8736) loss: 0.5920628672417632\n",
      "(Iteration 4391 / 8736) loss: 0.679080362781718\n",
      "(Iteration 4401 / 8736) loss: 0.898804379733356\n",
      "(Iteration 4411 / 8736) loss: 0.8247448539447013\n",
      "(Iteration 4421 / 8736) loss: 0.831586785578723\n",
      "(Iteration 4431 / 8736) loss: 0.8644838982305358\n",
      "(Iteration 4441 / 8736) loss: 0.9618546912567358\n",
      "(Iteration 4451 / 8736) loss: 0.7255888290501167\n",
      "(Iteration 4461 / 8736) loss: 0.7910563999079272\n",
      "(Iteration 4471 / 8736) loss: 0.8790614920051881\n",
      "(Iteration 4481 / 8736) loss: 0.7121353028936992\n",
      "(Iteration 4491 / 8736) loss: 0.7285339959863103\n",
      "(Iteration 4501 / 8736) loss: 0.8003828256462325\n",
      "(Iteration 4511 / 8736) loss: 0.7724095156529673\n",
      "(Iteration 4521 / 8736) loss: 0.8266932292375405\n",
      "(Iteration 4531 / 8736) loss: 0.8544416761784077\n",
      "(Iteration 4541 / 8736) loss: 0.8009246478725993\n",
      "(Iteration 4551 / 8736) loss: 0.8904700999727931\n",
      "(Iteration 4561 / 8736) loss: 0.7548039351194907\n",
      "(Iteration 4571 / 8736) loss: 0.7416716275829637\n",
      "(Iteration 4581 / 8736) loss: 0.918781847173921\n",
      "(Iteration 4591 / 8736) loss: 0.6906013832329623\n",
      "(Iteration 4601 / 8736) loss: 0.8362459690394121\n",
      "(Iteration 4611 / 8736) loss: 0.7437224483153928\n",
      "(Iteration 4621 / 8736) loss: 0.8118512707834314\n",
      "(Iteration 4631 / 8736) loss: 0.6186121336178431\n",
      "(Iteration 4641 / 8736) loss: 0.7513657097001291\n",
      "(Iteration 4651 / 8736) loss: 0.8075629612287832\n",
      "(Iteration 4661 / 8736) loss: 0.8778430031035156\n",
      "(Iteration 4671 / 8736) loss: 0.8606371085933082\n",
      "(Iteration 4681 / 8736) loss: 0.7491775323320343\n",
      "(Iteration 4691 / 8736) loss: 0.6307735786833617\n",
      "(Iteration 4701 / 8736) loss: 0.8320901011778034\n",
      "(Iteration 4711 / 8736) loss: 0.6826674277200794\n",
      "(Iteration 4721 / 8736) loss: 0.747999184576678\n",
      "(Iteration 4731 / 8736) loss: 0.7937175795315832\n",
      "(Iteration 4741 / 8736) loss: 0.5679812292440662\n",
      "(Iteration 4751 / 8736) loss: 0.8130078549978332\n",
      "(Iteration 4761 / 8736) loss: 0.7295265627771429\n",
      "(Iteration 4771 / 8736) loss: 0.6697708997632016\n",
      "(Iteration 4781 / 8736) loss: 0.7725510658092392\n",
      "(Iteration 4791 / 8736) loss: 0.7441923000506493\n",
      "(Iteration 4801 / 8736) loss: 0.7293743319322779\n",
      "(Iteration 4811 / 8736) loss: 0.7383066207749761\n",
      "(Iteration 4821 / 8736) loss: 0.7902423447493276\n",
      "(Iteration 4831 / 8736) loss: 1.1779379985484026\n",
      "(Iteration 4841 / 8736) loss: 0.7405864835286623\n",
      "(Iteration 4851 / 8736) loss: 1.0499202695564067\n",
      "(Iteration 4861 / 8736) loss: 0.647302377371936\n",
      "(Iteration 4871 / 8736) loss: 0.8601567925084493\n",
      "(Iteration 4881 / 8736) loss: 0.9344948970916025\n",
      "(Iteration 4891 / 8736) loss: 0.6614660741911247\n",
      "(Iteration 4901 / 8736) loss: 0.6117169564074298\n",
      "(Iteration 4911 / 8736) loss: 0.6546394838503937\n",
      "(Epoch 9 / 16) Training Accuracy: 0.7730714285714285, Validation Accuracy: 0.7712618974516426\n",
      "(Iteration 4921 / 8736) loss: 1.0049303653464159\n",
      "(Iteration 4931 / 8736) loss: 0.7263048372345824\n",
      "(Iteration 4941 / 8736) loss: 0.87845981966554\n",
      "(Iteration 4951 / 8736) loss: 0.6849491164398881\n",
      "(Iteration 4961 / 8736) loss: 0.6921756180532415\n",
      "(Iteration 4971 / 8736) loss: 0.7564913368157328\n",
      "(Iteration 4981 / 8736) loss: 0.7355043213110508\n",
      "(Iteration 4991 / 8736) loss: 1.0162278922807049\n",
      "(Iteration 5001 / 8736) loss: 0.7487020565757195\n",
      "(Iteration 5011 / 8736) loss: 0.8117300998578231\n",
      "(Iteration 5021 / 8736) loss: 0.7102933801233055\n",
      "(Iteration 5031 / 8736) loss: 0.7954876901518019\n",
      "(Iteration 5041 / 8736) loss: 0.9414383380783283\n",
      "(Iteration 5051 / 8736) loss: 0.6366595079800057\n",
      "(Iteration 5061 / 8736) loss: 0.7061344484809315\n",
      "(Iteration 5071 / 8736) loss: 0.6448916155579169\n",
      "(Iteration 5081 / 8736) loss: 0.6383297015572293\n",
      "(Iteration 5091 / 8736) loss: 0.5254197463296478\n",
      "(Iteration 5101 / 8736) loss: 0.7663778836959547\n",
      "(Iteration 5111 / 8736) loss: 0.839872955380244\n",
      "(Iteration 5121 / 8736) loss: 0.7076378606766034\n",
      "(Iteration 5131 / 8736) loss: 0.7667336030421914\n",
      "(Iteration 5141 / 8736) loss: 0.8017259020408681\n",
      "(Iteration 5151 / 8736) loss: 0.7566763024612075\n",
      "(Iteration 5161 / 8736) loss: 0.9975626497784951\n",
      "(Iteration 5171 / 8736) loss: 0.8395188721427417\n",
      "(Iteration 5181 / 8736) loss: 0.6676373265076057\n",
      "(Iteration 5191 / 8736) loss: 0.8050357675853163\n",
      "(Iteration 5201 / 8736) loss: 0.9439352508537522\n",
      "(Iteration 5211 / 8736) loss: 0.7642116341250759\n",
      "(Iteration 5221 / 8736) loss: 0.953905099485941\n",
      "(Iteration 5231 / 8736) loss: 0.6888800236427026\n",
      "(Iteration 5241 / 8736) loss: 0.7560643132080249\n",
      "(Iteration 5251 / 8736) loss: 0.9147861059696026\n",
      "(Iteration 5261 / 8736) loss: 0.7464597058097713\n",
      "(Iteration 5271 / 8736) loss: 0.8508418057237237\n",
      "(Iteration 5281 / 8736) loss: 0.8505912215975837\n",
      "(Iteration 5291 / 8736) loss: 0.8570924775787249\n",
      "(Iteration 5301 / 8736) loss: 0.6751402637625118\n",
      "(Iteration 5311 / 8736) loss: 0.7661077701068795\n",
      "(Iteration 5321 / 8736) loss: 0.699868463301126\n",
      "(Iteration 5331 / 8736) loss: 0.8705995574663692\n",
      "(Iteration 5341 / 8736) loss: 0.8297201212460373\n",
      "(Iteration 5351 / 8736) loss: 0.7097704837630036\n",
      "(Iteration 5361 / 8736) loss: 0.6750505908864278\n",
      "(Iteration 5371 / 8736) loss: 0.4787741568764996\n",
      "(Iteration 5381 / 8736) loss: 0.786905513348307\n",
      "(Iteration 5391 / 8736) loss: 0.6796012457462489\n",
      "(Iteration 5401 / 8736) loss: 0.6204500941361556\n",
      "(Iteration 5411 / 8736) loss: 0.876919956325252\n",
      "(Iteration 5421 / 8736) loss: 0.5043549521605117\n",
      "(Iteration 5431 / 8736) loss: 0.5954467196276138\n",
      "(Iteration 5441 / 8736) loss: 0.9861134157310338\n",
      "(Iteration 5451 / 8736) loss: 0.7290298352796326\n",
      "(Epoch 10 / 16) Training Accuracy: 0.7882571428571429, Validation Accuracy: 0.7801657967454713\n",
      "Decaying learning rate of the optimizer to 0.00029969999999999997\n",
      "(Iteration 5461 / 8736) loss: 0.7890164295516723\n",
      "(Iteration 5471 / 8736) loss: 0.7515111229220776\n",
      "(Iteration 5481 / 8736) loss: 0.7331819100157989\n",
      "(Iteration 5491 / 8736) loss: 0.9545253987770357\n",
      "(Iteration 5501 / 8736) loss: 0.7827636467152106\n",
      "(Iteration 5511 / 8736) loss: 0.6292677497685099\n",
      "(Iteration 5521 / 8736) loss: 0.6401217164332544\n",
      "(Iteration 5531 / 8736) loss: 0.8132777889957337\n",
      "(Iteration 5541 / 8736) loss: 0.7464610022405862\n",
      "(Iteration 5551 / 8736) loss: 0.685392801387376\n",
      "(Iteration 5561 / 8736) loss: 0.8148762198232239\n",
      "(Iteration 5571 / 8736) loss: 0.8115157039744127\n",
      "(Iteration 5581 / 8736) loss: 0.784878163467949\n",
      "(Iteration 5591 / 8736) loss: 0.7756077469669527\n",
      "(Iteration 5601 / 8736) loss: 0.8672327691518806\n",
      "(Iteration 5611 / 8736) loss: 0.7662132547353131\n",
      "(Iteration 5621 / 8736) loss: 0.636228758476182\n",
      "(Iteration 5631 / 8736) loss: 0.5740220899168064\n",
      "(Iteration 5641 / 8736) loss: 0.4151576586552345\n",
      "(Iteration 5651 / 8736) loss: 0.6609948233382693\n",
      "(Iteration 5661 / 8736) loss: 0.6797457382146004\n",
      "(Iteration 5671 / 8736) loss: 0.6940077592637296\n",
      "(Iteration 5681 / 8736) loss: 0.6350715483611808\n",
      "(Iteration 5691 / 8736) loss: 0.6686399792285127\n",
      "(Iteration 5701 / 8736) loss: 0.8549962633470317\n",
      "(Iteration 5711 / 8736) loss: 0.7264191622217657\n",
      "(Iteration 5721 / 8736) loss: 0.7970744674822691\n",
      "(Iteration 5731 / 8736) loss: 0.6650587193705565\n",
      "(Iteration 5741 / 8736) loss: 0.7257951423883924\n",
      "(Iteration 5751 / 8736) loss: 0.8759106752032122\n",
      "(Iteration 5761 / 8736) loss: 0.9140863069885796\n",
      "(Iteration 5771 / 8736) loss: 0.7302376031371609\n",
      "(Iteration 5781 / 8736) loss: 0.7975651487060916\n",
      "(Iteration 5791 / 8736) loss: 0.6867309052466584\n",
      "(Iteration 5801 / 8736) loss: 0.7236004324736299\n",
      "(Iteration 5811 / 8736) loss: 0.7158628427722027\n",
      "(Iteration 5821 / 8736) loss: 0.7672812079129432\n",
      "(Iteration 5831 / 8736) loss: 0.8489960767233244\n",
      "(Iteration 5841 / 8736) loss: 0.49452050754679633\n",
      "(Iteration 5851 / 8736) loss: 0.6304416771306808\n",
      "(Iteration 5861 / 8736) loss: 0.48646866890565865\n",
      "(Iteration 5871 / 8736) loss: 0.7973809194312658\n",
      "(Iteration 5881 / 8736) loss: 0.6409689774522369\n",
      "(Iteration 5891 / 8736) loss: 1.0671128953179707\n",
      "(Iteration 5901 / 8736) loss: 0.5704325560218323\n",
      "(Iteration 5911 / 8736) loss: 0.7096982979956858\n",
      "(Iteration 5921 / 8736) loss: 0.7320192930706988\n",
      "(Iteration 5931 / 8736) loss: 0.6821567797702738\n",
      "(Iteration 5941 / 8736) loss: 0.6787755408809445\n",
      "(Iteration 5951 / 8736) loss: 0.5848070465358906\n",
      "(Iteration 5961 / 8736) loss: 0.7104507380026063\n",
      "(Iteration 5971 / 8736) loss: 0.7323077209100621\n",
      "(Iteration 5981 / 8736) loss: 0.5963789487187523\n",
      "(Iteration 5991 / 8736) loss: 0.5674547454931077\n",
      "(Iteration 6001 / 8736) loss: 0.6411695990582964\n",
      "(Epoch 11 / 16) Training Accuracy: 0.7953142857142858, Validation Accuracy: 0.7887626650291679\n",
      "(Iteration 6011 / 8736) loss: 0.7372860322469095\n",
      "(Iteration 6021 / 8736) loss: 0.6352658340346375\n",
      "(Iteration 6031 / 8736) loss: 0.699478778443406\n",
      "(Iteration 6041 / 8736) loss: 0.738494580420028\n",
      "(Iteration 6051 / 8736) loss: 0.6675281153480205\n",
      "(Iteration 6061 / 8736) loss: 0.7748255911690617\n",
      "(Iteration 6071 / 8736) loss: 0.8563646367802469\n",
      "(Iteration 6081 / 8736) loss: 0.6739565324767414\n",
      "(Iteration 6091 / 8736) loss: 0.8785210285109228\n",
      "(Iteration 6101 / 8736) loss: 0.8420012549020982\n",
      "(Iteration 6111 / 8736) loss: 0.7437959125555242\n",
      "(Iteration 6121 / 8736) loss: 0.7866166246527396\n",
      "(Iteration 6131 / 8736) loss: 0.7463859377270012\n",
      "(Iteration 6141 / 8736) loss: 0.6697275609663237\n",
      "(Iteration 6151 / 8736) loss: 0.6867802527328308\n",
      "(Iteration 6161 / 8736) loss: 0.6883944825793409\n",
      "(Iteration 6171 / 8736) loss: 0.7039319282661841\n",
      "(Iteration 6181 / 8736) loss: 0.5708780706795745\n",
      "(Iteration 6191 / 8736) loss: 0.6154078686341139\n",
      "(Iteration 6201 / 8736) loss: 0.5471461831065844\n",
      "(Iteration 6211 / 8736) loss: 0.804045486659489\n",
      "(Iteration 6221 / 8736) loss: 0.8020658592110751\n",
      "(Iteration 6231 / 8736) loss: 0.6647396972453766\n",
      "(Iteration 6241 / 8736) loss: 0.6493728422846747\n",
      "(Iteration 6251 / 8736) loss: 0.6445716699815094\n",
      "(Iteration 6261 / 8736) loss: 0.5870501204772295\n",
      "(Iteration 6271 / 8736) loss: 0.8245188685437138\n",
      "(Iteration 6281 / 8736) loss: 0.651483423940849\n",
      "(Iteration 6291 / 8736) loss: 0.7752328738625416\n",
      "(Iteration 6301 / 8736) loss: 0.7446848685614356\n",
      "(Iteration 6311 / 8736) loss: 0.6309705580774301\n",
      "(Iteration 6321 / 8736) loss: 0.741036356191307\n",
      "(Iteration 6331 / 8736) loss: 0.49880400690910526\n",
      "(Iteration 6341 / 8736) loss: 0.6869666175762655\n",
      "(Iteration 6351 / 8736) loss: 0.7112769022945943\n",
      "(Iteration 6361 / 8736) loss: 0.6717061986974591\n",
      "(Iteration 6371 / 8736) loss: 0.7137748556993619\n",
      "(Iteration 6381 / 8736) loss: 0.7073247033980463\n",
      "(Iteration 6391 / 8736) loss: 0.5839597345072187\n",
      "(Iteration 6401 / 8736) loss: 0.44678613434142905\n",
      "(Iteration 6411 / 8736) loss: 0.7737867336034622\n",
      "(Iteration 6421 / 8736) loss: 0.4118388721389969\n",
      "(Iteration 6431 / 8736) loss: 0.5544494488368358\n",
      "(Iteration 6441 / 8736) loss: 0.8479843678604163\n",
      "(Iteration 6451 / 8736) loss: 0.6167955874124957\n",
      "(Iteration 6461 / 8736) loss: 0.6350881979477438\n",
      "(Iteration 6471 / 8736) loss: 0.8305272789827729\n",
      "(Iteration 6481 / 8736) loss: 0.6660343215302571\n",
      "(Iteration 6491 / 8736) loss: 0.6902102879992493\n",
      "(Iteration 6501 / 8736) loss: 0.6145738360884082\n",
      "(Iteration 6511 / 8736) loss: 0.9583571410015007\n",
      "(Iteration 6521 / 8736) loss: 0.4433602720324811\n",
      "(Iteration 6531 / 8736) loss: 0.6431315133235883\n",
      "(Iteration 6541 / 8736) loss: 0.9086141153097176\n",
      "(Iteration 6551 / 8736) loss: 0.788004780540603\n",
      "(Epoch 12 / 16) Training Accuracy: 0.8015, Validation Accuracy: 0.7955173472520725\n",
      "(Iteration 6561 / 8736) loss: 0.8117532885399007\n",
      "(Iteration 6571 / 8736) loss: 0.7200178531292488\n",
      "(Iteration 6581 / 8736) loss: 0.6293759866359976\n",
      "(Iteration 6591 / 8736) loss: 0.6054269417349214\n",
      "(Iteration 6601 / 8736) loss: 0.6961441348700664\n",
      "(Iteration 6611 / 8736) loss: 0.6344932113443074\n",
      "(Iteration 6621 / 8736) loss: 0.6353379325808952\n",
      "(Iteration 6631 / 8736) loss: 0.7461270032567393\n",
      "(Iteration 6641 / 8736) loss: 0.7755576593303527\n",
      "(Iteration 6651 / 8736) loss: 0.751359345852467\n",
      "(Iteration 6661 / 8736) loss: 0.8258844250079037\n",
      "(Iteration 6671 / 8736) loss: 0.5268463206395055\n",
      "(Iteration 6681 / 8736) loss: 0.8372865165603676\n",
      "(Iteration 6691 / 8736) loss: 0.49791294057581126\n",
      "(Iteration 6701 / 8736) loss: 0.7553823341197121\n",
      "(Iteration 6711 / 8736) loss: 0.5966734733145592\n",
      "(Iteration 6721 / 8736) loss: 0.6061147193766042\n",
      "(Iteration 6731 / 8736) loss: 0.5411284995216994\n",
      "(Iteration 6741 / 8736) loss: 0.7184162683716434\n",
      "(Iteration 6751 / 8736) loss: 0.8792632309491932\n",
      "(Iteration 6761 / 8736) loss: 0.8425867527712616\n",
      "(Iteration 6771 / 8736) loss: 0.5978162449274397\n",
      "(Iteration 6781 / 8736) loss: 0.5447063809350039\n",
      "(Iteration 6791 / 8736) loss: 0.5827716457700994\n",
      "(Iteration 6801 / 8736) loss: 0.7531522699571398\n",
      "(Iteration 6811 / 8736) loss: 0.741419806585944\n",
      "(Iteration 6821 / 8736) loss: 0.5078126322982507\n",
      "(Iteration 6831 / 8736) loss: 0.5888468907286518\n",
      "(Iteration 6841 / 8736) loss: 0.7451888512296287\n",
      "(Iteration 6851 / 8736) loss: 0.8113688009771955\n",
      "(Iteration 6861 / 8736) loss: 0.5300358210643638\n",
      "(Iteration 6871 / 8736) loss: 0.7907108808095561\n",
      "(Iteration 6881 / 8736) loss: 0.6771606971866355\n",
      "(Iteration 6891 / 8736) loss: 0.4911100440469661\n",
      "(Iteration 6901 / 8736) loss: 0.6127828045334657\n",
      "(Iteration 6911 / 8736) loss: 0.5897395361705311\n",
      "(Iteration 6921 / 8736) loss: 0.6307941064750057\n",
      "(Iteration 6931 / 8736) loss: 0.6473818834636546\n",
      "(Iteration 6941 / 8736) loss: 1.026983236633181\n",
      "(Iteration 6951 / 8736) loss: 0.6676298458894468\n",
      "(Iteration 6961 / 8736) loss: 0.6774659320502244\n",
      "(Iteration 6971 / 8736) loss: 0.6503379355539622\n",
      "(Iteration 6981 / 8736) loss: 0.7376710555552255\n",
      "(Iteration 6991 / 8736) loss: 0.706257778298964\n",
      "(Iteration 7001 / 8736) loss: 0.5765911952091581\n",
      "(Iteration 7011 / 8736) loss: 0.8302432739795521\n",
      "(Iteration 7021 / 8736) loss: 0.6541293345080438\n",
      "(Iteration 7031 / 8736) loss: 0.6396779089458273\n",
      "(Iteration 7041 / 8736) loss: 0.6649547277562934\n",
      "(Iteration 7051 / 8736) loss: 0.7790687206012151\n",
      "(Iteration 7061 / 8736) loss: 0.6640100116767843\n",
      "(Iteration 7071 / 8736) loss: 0.6185014042907458\n",
      "(Iteration 7081 / 8736) loss: 0.61711544276402\n",
      "(Iteration 7091 / 8736) loss: 0.6896260790559408\n",
      "(Epoch 13 / 16) Training Accuracy: 0.8097285714285715, Validation Accuracy: 0.8056493705864293\n",
      "(Iteration 7101 / 8736) loss: 0.5491667565262645\n",
      "(Iteration 7111 / 8736) loss: 0.5878114308116829\n",
      "(Iteration 7121 / 8736) loss: 0.6595224859196502\n",
      "(Iteration 7131 / 8736) loss: 0.6394018737312801\n",
      "(Iteration 7141 / 8736) loss: 0.7781843601646221\n",
      "(Iteration 7151 / 8736) loss: 0.6787093892541569\n",
      "(Iteration 7161 / 8736) loss: 0.7890895665408955\n",
      "(Iteration 7171 / 8736) loss: 0.6790923609899499\n",
      "(Iteration 7181 / 8736) loss: 0.607127916564131\n",
      "(Iteration 7191 / 8736) loss: 0.7570232469532275\n",
      "(Iteration 7201 / 8736) loss: 0.7108998370445156\n",
      "(Iteration 7211 / 8736) loss: 0.6096478301025446\n",
      "(Iteration 7221 / 8736) loss: 0.7267074549559277\n",
      "(Iteration 7231 / 8736) loss: 0.6645768931807596\n",
      "(Iteration 7241 / 8736) loss: 0.6889256513033787\n",
      "(Iteration 7251 / 8736) loss: 0.6210380147332589\n",
      "(Iteration 7261 / 8736) loss: 0.8062789786830313\n",
      "(Iteration 7271 / 8736) loss: 0.7195896333105124\n",
      "(Iteration 7281 / 8736) loss: 0.6228259463565025\n",
      "(Iteration 7291 / 8736) loss: 0.6745305871920183\n",
      "(Iteration 7301 / 8736) loss: 0.5572038364890943\n",
      "(Iteration 7311 / 8736) loss: 0.7324666714038643\n",
      "(Iteration 7321 / 8736) loss: 0.686906307461116\n",
      "(Iteration 7331 / 8736) loss: 0.4598585446830969\n",
      "(Iteration 7341 / 8736) loss: 0.7283816386469386\n",
      "(Iteration 7351 / 8736) loss: 0.6747111520215316\n",
      "(Iteration 7361 / 8736) loss: 0.823151746941895\n",
      "(Iteration 7371 / 8736) loss: 0.530229215146629\n",
      "(Iteration 7381 / 8736) loss: 0.9238112482057711\n",
      "(Iteration 7391 / 8736) loss: 0.6281989070360379\n",
      "(Iteration 7401 / 8736) loss: 0.6132409641043292\n",
      "(Iteration 7411 / 8736) loss: 0.6739653573136672\n",
      "(Iteration 7421 / 8736) loss: 0.922003272871553\n",
      "(Iteration 7431 / 8736) loss: 0.6391199382094629\n",
      "(Iteration 7441 / 8736) loss: 0.5435013002030379\n",
      "(Iteration 7451 / 8736) loss: 0.815928144783353\n",
      "(Iteration 7461 / 8736) loss: 0.6090993331732859\n",
      "(Iteration 7471 / 8736) loss: 0.6258526209162244\n",
      "(Iteration 7481 / 8736) loss: 0.6241804406466603\n",
      "(Iteration 7491 / 8736) loss: 0.6604849268159853\n",
      "(Iteration 7501 / 8736) loss: 0.693588519948102\n",
      "(Iteration 7511 / 8736) loss: 0.5694263148790241\n",
      "(Iteration 7521 / 8736) loss: 0.8025237564866017\n",
      "(Iteration 7531 / 8736) loss: 0.5359355393601776\n",
      "(Iteration 7541 / 8736) loss: 0.5971380977537749\n",
      "(Iteration 7551 / 8736) loss: 0.8777254407714555\n",
      "(Iteration 7561 / 8736) loss: 0.6560206278844576\n",
      "(Iteration 7571 / 8736) loss: 0.586276748477203\n",
      "(Iteration 7581 / 8736) loss: 0.5514735723571758\n",
      "(Iteration 7591 / 8736) loss: 0.628801124272594\n",
      "(Iteration 7601 / 8736) loss: 0.7098240057846392\n",
      "(Iteration 7611 / 8736) loss: 0.7341121901354131\n",
      "(Iteration 7621 / 8736) loss: 0.5592729037970968\n",
      "(Iteration 7631 / 8736) loss: 0.6850865809775538\n",
      "(Iteration 7641 / 8736) loss: 0.737112619977783\n",
      "(Epoch 14 / 16) Training Accuracy: 0.8159714285714286, Validation Accuracy: 0.8108688977586737\n",
      "(Iteration 7651 / 8736) loss: 0.5793088157662931\n",
      "(Iteration 7661 / 8736) loss: 0.6224197128636645\n",
      "(Iteration 7671 / 8736) loss: 0.5858038496350872\n",
      "(Iteration 7681 / 8736) loss: 0.5094806439553081\n",
      "(Iteration 7691 / 8736) loss: 0.5189889195375461\n",
      "(Iteration 7701 / 8736) loss: 0.7684290836161869\n",
      "(Iteration 7711 / 8736) loss: 0.6751431376326743\n",
      "(Iteration 7721 / 8736) loss: 0.7121526955508276\n",
      "(Iteration 7731 / 8736) loss: 0.721280821593623\n",
      "(Iteration 7741 / 8736) loss: 0.5538478564745861\n",
      "(Iteration 7751 / 8736) loss: 0.5995050418114799\n",
      "(Iteration 7761 / 8736) loss: 0.6929762408981621\n",
      "(Iteration 7771 / 8736) loss: 0.7210733046588854\n",
      "(Iteration 7781 / 8736) loss: 0.599546961101167\n",
      "(Iteration 7791 / 8736) loss: 0.5632629547889637\n",
      "(Iteration 7801 / 8736) loss: 0.8286224757302219\n",
      "(Iteration 7811 / 8736) loss: 0.5521415635572676\n",
      "(Iteration 7821 / 8736) loss: 0.5530584916678378\n",
      "(Iteration 7831 / 8736) loss: 0.4237702807966764\n",
      "(Iteration 7841 / 8736) loss: 0.5152093803742976\n",
      "(Iteration 7851 / 8736) loss: 0.6292220469966714\n",
      "(Iteration 7861 / 8736) loss: 0.7695662237876214\n",
      "(Iteration 7871 / 8736) loss: 0.5947931426298287\n",
      "(Iteration 7881 / 8736) loss: 0.6169673236836807\n",
      "(Iteration 7891 / 8736) loss: 0.46865001891804847\n",
      "(Iteration 7901 / 8736) loss: 0.5422348113760187\n",
      "(Iteration 7911 / 8736) loss: 0.518794380664988\n",
      "(Iteration 7921 / 8736) loss: 0.7087893542460186\n",
      "(Iteration 7931 / 8736) loss: 0.6637125059912364\n",
      "(Iteration 7941 / 8736) loss: 0.6195288731186958\n",
      "(Iteration 7951 / 8736) loss: 0.6044513763882563\n",
      "(Iteration 7961 / 8736) loss: 0.7777749325942351\n",
      "(Iteration 7971 / 8736) loss: 0.5033946960738527\n",
      "(Iteration 7981 / 8736) loss: 0.6022577463957537\n",
      "(Iteration 7991 / 8736) loss: 0.43989759006790424\n",
      "(Iteration 8001 / 8736) loss: 0.7704343795820908\n",
      "(Iteration 8011 / 8736) loss: 0.7585602029330318\n",
      "(Iteration 8021 / 8736) loss: 0.6575258560977175\n",
      "(Iteration 8031 / 8736) loss: 0.599986237808629\n",
      "(Iteration 8041 / 8736) loss: 0.5442364213012575\n",
      "(Iteration 8051 / 8736) loss: 0.6347389554302272\n",
      "(Iteration 8061 / 8736) loss: 0.5142320203713345\n",
      "(Iteration 8071 / 8736) loss: 0.5424721869561117\n",
      "(Iteration 8081 / 8736) loss: 0.8123889783095997\n",
      "(Iteration 8091 / 8736) loss: 0.6254432060224256\n",
      "(Iteration 8101 / 8736) loss: 1.154609842520295\n",
      "(Iteration 8111 / 8736) loss: 0.6201321292097529\n",
      "(Iteration 8121 / 8736) loss: 0.6963514778713361\n",
      "(Iteration 8131 / 8736) loss: 0.5815942113077682\n",
      "(Iteration 8141 / 8736) loss: 0.6437994093714056\n",
      "(Iteration 8151 / 8736) loss: 0.747455725943577\n",
      "(Iteration 8161 / 8736) loss: 0.532358950934325\n",
      "(Iteration 8171 / 8736) loss: 0.5210347728313778\n",
      "(Iteration 8181 / 8736) loss: 0.5029925565017472\n",
      "(Epoch 15 / 16) Training Accuracy: 0.8183285714285714, Validation Accuracy: 0.8176235799815781\n",
      "(Iteration 8191 / 8736) loss: 0.5326592735771214\n",
      "(Iteration 8201 / 8736) loss: 0.5913120204014061\n",
      "(Iteration 8211 / 8736) loss: 0.6554708590643442\n",
      "(Iteration 8221 / 8736) loss: 0.8222353641379568\n",
      "(Iteration 8231 / 8736) loss: 0.625376670480634\n",
      "(Iteration 8241 / 8736) loss: 0.505339591038311\n",
      "(Iteration 8251 / 8736) loss: 0.4770867301387376\n",
      "(Iteration 8261 / 8736) loss: 0.8919326827789869\n",
      "(Iteration 8271 / 8736) loss: 0.7865421385833804\n",
      "(Iteration 8281 / 8736) loss: 0.6227081280378142\n",
      "(Iteration 8291 / 8736) loss: 0.6560186147262858\n",
      "(Iteration 8301 / 8736) loss: 0.5716834898404964\n",
      "(Iteration 8311 / 8736) loss: 0.8146341862564024\n",
      "(Iteration 8321 / 8736) loss: 0.6539427132577333\n",
      "(Iteration 8331 / 8736) loss: 0.5544168757373684\n",
      "(Iteration 8341 / 8736) loss: 0.6748356643757547\n",
      "(Iteration 8351 / 8736) loss: 0.580180752388165\n",
      "(Iteration 8361 / 8736) loss: 0.6771744732891812\n",
      "(Iteration 8371 / 8736) loss: 0.5034432158047122\n",
      "(Iteration 8381 / 8736) loss: 0.5586164329940967\n",
      "(Iteration 8391 / 8736) loss: 0.6551249853483686\n",
      "(Iteration 8401 / 8736) loss: 0.5966553192776943\n",
      "(Iteration 8411 / 8736) loss: 0.6874982097898448\n",
      "(Iteration 8421 / 8736) loss: 0.6634963620399317\n",
      "(Iteration 8431 / 8736) loss: 0.6424459849160148\n",
      "(Iteration 8441 / 8736) loss: 0.7713006691048486\n",
      "(Iteration 8451 / 8736) loss: 0.5578987152494368\n",
      "(Iteration 8461 / 8736) loss: 0.636354808419505\n",
      "(Iteration 8471 / 8736) loss: 0.7587318847870221\n",
      "(Iteration 8481 / 8736) loss: 0.6206746742044831\n",
      "(Iteration 8491 / 8736) loss: 0.560590634197008\n",
      "(Iteration 8501 / 8736) loss: 0.5526358911848736\n",
      "(Iteration 8511 / 8736) loss: 0.6342824040824522\n",
      "(Iteration 8521 / 8736) loss: 0.6902351571201177\n",
      "(Iteration 8531 / 8736) loss: 0.7479213511511841\n",
      "(Iteration 8541 / 8736) loss: 0.5696990358794545\n",
      "(Iteration 8551 / 8736) loss: 0.572616360522653\n",
      "(Iteration 8561 / 8736) loss: 0.519741840981092\n",
      "(Iteration 8571 / 8736) loss: 0.725358604334001\n",
      "(Iteration 8581 / 8736) loss: 0.7152951330528344\n",
      "(Iteration 8591 / 8736) loss: 0.5185178562904075\n",
      "(Iteration 8601 / 8736) loss: 0.5627539598643939\n",
      "(Iteration 8611 / 8736) loss: 0.8049840488750921\n",
      "(Iteration 8621 / 8736) loss: 0.5634039966775649\n",
      "(Iteration 8631 / 8736) loss: 0.6682437327350477\n",
      "(Iteration 8641 / 8736) loss: 0.849631936426159\n",
      "(Iteration 8651 / 8736) loss: 0.6809368267342972\n",
      "(Iteration 8661 / 8736) loss: 0.6498967090196869\n",
      "(Iteration 8671 / 8736) loss: 0.6624125032147826\n",
      "(Iteration 8681 / 8736) loss: 0.6261055766020315\n",
      "(Iteration 8691 / 8736) loss: 0.5537015751263734\n",
      "(Iteration 8701 / 8736) loss: 0.6840633445898671\n",
      "(Iteration 8711 / 8736) loss: 0.6555548973373746\n",
      "(Iteration 8721 / 8736) loss: 0.6220715959317439\n",
      "(Iteration 8731 / 8736) loss: 0.8358048809946479\n",
      "(Epoch 16 / 16) Training Accuracy: 0.8253285714285714, Validation Accuracy: 0.8225360761436905\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "model = SmallConvolutionalNetwork()\n",
    "loss_f = cross_entropy()\n",
    "\n",
    "\n",
    "results = None\n",
    "#############################################################################\n",
    "# TODO: Use the train_net function you completed to train a network         #\n",
    "#############################################################################\n",
    "optimizer =  Adam(model.net, 3e-4)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 16\n",
    "lr_decay = .999\n",
    "lr_decay_every = 10\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "results = train_net(data_dict, model, loss_f, optimizer, batch_size, epochs, \n",
    "                    lr_decay, lr_decay_every, show_every=10, verbose=True)\n",
    "opt_params, loss_hist, train_acc_hist, val_acc_hist = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"save_new.pkl\", \"wb\") as result:\n",
    "  result.write(pickle.dumps(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'conv1_w': array([[[[-1.02509461e-01,  7.55769935e-02,  2.02150191e-01,\n",
       "            -8.64808937e-02, -1.47261235e-01, -8.33692413e-02,\n",
       "            -2.24511258e-01, -8.15010328e-02],\n",
       "           [-5.40068093e-02,  4.76273819e-02,  1.96840868e-01,\n",
       "            -1.25876354e-01, -8.56156753e-02, -1.40164022e-01,\n",
       "            -2.05916842e-01, -5.07163806e-02],\n",
       "           [ 7.29720825e-03,  7.41368437e-02,  2.44050580e-01,\n",
       "            -3.83936343e-02, -9.25298014e-02, -3.98324362e-02,\n",
       "            -1.89931827e-01, -5.20270879e-02]],\n",
       "  \n",
       "          [[ 1.40301486e-02,  4.80076662e-02,  1.61993122e-01,\n",
       "            -1.66356953e-01, -5.13969770e-02, -1.26339265e-01,\n",
       "            -2.02185053e-01, -5.93954900e-02],\n",
       "           [ 8.57938889e-03,  5.35812792e-02,  1.34877087e-01,\n",
       "            -1.98961898e-01, -2.87712732e-02, -1.06219319e-01,\n",
       "            -2.43507883e-01,  3.60025896e-02],\n",
       "           [ 4.28341303e-02,  6.33601881e-03,  1.24154816e-01,\n",
       "            -1.03518936e-01, -3.26190086e-02, -6.87552560e-02,\n",
       "            -1.53192935e-01, -2.05470224e-02]],\n",
       "  \n",
       "          [[ 1.26379403e-01,  1.45325822e-01,  5.29473124e-02,\n",
       "            -1.40874473e-01,  4.16281647e-02, -7.47481792e-02,\n",
       "            -1.83694026e-01,  2.54722459e-02],\n",
       "           [ 1.36518908e-01,  1.42289791e-01,  6.39492441e-02,\n",
       "            -1.50022594e-01,  1.13429303e-02, -5.34360353e-02,\n",
       "            -2.11452260e-01,  1.76191005e-02],\n",
       "           [ 1.58167692e-01,  9.87776715e-02,  6.95973753e-02,\n",
       "            -8.58270659e-02, -1.23445202e-02, -2.97269767e-02,\n",
       "            -1.72814037e-01, -4.65571746e-02]],\n",
       "  \n",
       "          [[ 1.04659242e-01,  1.04169083e-01, -3.94019186e-02,\n",
       "             1.71340804e-02,  1.23170723e-02, -2.01165812e-02,\n",
       "            -1.62771468e-01, -1.24527558e-01],\n",
       "           [ 1.28236949e-01,  1.20632656e-01, -1.64143540e-02,\n",
       "            -3.60293284e-02,  3.72374367e-02, -5.08337973e-02,\n",
       "            -1.97763451e-01, -6.53064903e-02],\n",
       "           [ 1.61119559e-01,  1.08321397e-01,  2.02215420e-02,\n",
       "             1.78537998e-02,  3.37830513e-02,  8.74989869e-03,\n",
       "            -1.34679516e-01, -1.05787028e-01]],\n",
       "  \n",
       "          [[-7.82875779e-02,  5.93224980e-02,  1.20447299e-02,\n",
       "             1.68736984e-01,  1.92020639e-02, -7.22693981e-02,\n",
       "            -4.57993959e-02, -2.53018567e-01],\n",
       "           [-2.90492308e-02,  9.87890044e-02, -3.74155103e-02,\n",
       "             8.72689580e-02,  3.76496437e-02, -7.66343983e-02,\n",
       "            -1.08425162e-01, -2.16231077e-01],\n",
       "           [-2.85379217e-02,  7.64217846e-02,  3.55488589e-02,\n",
       "             2.13918460e-01, -2.03291086e-02, -4.98355291e-02,\n",
       "             1.18818444e-02, -3.75478368e-01]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.63365599e-01, -7.35199015e-03,  7.71278113e-02,\n",
       "             3.35146949e-02, -1.56634384e-01, -2.42092797e-01,\n",
       "            -1.61497746e-02, -3.28166898e-02],\n",
       "           [-1.70261039e-01,  7.47573687e-03,  9.14320976e-02,\n",
       "            -5.97967232e-02, -2.07382933e-01, -2.31525571e-01,\n",
       "            -2.09578595e-02, -1.50745396e-02],\n",
       "           [-1.49204043e-01,  3.55880182e-02,  1.50984803e-01,\n",
       "            -9.83150849e-03, -1.93099540e-01, -2.07344297e-01,\n",
       "            -1.17642868e-02, -4.43123565e-02]],\n",
       "  \n",
       "          [[-1.73777698e-02,  3.29378369e-02, -2.78735026e-02,\n",
       "            -4.07883110e-02, -9.78211527e-02, -2.03490677e-01,\n",
       "            -6.62495829e-02,  8.17012771e-02],\n",
       "           [-7.32637419e-02,  1.06372858e-02, -7.25227948e-02,\n",
       "            -1.18988664e-01, -8.51870801e-02, -2.19064725e-01,\n",
       "            -5.58784525e-02,  1.01038666e-01],\n",
       "           [-2.78006271e-02,  3.29650865e-02, -3.34197815e-02,\n",
       "            -6.55560235e-02, -8.19553704e-02, -2.06765544e-01,\n",
       "            -5.35346798e-02,  2.08796845e-02]],\n",
       "  \n",
       "          [[ 8.54474266e-02,  1.18969822e-01, -1.27103725e-01,\n",
       "            -6.40091797e-02, -1.69580205e-02, -1.29622999e-01,\n",
       "            -5.96080641e-02,  1.70583902e-01],\n",
       "           [ 8.46281244e-02,  1.22723195e-01, -1.52072477e-01,\n",
       "            -1.06031932e-01,  8.90482084e-04, -1.05503981e-01,\n",
       "            -5.72796248e-02,  1.73794628e-01],\n",
       "           [ 7.73397424e-02,  6.98517325e-02, -1.16872397e-01,\n",
       "            -7.10728476e-02, -1.27970625e-02, -1.22632998e-01,\n",
       "            -7.08890750e-02,  9.95866143e-02]],\n",
       "  \n",
       "          [[ 1.17791008e-01,  2.07643647e-01, -1.33001226e-01,\n",
       "            -1.84942780e-02,  5.35241369e-02, -7.05495689e-02,\n",
       "            -4.92769806e-02,  8.78635148e-02],\n",
       "           [ 1.38763662e-01,  2.08186137e-01, -1.40984347e-01,\n",
       "             1.68285486e-02,  6.99348697e-02, -8.03373372e-02,\n",
       "            -6.49892119e-02,  1.29597948e-01],\n",
       "           [ 1.32245337e-01,  2.02533323e-01, -1.19483024e-01,\n",
       "             8.03204086e-02,  5.56169601e-02, -1.18524220e-01,\n",
       "            -4.34772755e-02,  8.70010822e-02]],\n",
       "  \n",
       "          [[ 5.00063090e-02,  2.41965768e-01, -9.43893585e-02,\n",
       "             2.21219641e-01,  7.02378631e-02, -9.14421922e-02,\n",
       "             1.53025526e-02, -1.06353261e-01],\n",
       "           [ 7.30956606e-02,  2.17790831e-01, -1.35353526e-01,\n",
       "             1.48958152e-01,  8.73428459e-02, -9.01134572e-02,\n",
       "            -3.43492222e-02, -9.11286697e-03],\n",
       "           [ 5.08845097e-02,  2.19907055e-01, -4.85817836e-02,\n",
       "             2.24957057e-01,  1.08789202e-01, -1.21707060e-01,\n",
       "             6.79024186e-02, -1.34278546e-01]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.65136583e-01, -1.67439582e-01,  2.71164733e-02,\n",
       "             7.52589949e-02, -1.80792290e-01, -1.59204937e-01,\n",
       "             7.18341760e-02, -9.16395514e-02],\n",
       "           [-2.28320833e-01, -1.41431626e-01,  1.16829505e-01,\n",
       "             7.12108748e-02, -2.13670445e-01, -1.79206424e-01,\n",
       "             8.58651392e-02, -3.18173286e-02],\n",
       "           [-1.41805904e-01, -1.59306066e-01,  8.41654683e-02,\n",
       "             1.22143282e-01, -1.71283041e-01, -1.37671054e-01,\n",
       "             4.81413004e-02, -6.72396292e-02]],\n",
       "  \n",
       "          [[-3.09994008e-02, -1.74054159e-01, -1.02475907e-01,\n",
       "            -8.98968693e-03, -6.69737344e-02, -7.39008842e-02,\n",
       "            -1.31484138e-02,  7.04244443e-02],\n",
       "           [-4.22988499e-02, -1.60572301e-01, -1.38998820e-01,\n",
       "            -6.43627183e-02, -7.39090807e-02, -1.05647895e-01,\n",
       "            -2.32557193e-03,  1.13892359e-01],\n",
       "           [-7.16096513e-02, -1.74533664e-01, -1.32603996e-01,\n",
       "            -4.01348205e-02, -9.12253973e-02, -9.09332762e-02,\n",
       "            -3.64907998e-02,  8.82977693e-02]],\n",
       "  \n",
       "          [[ 4.44531256e-02, -8.82864740e-02, -1.99939983e-01,\n",
       "            -2.24777890e-02,  3.71130115e-02,  9.86814806e-03,\n",
       "            -4.00679967e-02,  2.12212134e-01],\n",
       "           [ 1.05834302e-01, -7.20705893e-02, -1.97913007e-01,\n",
       "            -5.17814880e-02,  3.42334669e-02,  1.20466979e-02,\n",
       "            -1.73236022e-02,  2.58629959e-01],\n",
       "           [ 8.00994714e-02, -5.66963585e-02, -1.82949788e-01,\n",
       "            -1.71192862e-02,  3.11275253e-02,  1.16952407e-02,\n",
       "             1.36219271e-02,  1.69379505e-01]],\n",
       "  \n",
       "          [[ 1.03847909e-01,  1.07131399e-02, -1.39177176e-01,\n",
       "             2.93982878e-02,  9.73620111e-02,  8.48246825e-02,\n",
       "            -9.41456976e-03,  1.91504315e-01],\n",
       "           [ 1.25223342e-01, -1.89909608e-02, -2.07863443e-01,\n",
       "            -2.44563373e-02,  1.27701121e-01,  8.60968081e-02,\n",
       "            -5.03274790e-02,  2.37897301e-01],\n",
       "           [ 1.44612241e-01,  5.68301593e-03, -1.54289351e-01,\n",
       "             8.61620219e-02,  1.01792740e-01,  6.43464910e-02,\n",
       "             1.12851573e-03,  1.34575276e-01]],\n",
       "  \n",
       "          [[ 7.89019446e-02,  6.66682429e-02, -2.95967265e-02,\n",
       "             1.37790813e-01,  1.49265769e-01,  5.34395798e-02,\n",
       "             2.67636686e-02, -7.39436739e-03],\n",
       "           [ 6.98046260e-02,  6.78734615e-02, -8.18780566e-02,\n",
       "             1.42493613e-01,  1.63240309e-01,  8.80593585e-02,\n",
       "            -4.14520228e-03,  8.40833298e-02],\n",
       "           [ 8.23672913e-02,  3.12385469e-02, -5.03098810e-02,\n",
       "             1.70047123e-01,  1.38132286e-01,  5.77371013e-02,\n",
       "             1.14278940e-02, -5.14320549e-02]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.41912240e-01, -1.59744027e-01,  2.92879844e-02,\n",
       "             1.54274072e-01, -1.65591755e-01,  1.20526766e-02,\n",
       "             1.56982552e-01, -6.32446956e-02],\n",
       "           [-1.53482682e-01, -1.41792838e-01,  6.97145340e-02,\n",
       "             1.05859555e-01, -1.34772294e-01,  2.53284320e-02,\n",
       "             1.19321217e-01, -1.27913964e-02],\n",
       "           [-1.27523059e-01, -1.43504737e-01,  1.07548443e-01,\n",
       "             9.21980841e-02, -1.05506257e-01,  2.90527198e-03,\n",
       "             8.68384126e-02, -7.47308666e-02]],\n",
       "  \n",
       "          [[-4.99712400e-02, -2.35424074e-01, -1.08845405e-01,\n",
       "             2.66355082e-02, -4.30012777e-02,  7.34108340e-02,\n",
       "             8.27368238e-02,  9.85031387e-02],\n",
       "           [-6.20241239e-02, -2.21800706e-01, -1.04641944e-01,\n",
       "            -1.65817070e-02, -6.08134951e-02,  9.96443345e-02,\n",
       "             7.56757456e-02,  1.11716475e-01],\n",
       "           [-5.82784976e-03, -2.18561121e-01, -8.81627939e-02,\n",
       "            -2.45144291e-02, -3.44186178e-02,  1.02732937e-01,\n",
       "             1.88670308e-02,  2.45821682e-02]],\n",
       "  \n",
       "          [[ 4.71550013e-02, -2.06122625e-01, -1.42365895e-01,\n",
       "            -4.01970718e-02,  4.66749002e-02,  2.04331965e-01,\n",
       "             5.25966126e-02,  1.22287310e-01],\n",
       "           [ 6.46037596e-02, -2.12219125e-01, -1.61466177e-01,\n",
       "            -1.11952175e-01,  2.86482276e-02,  2.32372668e-01,\n",
       "             2.51636805e-02,  1.89036030e-01],\n",
       "           [ 5.08657145e-02, -2.11237632e-01, -1.31654664e-01,\n",
       "            -6.96124624e-03,  5.14290669e-02,  1.78043263e-01,\n",
       "             7.16703930e-03,  1.42667948e-01]],\n",
       "  \n",
       "          [[ 7.84465010e-02, -1.90208885e-01, -1.05197791e-01,\n",
       "            -1.59456398e-02,  1.21162135e-01,  2.21102625e-01,\n",
       "             2.80483659e-02,  1.23801759e-01],\n",
       "           [ 1.23769973e-01, -1.73014989e-01, -1.45944167e-01,\n",
       "            -4.98223717e-02,  1.62376594e-01,  2.57865592e-01,\n",
       "            -2.96450203e-02,  1.98311993e-01],\n",
       "           [ 1.28933226e-01, -1.51074262e-01, -9.89649174e-02,\n",
       "            -4.13005323e-02,  1.01532534e-01,  2.08246607e-01,\n",
       "             7.34467381e-03,  7.87215072e-02]],\n",
       "  \n",
       "          [[ 2.69257774e-02, -8.67686565e-02, -1.88487099e-02,\n",
       "             5.25736721e-02,  1.54419780e-01,  2.30154271e-01,\n",
       "            -6.50542398e-02, -8.80420636e-02],\n",
       "           [ 8.37513008e-02, -1.15043529e-01, -5.40460272e-03,\n",
       "             2.58181947e-02,  2.07554597e-01,  2.10793972e-01,\n",
       "            -1.13228678e-02,  4.93686058e-02],\n",
       "           [ 6.08499474e-02, -8.57987292e-02,  1.60029542e-02,\n",
       "             3.77092816e-02,  1.38341556e-01,  1.74454752e-01,\n",
       "            -2.25038467e-02, -1.31719542e-01]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.37093970e-01,  1.30880698e-01,  2.16145514e-02,\n",
       "             1.61954587e-01, -9.77477148e-02,  3.58660736e-02,\n",
       "             2.54876340e-01, -3.08522823e-02],\n",
       "           [-9.71769273e-02,  1.41553746e-01,  1.33135255e-01,\n",
       "             1.23225530e-01, -1.31165421e-01,  2.24312728e-04,\n",
       "             2.37325963e-01, -2.62588009e-02],\n",
       "           [-9.25380234e-02,  1.52401950e-01,  1.46088566e-01,\n",
       "             1.23746613e-01, -6.16527168e-02,  5.08432850e-03,\n",
       "             2.17919324e-01, -6.12228145e-02]],\n",
       "  \n",
       "          [[-4.15178686e-02,  3.06197558e-02, -3.88193644e-02,\n",
       "            -6.70322700e-03, -5.29614421e-02,  3.06878265e-02,\n",
       "             1.81983074e-01,  1.10495578e-03],\n",
       "           [-4.05830927e-02,  5.82954648e-03,  4.80790418e-05,\n",
       "             9.96517477e-03, -1.63189041e-02,  5.23576528e-02,\n",
       "             1.99700338e-01,  3.93838846e-02],\n",
       "           [-1.02303657e-01,  1.82853311e-02, -8.51119942e-03,\n",
       "             4.98269310e-03, -8.35362601e-03,  3.73644345e-02,\n",
       "             1.78229586e-01, -6.53920990e-02]],\n",
       "  \n",
       "          [[-2.37112833e-02, -1.31035298e-02, -4.74258806e-02,\n",
       "            -1.06885363e-01,  5.47813696e-02,  1.17334239e-01,\n",
       "             1.45800814e-01,  4.62193654e-02],\n",
       "           [ 2.70098413e-03, -2.23855990e-02, -3.86239414e-02,\n",
       "            -6.70785480e-02,  3.61935045e-02,  9.02757718e-02,\n",
       "             1.32399179e-01,  9.05665871e-02],\n",
       "           [-3.13764847e-02,  3.50924534e-02, -8.15938599e-02,\n",
       "            -8.09406758e-02,  5.77929444e-02,  1.15156968e-01,\n",
       "             1.33201134e-01, -4.08897107e-02]],\n",
       "  \n",
       "          [[-6.87360254e-02, -3.46407483e-02, -1.99062964e-02,\n",
       "            -1.33490822e-01,  8.49985149e-02,  1.65570817e-01,\n",
       "             8.99070950e-02, -8.64766155e-02],\n",
       "           [-3.91632692e-02, -1.41755727e-03, -6.64022513e-02,\n",
       "            -1.15543563e-01,  1.27118379e-01,  1.95345122e-01,\n",
       "             6.06747296e-02, -6.58405276e-03],\n",
       "           [-4.39764518e-02,  3.99130254e-02,  4.33461656e-03,\n",
       "            -7.65395171e-02,  1.01503014e-01,  1.42846989e-01,\n",
       "             1.29939867e-01, -1.17933823e-01]],\n",
       "  \n",
       "          [[-1.50268093e-01,  2.05456737e-02,  3.74002281e-02,\n",
       "            -1.00097796e-01,  4.10206320e-02,  1.01763242e-01,\n",
       "             5.01053639e-02, -3.04075769e-01],\n",
       "           [-1.16850263e-01,  3.29044568e-02,  1.49967570e-02,\n",
       "            -1.35278416e-01,  1.08360917e-01,  1.50663762e-01,\n",
       "             8.94275889e-02, -2.12134970e-01],\n",
       "           [-1.29361437e-01,  7.89016710e-02,  6.22938889e-02,\n",
       "            -5.43998000e-02,  3.79304395e-02,  6.29183084e-02,\n",
       "             1.19742618e-01, -3.60947767e-01]]]]),\n",
       "  'conv1_b': array([ 0.28344512,  0.02999126,  0.02751623, -0.03512319,  0.19762636,\n",
       "          0.01943421,  0.03399402,  0.13418208]),\n",
       "  'conv2_w': array([[[[-4.94839798e-02,  4.18981426e-02, -1.18403966e-01,\n",
       "            -1.32981993e-01],\n",
       "           [ 6.77024519e-02,  6.16586321e-02,  1.80029904e-01,\n",
       "             1.70267476e-02],\n",
       "           [ 7.95154429e-02,  8.89727937e-02,  9.86352497e-03,\n",
       "            -3.94376944e-03],\n",
       "           ...,\n",
       "           [-4.06555374e-01, -1.66421742e-01, -1.09413261e-02,\n",
       "             1.64763541e-01],\n",
       "           [ 6.11051044e-02, -6.23529290e-03, -3.49457398e-01,\n",
       "            -1.02680467e-01],\n",
       "           [-3.76590233e-01,  7.53138413e-02, -1.81592546e-02,\n",
       "            -1.00408807e-01]],\n",
       "  \n",
       "          [[ 1.66615326e-01,  1.50709832e-01, -1.59711382e-01,\n",
       "             1.85229403e-02],\n",
       "           [ 9.28217146e-02, -2.99542150e-02,  3.01876351e-02,\n",
       "            -1.69784938e-02],\n",
       "           [ 1.14603595e-01, -4.50041749e-02, -2.82733897e-02,\n",
       "             3.83174348e-02],\n",
       "           ...,\n",
       "           [-3.61541574e-01, -1.58274726e-01,  1.10403202e-01,\n",
       "             1.67502717e-01],\n",
       "           [-5.77303757e-02, -3.16612048e-02, -2.18590384e-01,\n",
       "            -1.24144649e-01],\n",
       "           [-5.96750985e-02,  1.50909083e-01, -7.07342502e-02,\n",
       "             5.61464442e-02]],\n",
       "  \n",
       "          [[ 1.86071661e-01,  1.24601158e-01, -1.07288554e-01,\n",
       "             5.57621863e-02],\n",
       "           [-1.88479756e-02, -8.69102248e-02, -7.01532878e-02,\n",
       "            -1.00197651e-01],\n",
       "           [ 1.27413123e-01, -1.21515423e-01,  5.11052513e-03,\n",
       "             4.26470688e-02],\n",
       "           ...,\n",
       "           [-3.32763799e-01, -1.16569082e-01,  2.27680971e-01,\n",
       "             1.01073438e-01],\n",
       "           [-2.50459297e-02, -4.82610344e-02, -9.76349778e-02,\n",
       "            -1.15130899e-01],\n",
       "           [ 1.19104049e-01,  1.71533066e-01, -2.10412412e-01,\n",
       "             6.63355251e-02]],\n",
       "  \n",
       "          [[ 1.04065497e-01, -6.64908919e-02, -5.99625893e-02,\n",
       "             1.28154730e-01],\n",
       "           [-1.48059318e-01, -2.32327437e-01, -1.20985600e-01,\n",
       "            -5.13772335e-02],\n",
       "           [ 2.44801857e-02, -7.56549866e-02,  7.48255531e-02,\n",
       "             2.38054130e-02],\n",
       "           ...,\n",
       "           [-1.38370506e-01, -1.03809188e-01,  1.73585296e-01,\n",
       "             1.97863969e-02],\n",
       "           [ 2.90312627e-02,  4.41289739e-02, -2.05380872e-02,\n",
       "            -1.39484898e-01],\n",
       "           [ 7.40560775e-02,  1.54563114e-01, -2.23853508e-01,\n",
       "             4.67975040e-02]],\n",
       "  \n",
       "          [[ 3.16558752e-02, -2.56210771e-01, -5.51592399e-02,\n",
       "             2.64337029e-01],\n",
       "           [-8.35885314e-02, -1.66040512e-01, -2.41733787e-01,\n",
       "            -6.46810298e-03],\n",
       "           [-1.20005363e-01, -2.54568890e-03,  3.65702528e-02,\n",
       "             1.07728808e-02],\n",
       "           ...,\n",
       "           [ 1.49203632e-01,  2.92391685e-03,  1.47040197e-01,\n",
       "            -5.02704649e-02],\n",
       "           [ 1.05316005e-01,  1.50479279e-01, -6.34694547e-02,\n",
       "            -1.34684211e-01],\n",
       "           [-2.38981931e-02, -1.04806971e-02, -2.00748333e-01,\n",
       "             1.78106898e-02]],\n",
       "  \n",
       "          [[ 6.04177933e-03, -3.70223704e-01, -3.14104630e-02,\n",
       "             1.95779619e-01],\n",
       "           [-1.27736111e-01, -3.09997786e-02, -2.61069682e-01,\n",
       "            -2.94046082e-02],\n",
       "           [-3.49573354e-01,  7.17484779e-02,  1.31831562e-02,\n",
       "             6.93697725e-04],\n",
       "           ...,\n",
       "           [ 4.25669291e-01,  1.11907578e-01,  1.16500974e-01,\n",
       "            -6.64843938e-04],\n",
       "           [ 5.49747123e-02,  2.23526153e-01,  3.62651363e-02,\n",
       "            -2.78652836e-01],\n",
       "           [-6.14086716e-02, -2.07241321e-01, -1.42981969e-01,\n",
       "             2.08087641e-02]]],\n",
       "  \n",
       "  \n",
       "         [[[-2.03264165e-01,  7.43689273e-02,  3.87609720e-03,\n",
       "            -1.20999999e-01],\n",
       "           [ 8.87595358e-02,  1.14933075e-01,  4.65582794e-01,\n",
       "             1.56127921e-01],\n",
       "           [ 2.60459026e-02,  9.46675000e-02, -3.74568166e-02,\n",
       "             3.78049581e-02],\n",
       "           ...,\n",
       "           [-3.25101310e-01, -1.16373769e-01, -1.17205564e-01,\n",
       "             1.31450671e-01],\n",
       "           [ 2.09285675e-01,  1.12668917e-01, -1.46479800e-01,\n",
       "             4.48903459e-02],\n",
       "           [-4.04928777e-01, -4.84104681e-02, -1.92349446e-01,\n",
       "            -7.02377186e-02]],\n",
       "  \n",
       "          [[ 1.33055145e-01,  1.47369862e-01, -2.13326805e-02,\n",
       "             9.37002643e-02],\n",
       "           [ 1.23224073e-01,  1.21340187e-01,  2.55096896e-01,\n",
       "            -1.63616351e-02],\n",
       "           [ 6.63794520e-02, -3.10728692e-02, -1.51157588e-02,\n",
       "             3.94887782e-02],\n",
       "           ...,\n",
       "           [-2.44066306e-01, -1.41847021e-01, -1.10309447e-01,\n",
       "             5.95653119e-02],\n",
       "           [ 2.15069712e-01,  4.38784112e-02,  6.40644323e-03,\n",
       "            -1.24341104e-02],\n",
       "           [-9.91590776e-02,  5.94976827e-02, -2.13761999e-01,\n",
       "             9.06220820e-02]],\n",
       "  \n",
       "          [[ 1.57078413e-01,  2.01037162e-01,  2.65131850e-03,\n",
       "             6.41775565e-02],\n",
       "           [ 4.90286247e-02, -1.23807169e-01,  3.18954278e-02,\n",
       "            -2.67356013e-01],\n",
       "           [ 1.45402975e-01, -1.01217762e-01,  2.08837059e-02,\n",
       "             3.80313402e-02],\n",
       "           ...,\n",
       "           [-2.21113084e-01, -1.48439612e-01, -5.52735893e-02,\n",
       "            -7.12696591e-02],\n",
       "           [ 2.79890877e-01, -5.82701234e-02, -1.84527467e-02,\n",
       "            -9.20907411e-02],\n",
       "           [ 1.05853723e-01,  1.13752737e-01, -2.16694132e-01,\n",
       "             1.00727623e-01]],\n",
       "  \n",
       "          [[ 8.65408986e-02,  8.26346394e-02,  7.09997413e-02,\n",
       "             1.30514627e-01],\n",
       "           [-7.10799452e-02, -3.05332405e-01, -2.08230115e-01,\n",
       "            -3.19844734e-01],\n",
       "           [ 4.87886834e-02, -7.03136457e-02,  1.06877009e-01,\n",
       "             3.13014517e-02],\n",
       "           ...,\n",
       "           [-2.16611866e-01, -1.49712108e-01, -7.43972243e-02,\n",
       "            -2.45750459e-01],\n",
       "           [ 1.74435434e-01, -5.39487065e-02,  5.38993692e-03,\n",
       "            -1.12246375e-01],\n",
       "           [ 1.35463007e-01,  1.00939928e-01, -1.57915908e-01,\n",
       "             1.07776821e-01]],\n",
       "  \n",
       "          [[ 1.12742303e-01, -2.42329610e-01,  1.22554516e-01,\n",
       "             1.47120358e-01],\n",
       "           [-1.11995581e-01, -2.64468940e-01, -4.07079611e-01,\n",
       "            -3.32082437e-01],\n",
       "           [-7.58790482e-02,  2.22052213e-02,  5.27382058e-02,\n",
       "             3.58807214e-02],\n",
       "           ...,\n",
       "           [-1.04225129e-01, -1.51168160e-01, -2.08866951e-02,\n",
       "            -3.19778535e-01],\n",
       "           [ 3.88530199e-02,  5.41745049e-02,  1.60126491e-03,\n",
       "            -1.36186379e-01],\n",
       "           [ 1.07701734e-01, -8.59210677e-02, -5.61960682e-02,\n",
       "             8.25634572e-02]],\n",
       "  \n",
       "          [[ 8.15266773e-02, -3.51397073e-01,  1.67546262e-01,\n",
       "             1.14284069e-01],\n",
       "           [-1.37762958e-01, -1.62154404e-02, -5.21264495e-01,\n",
       "            -3.04162757e-01],\n",
       "           [-2.90147796e-01,  6.15030780e-02, -6.64948383e-02,\n",
       "            -3.84460153e-03],\n",
       "           ...,\n",
       "           [ 2.04227563e-01, -2.21590847e-02,  8.69619104e-02,\n",
       "            -2.35222962e-01],\n",
       "           [-1.61898036e-01,  1.21094763e-01,  4.79687191e-02,\n",
       "            -2.41888692e-01],\n",
       "           [ 1.11073270e-01, -2.93048126e-01,  1.04573266e-01,\n",
       "             5.68423466e-02]]],\n",
       "  \n",
       "  \n",
       "         [[[-3.03343447e-01,  4.95568642e-03, -6.21233315e-03,\n",
       "            -8.19882932e-02],\n",
       "           [ 9.50026364e-03,  2.57189950e-03,  5.29223213e-01,\n",
       "            -2.53506963e-02],\n",
       "           [-3.57096876e-02,  9.66542307e-02,  2.31454775e-02,\n",
       "             6.63291839e-02],\n",
       "           ...,\n",
       "           [-2.02135269e-01, -7.56131136e-02, -2.70409201e-01,\n",
       "             5.38044147e-02],\n",
       "           [ 9.98455733e-02,  1.68178279e-01, -7.32606471e-02,\n",
       "             8.31724772e-02],\n",
       "           [-4.52107901e-01,  3.21964560e-02, -2.69031410e-01,\n",
       "            -2.19702250e-02]],\n",
       "  \n",
       "          [[ 6.60183311e-02,  1.52241316e-01,  4.09275299e-02,\n",
       "             8.95184819e-02],\n",
       "           [ 1.47625681e-01, -3.22086528e-03,  1.67196683e-01,\n",
       "            -2.70513242e-01],\n",
       "           [ 5.07835443e-02,  2.94661978e-03,  5.40233530e-02,\n",
       "             3.58616565e-02],\n",
       "           ...,\n",
       "           [-2.35773982e-01, -6.33952761e-02, -1.81651279e-01,\n",
       "            -1.41731983e-01],\n",
       "           [ 2.20017926e-01,  1.25282940e-01, -5.96518204e-02,\n",
       "            -5.48364140e-02],\n",
       "           [-2.08300867e-01,  1.30339184e-01, -1.84002561e-01,\n",
       "             1.20408864e-01]],\n",
       "  \n",
       "          [[ 8.91767290e-02,  2.20685925e-01,  4.33902235e-02,\n",
       "             1.08706963e-01],\n",
       "           [ 1.02282440e-01, -9.82919095e-02, -1.36724604e-01,\n",
       "            -5.15603676e-01],\n",
       "           [ 1.15462015e-01, -1.27541248e-01,  5.97203260e-02,\n",
       "             3.23540789e-02],\n",
       "           ...,\n",
       "           [-2.87284442e-01, -4.12414048e-02, -6.87812043e-02,\n",
       "            -4.30910528e-01],\n",
       "           [ 3.97497543e-01,  4.92440193e-02,  1.72296165e-02,\n",
       "            -1.96152450e-01],\n",
       "           [ 1.39827369e-03,  1.19584472e-01, -1.21684860e-01,\n",
       "             1.15733055e-01]],\n",
       "  \n",
       "          [[ 1.17068698e-01,  1.01311161e-01,  1.13430480e-01,\n",
       "             1.38562631e-01],\n",
       "           [-2.40383980e-02, -2.43485166e-01, -4.69916557e-01,\n",
       "            -4.93200370e-01],\n",
       "           [ 1.19342573e-01, -6.51726521e-02,  1.45508069e-01,\n",
       "             5.25525343e-02],\n",
       "           ...,\n",
       "           [-3.59931898e-01, -6.80603070e-02,  5.31092193e-02,\n",
       "            -3.78645192e-01],\n",
       "           [ 2.82689040e-01, -1.75422515e-02,  1.08537123e-01,\n",
       "            -2.66185731e-01],\n",
       "           [ 1.04830487e-01,  9.17633886e-02, -1.93645437e-02,\n",
       "             5.52566057e-02]],\n",
       "  \n",
       "          [[ 1.50434025e-01, -2.22962714e-01,  1.31728328e-01,\n",
       "             1.28626980e-01],\n",
       "           [-4.21349118e-02, -1.91919073e-01, -7.13769302e-01,\n",
       "            -3.32406922e-01],\n",
       "           [ 4.82158624e-02,  3.90568589e-02,  5.10162418e-02,\n",
       "            -2.30304701e-02],\n",
       "           ...,\n",
       "           [-2.37343010e-01, -1.22658514e-01,  1.12207846e-01,\n",
       "            -1.33381401e-01],\n",
       "           [ 3.41694898e-02,  2.67444436e-02,  1.27544096e-01,\n",
       "            -2.21356666e-01],\n",
       "           [ 9.11789776e-02, -6.07905903e-02,  2.96752686e-02,\n",
       "             6.75345246e-02]],\n",
       "  \n",
       "          [[ 1.65505494e-01, -3.29413131e-01,  2.04777196e-01,\n",
       "             7.24706017e-02],\n",
       "           [-7.46150083e-02, -4.62081100e-02, -8.12489908e-01,\n",
       "            -5.94130215e-02],\n",
       "           [-1.67264826e-01,  1.02206728e-01, -1.45950278e-01,\n",
       "            -3.42982100e-02],\n",
       "           ...,\n",
       "           [-2.18485333e-01, -3.23258785e-02,  1.69418551e-01,\n",
       "             4.77270495e-02],\n",
       "           [-3.12824006e-01,  1.03097825e-01,  1.05357683e-01,\n",
       "            -8.53093168e-02],\n",
       "           [ 1.31951969e-01, -3.30566962e-01,  1.65944441e-01,\n",
       "            -3.43057587e-02]]],\n",
       "  \n",
       "  \n",
       "         [[[-3.53754210e-01,  3.73095810e-02, -1.33706884e-02,\n",
       "            -8.46204354e-02],\n",
       "           [-7.58526598e-02, -1.52583640e-01,  3.27759581e-02,\n",
       "            -4.94167732e-01],\n",
       "           [-4.01765215e-02,  1.19582689e-01,  8.78539691e-02,\n",
       "            -1.58188159e-03],\n",
       "           ...,\n",
       "           [ 4.83310694e-02,  7.89284498e-02, -1.56698809e-01,\n",
       "            -1.79906249e-01],\n",
       "           [-2.81608620e-02,  1.43353463e-01, -1.35672619e-02,\n",
       "            -1.18915318e-02],\n",
       "           [-3.49565824e-01,  5.77253344e-03, -1.34000429e-01,\n",
       "            -1.87186053e-02]],\n",
       "  \n",
       "          [[-7.25936654e-02,  1.46679444e-01,  4.35868842e-02,\n",
       "             7.06464360e-02],\n",
       "           [ 6.72797978e-02, -1.09445681e-01, -1.69246979e-01,\n",
       "            -5.03682070e-01],\n",
       "           [ 3.82678750e-03, -3.19577376e-02,  1.44821972e-01,\n",
       "             9.76646035e-03],\n",
       "           ...,\n",
       "           [-5.68056340e-02,  4.06606664e-02, -6.20467433e-02,\n",
       "            -3.92919315e-01],\n",
       "           [ 6.55532821e-02,  1.22507677e-01,  1.33926610e-02,\n",
       "            -1.14747412e-01],\n",
       "           [-2.12923017e-01,  1.23260273e-01,  3.92025214e-02,\n",
       "             9.88961425e-02]],\n",
       "  \n",
       "          [[ 4.35768068e-02,  1.90077805e-01,  9.47638275e-02,\n",
       "             8.09700772e-02],\n",
       "           [ 4.27633201e-02, -1.46324892e-01, -3.39770883e-01,\n",
       "            -4.70036236e-01],\n",
       "           [ 7.84651347e-02, -7.08805248e-02,  1.32464366e-01,\n",
       "            -8.73122480e-03],\n",
       "           ...,\n",
       "           [-1.26596818e-01, -1.86332774e-02,  5.39881961e-02,\n",
       "            -2.38860605e-01],\n",
       "           [ 2.50902605e-01,  1.90697112e-02,  8.55340955e-02,\n",
       "            -1.71155483e-01],\n",
       "           [-1.29401487e-01,  1.13646813e-01,  8.17990445e-02,\n",
       "             6.35340251e-02]],\n",
       "  \n",
       "          [[ 5.63535050e-02,  1.37806888e-01,  1.36926168e-01,\n",
       "             9.67002348e-02],\n",
       "           [ 4.18525944e-02, -1.02478891e-01, -4.16442981e-01,\n",
       "            -3.13582993e-01],\n",
       "           [ 8.72736979e-02, -4.61009003e-02,  5.51082325e-02,\n",
       "             2.45451432e-02],\n",
       "           ...,\n",
       "           [-2.32414460e-01, -8.75165697e-02,  1.17160974e-01,\n",
       "            -3.40001779e-02],\n",
       "           [ 3.16515549e-01, -2.41927315e-02,  1.75034950e-01,\n",
       "            -1.74998852e-01],\n",
       "           [-1.04272070e-01,  1.09384835e-01,  1.27784889e-01,\n",
       "             3.97230162e-02]],\n",
       "  \n",
       "          [[ 1.01956938e-01, -1.02711579e-01,  1.73250800e-01,\n",
       "             4.23134249e-02],\n",
       "           [ 3.80820022e-02, -7.82346205e-02, -4.75949811e-01,\n",
       "            -1.06928181e-01],\n",
       "           [ 5.80434080e-02,  5.08547060e-02,  1.18722915e-02,\n",
       "            -2.03858144e-02],\n",
       "           ...,\n",
       "           [-2.54686947e-01, -1.38721559e-01,  1.09919008e-01,\n",
       "             8.84877218e-02],\n",
       "           [ 2.04142946e-01, -3.41762200e-02,  1.87143642e-01,\n",
       "             1.66226651e-02],\n",
       "           [-6.08292592e-02, -3.86793037e-02,  1.38982872e-01,\n",
       "             2.44556983e-02]],\n",
       "  \n",
       "          [[ 1.86920126e-01, -2.70213734e-01,  2.09064162e-01,\n",
       "            -4.53973167e-03],\n",
       "           [ 6.56289321e-02,  1.12922285e-01, -5.31027012e-01,\n",
       "             1.54682808e-01],\n",
       "           [-8.49251748e-02,  5.39084682e-02, -1.55275032e-01,\n",
       "            -4.81767846e-02],\n",
       "           ...,\n",
       "           [-3.94365269e-01, -2.76058812e-02,  9.77559760e-03,\n",
       "             1.01518440e-01],\n",
       "           [-2.02476132e-01,  4.19156261e-02,  3.29645387e-02,\n",
       "             1.04085414e-01],\n",
       "           [ 9.72199026e-02, -2.68070978e-01,  1.67145881e-01,\n",
       "            -1.35438344e-01]]],\n",
       "  \n",
       "  \n",
       "         [[[-2.94040405e-01,  4.61124279e-02, -2.51775912e-02,\n",
       "            -4.43311445e-02],\n",
       "           [-1.56844124e-01, -1.89703804e-01, -5.34102452e-01,\n",
       "            -4.55035009e-01],\n",
       "           [-3.44656857e-02,  5.89522052e-02,  8.97605546e-02,\n",
       "            -3.20592330e-02],\n",
       "           ...,\n",
       "           [ 1.47107314e-01,  1.08587266e-01, -2.27779402e-02,\n",
       "            -2.63431631e-01],\n",
       "           [-1.58610233e-01,  2.63120481e-02,  6.63680537e-02,\n",
       "             4.86790476e-03],\n",
       "           [-1.27838317e-01,  1.57629902e-02,  3.20372247e-02,\n",
       "            -5.34425954e-02]],\n",
       "  \n",
       "          [[-1.01260349e-01,  1.43950589e-01,  6.32317760e-02,\n",
       "             9.11099122e-02],\n",
       "           [-5.18081346e-03, -1.68936146e-01, -3.64843777e-01,\n",
       "            -3.40743601e-01],\n",
       "           [ 1.27587458e-02, -5.57373640e-02,  4.47223507e-02,\n",
       "            -4.38292003e-03],\n",
       "           ...,\n",
       "           [ 1.19420441e-01,  2.62890246e-02,  2.64492340e-02,\n",
       "            -2.55576665e-01],\n",
       "           [-2.98049294e-02,  2.80639349e-02,  7.77767806e-02,\n",
       "            -5.66144752e-02],\n",
       "           [-1.33953481e-02,  7.83339278e-02,  1.42677075e-01,\n",
       "             3.11696481e-02]],\n",
       "  \n",
       "          [[-5.56066895e-02,  1.74156989e-01,  1.08409927e-01,\n",
       "             1.20656679e-01],\n",
       "           [-2.02467569e-02, -1.02813730e-01, -3.60573967e-01,\n",
       "            -2.48136434e-01],\n",
       "           [ 2.34252342e-02, -7.29292861e-02, -2.74509970e-02,\n",
       "             1.61159791e-02],\n",
       "           ...,\n",
       "           [ 4.48131428e-02, -5.12787802e-02,  8.10768249e-02,\n",
       "            -2.95213795e-02],\n",
       "           [ 1.46785196e-01, -4.95852601e-02,  4.65449293e-02,\n",
       "            -3.44624501e-02],\n",
       "           [-5.53544857e-02,  1.36289736e-01,  1.69745206e-01,\n",
       "             3.00615006e-02]],\n",
       "  \n",
       "          [[-1.97828840e-02,  9.91236844e-02,  1.02384874e-01,\n",
       "             7.65797057e-02],\n",
       "           [ 2.50359885e-02, -7.72902139e-02, -3.10944949e-01,\n",
       "            -1.05193565e-01],\n",
       "           [ 1.01375711e-01, -2.45643928e-02, -6.24163370e-02,\n",
       "            -8.18156100e-03],\n",
       "           ...,\n",
       "           [-9.56296125e-02, -1.46809432e-01,  1.10567864e-02,\n",
       "             7.45651577e-02],\n",
       "           [ 2.66406906e-01, -6.02760895e-02,  6.85080546e-02,\n",
       "            -7.16363163e-03],\n",
       "           [-8.00412570e-02,  8.04075256e-02,  1.32820665e-01,\n",
       "             1.23078232e-02]],\n",
       "  \n",
       "          [[-2.10145505e-03, -5.13889766e-02,  9.43936958e-02,\n",
       "             6.21119339e-02],\n",
       "           [ 6.78876303e-02,  6.07481616e-02, -2.48126462e-01,\n",
       "            -4.74393800e-02],\n",
       "           [ 6.71853711e-02,  3.03080474e-02, -1.31681389e-01,\n",
       "            -1.69103286e-02],\n",
       "           ...,\n",
       "           [-2.32011952e-01, -9.00024572e-02, -5.11729848e-02,\n",
       "             2.21032443e-02],\n",
       "           [ 3.00617755e-01, -5.48238274e-02,  3.32188639e-02,\n",
       "             1.88783515e-02],\n",
       "           [-1.47292408e-01, -5.05185160e-02,  1.00035611e-01,\n",
       "            -6.64211546e-02]],\n",
       "  \n",
       "          [[ 6.48885952e-02, -1.96767803e-01,  8.39768263e-02,\n",
       "            -2.18449957e-02],\n",
       "           [ 1.34906530e-01,  1.66000631e-01, -8.61358091e-02,\n",
       "             4.81573995e-02],\n",
       "           [-1.79565657e-02,  7.60982416e-02, -1.48758917e-01,\n",
       "            -1.97591173e-02],\n",
       "           ...,\n",
       "           [-4.46312007e-01,  1.77753978e-02, -8.25703769e-02,\n",
       "            -4.42466318e-02],\n",
       "           [ 2.12216371e-02,  5.63429525e-02, -1.43157633e-01,\n",
       "            -1.67067520e-02],\n",
       "           [-6.50488946e-02, -2.18872238e-01,  1.40279759e-02,\n",
       "            -1.32230799e-01]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.23613717e-01,  3.81731129e-02, -1.15666112e-01,\n",
       "            -1.31899408e-02],\n",
       "           [-3.49159433e-01, -1.87958981e-01, -6.75986852e-01,\n",
       "            -7.94217607e-02],\n",
       "           [-1.04123324e-01,  2.74934423e-03, -1.10058497e-01,\n",
       "            -3.94596596e-02],\n",
       "           ...,\n",
       "           [-2.82990980e-02,  1.36371410e-01,  1.52287721e-01,\n",
       "            -2.06520050e-01],\n",
       "           [-2.98058299e-01, -1.24499577e-01,  1.96933061e-01,\n",
       "             3.61361457e-02],\n",
       "           [ 9.30607558e-02,  5.33825567e-02,  4.97862143e-02,\n",
       "            -1.36154575e-01]],\n",
       "  \n",
       "          [[-7.31468834e-02,  8.55748223e-02, -2.00539889e-02,\n",
       "             1.09397224e-01],\n",
       "           [-1.15284363e-01, -1.26116183e-01, -3.84760695e-01,\n",
       "            -3.31347401e-02],\n",
       "           [-7.58113308e-02, -1.88524324e-02, -1.73155026e-01,\n",
       "             1.17700153e-02],\n",
       "           ...,\n",
       "           [-2.70010172e-02,  5.42398667e-02,  8.14384257e-02,\n",
       "            -6.88103935e-02],\n",
       "           [-2.46852935e-01, -4.30968643e-02,  1.44808297e-01,\n",
       "             7.73490522e-02],\n",
       "           [ 1.18295155e-01,  6.97514646e-02,  7.38184465e-02,\n",
       "            -1.05369174e-02]],\n",
       "  \n",
       "          [[-1.05776953e-01,  6.71696073e-02,  4.89026716e-03,\n",
       "             8.62156517e-02],\n",
       "           [-7.45409181e-02, -1.38560420e-01, -1.74543173e-01,\n",
       "             9.81974514e-03],\n",
       "           [-1.18767695e-02, -8.59960958e-02, -1.93275778e-01,\n",
       "             5.27005372e-02],\n",
       "           ...,\n",
       "           [-8.14156772e-02, -1.25439565e-03,  8.88674423e-02,\n",
       "             7.43811682e-02],\n",
       "           [-2.90695672e-02, -6.39357435e-02,  3.68974609e-02,\n",
       "             1.09815447e-01],\n",
       "           [ 1.00943033e-01,  5.86132527e-02,  7.80275402e-02,\n",
       "            -5.60135096e-02]],\n",
       "  \n",
       "          [[-1.16671760e-01,  7.31947223e-02,  1.46658205e-02,\n",
       "             8.07195320e-02],\n",
       "           [-9.69307837e-02,  3.65739329e-04, -3.07614396e-03,\n",
       "            -4.59798745e-02],\n",
       "           [-5.63562949e-02, -4.34717446e-02, -1.25435773e-01,\n",
       "             8.77785823e-02],\n",
       "           ...,\n",
       "           [-2.38343499e-01, -8.75010136e-03,  3.56116855e-02,\n",
       "             8.94634854e-02],\n",
       "           [ 9.91142520e-02,  1.40081438e-02, -6.59514968e-02,\n",
       "             8.76862047e-02],\n",
       "           [ 2.18436745e-02, -1.52822484e-02,  1.31585445e-02,\n",
       "            -7.37950271e-02]],\n",
       "  \n",
       "          [[-1.00280150e-01, -4.49257822e-02, -9.10889482e-02,\n",
       "             5.74638940e-02],\n",
       "           [-6.76729367e-02,  7.06455071e-02,  9.69864351e-02,\n",
       "            -8.95854736e-02],\n",
       "           [ 2.52519560e-02,  6.66268105e-02, -9.76576254e-02,\n",
       "             7.07056345e-02],\n",
       "           ...,\n",
       "           [-3.21938012e-01, -7.09636038e-04,  6.22141460e-03,\n",
       "            -3.41383868e-02],\n",
       "           [ 1.62832350e-01,  7.96652423e-02, -1.19590410e-01,\n",
       "            -1.29684181e-02],\n",
       "           [-1.37179722e-01, -1.07825737e-01, -1.14042868e-01,\n",
       "            -5.33265018e-02]],\n",
       "  \n",
       "          [[-1.19452989e-01, -6.26742987e-02, -9.32512637e-02,\n",
       "            -3.50293323e-02],\n",
       "           [-1.23924276e-03,  9.17649524e-02,  3.07486998e-01,\n",
       "            -1.42869608e-01],\n",
       "           [-2.13392145e-02, -1.28382694e-02,  3.37167382e-02,\n",
       "             1.94145914e-02],\n",
       "           ...,\n",
       "           [-4.53615929e-01,  1.08952149e-01, -8.49188523e-02,\n",
       "            -1.48972514e-01],\n",
       "           [-4.27866421e-02,  9.00856731e-02, -2.00950081e-01,\n",
       "            -1.12676245e-01],\n",
       "           [-1.91403377e-01, -1.66465353e-01, -1.94798766e-01,\n",
       "            -1.14792158e-01]]]]),\n",
       "  'conv2_b': array([0.09654416, 0.24599045, 0.1384285 , 0.34190513]),\n",
       "  'fc1_w': array([[ 0.1005355 ,  0.24354475,  0.03232333, ...,  0.18476575,\n",
       "           0.07322973,  0.01117934],\n",
       "         [ 0.02684572,  0.08507557,  0.06152143, ...,  0.11876235,\n",
       "          -0.07948164,  0.05944143],\n",
       "         [ 0.03326924,  0.13155976, -0.03489603, ...,  0.1249234 ,\n",
       "          -0.05141636,  0.06509975],\n",
       "         ...,\n",
       "         [ 0.13863754,  0.01483852,  0.03775994, ..., -0.0487478 ,\n",
       "           0.07227087, -0.10831526],\n",
       "         [ 0.01938628,  0.04784339, -0.12971275, ..., -0.05898967,\n",
       "          -0.00285208,  0.06984089],\n",
       "         [ 0.15296789,  0.07091693,  0.02768805, ...,  0.0190499 ,\n",
       "          -0.01988922,  0.03076079]]),\n",
       "  'fc1_b': array([ 0.32370393,  0.44575155,  0.04386294,  0.16398137, -0.01283738,\n",
       "         -0.19095992,  0.03575539,  0.27299779,  0.12256047,  0.08833665]),\n",
       "  'fc2_w': array([[ 0.10689063, -0.0562036 , -0.08276076, -0.17893346,  0.05719132,\n",
       "          -0.11261527,  0.26150965, -0.1460427 , -0.02420991, -0.06360796],\n",
       "         [ 0.20694022, -0.11340183, -0.15515496,  0.09593675, -0.01209345,\n",
       "           0.07680525, -0.16062533,  0.01906046, -0.08722861, -0.09047414],\n",
       "         [-0.08457699,  0.17432667, -0.01596281,  0.07942735, -0.12532113,\n",
       "          -0.08043225,  0.07203745,  0.12126994, -0.05256794, -0.22089145],\n",
       "         [ 0.07676203, -0.06181546,  0.15407748, -0.14882941, -0.18186604,\n",
       "           0.01449568,  0.01847544,  0.08024759, -0.20699692,  0.14603315],\n",
       "         [ 0.18361988, -0.26938287, -0.1467062 ,  0.12051664, -0.30951263,\n",
       "          -0.3489227 ,  0.05639624,  0.44127883,  0.37883545, -0.10486728],\n",
       "         [-0.20933898, -0.16174244, -0.00166563, -0.06870873,  0.15859322,\n",
       "           0.18075034, -0.08864399,  0.1279472 ,  0.10704888,  0.00510529],\n",
       "         [ 0.25453601, -0.13276044, -0.23128451,  0.12377979,  0.07264215,\n",
       "          -0.52412636, -0.05310472,  0.48231318,  0.09058507,  0.03900787],\n",
       "         [ 0.00658598, -0.06379087, -0.12349548,  0.20531637, -0.10739919,\n",
       "          -0.0042841 ,  0.06073455, -0.11951139,  0.04122653,  0.17955199],\n",
       "         [ 0.05879813, -0.07139666,  0.18078824,  0.124382  ,  0.11086293,\n",
       "          -0.28204966, -0.09094127, -0.17570447,  0.06608345, -0.19453876],\n",
       "         [ 0.0619287 ,  0.10164846,  0.00921243, -0.12699213, -0.1125076 ,\n",
       "          -0.1889022 , -0.19452064, -0.04524311,  0.18204878,  0.1933763 ]]),\n",
       "  'fc2_b': array([ 0.26457038, -0.02112293, -0.14940947, -0.04595456,  0.08319516,\n",
       "          0.00261493, -0.04688688, -0.06042848, -0.22027215,  0.07713415])},\n",
       " [2.3025736957897607,\n",
       "  2.302428759722166,\n",
       "  2.302507439535007,\n",
       "  2.3020575693218936,\n",
       "  2.302016538330099,\n",
       "  2.3015484571746136,\n",
       "  2.301448159651697,\n",
       "  2.3000856688435363,\n",
       "  2.299943015462472,\n",
       "  2.294329404502874,\n",
       "  2.2950843473085274,\n",
       "  2.2880848696287717,\n",
       "  2.2900703468530326,\n",
       "  2.2847235725745785,\n",
       "  2.2944702449418712,\n",
       "  2.2590218178591615,\n",
       "  2.249290430788168,\n",
       "  2.288917272432682,\n",
       "  2.2371513294599925,\n",
       "  2.309248647834952,\n",
       "  2.224289006456823,\n",
       "  2.2725222947634345,\n",
       "  2.20919735552847,\n",
       "  2.2346833094482754,\n",
       "  2.251685263285823,\n",
       "  2.2841322271352142,\n",
       "  2.300083387300709,\n",
       "  2.2436194684181756,\n",
       "  2.290936335891582,\n",
       "  2.2646452415211336,\n",
       "  2.217983532588001,\n",
       "  2.246337994119472,\n",
       "  2.2585640783543584,\n",
       "  2.24500939947966,\n",
       "  2.2089602639147836,\n",
       "  2.218152097124217,\n",
       "  2.28825553763226,\n",
       "  2.240491992471847,\n",
       "  2.244763387879176,\n",
       "  2.2081021362273363,\n",
       "  2.219311312538483,\n",
       "  2.193060737103585,\n",
       "  2.2611325576038004,\n",
       "  2.2429066934275848,\n",
       "  2.217358148331096,\n",
       "  2.235744317084532,\n",
       "  2.1864260271632516,\n",
       "  2.254427525684553,\n",
       "  2.206736302213012,\n",
       "  2.271086883446393,\n",
       "  2.232090773771891,\n",
       "  2.310864643591044,\n",
       "  2.214808537146127,\n",
       "  2.248871997160687,\n",
       "  2.2484556890394796,\n",
       "  2.2540042863313796,\n",
       "  2.263627259992556,\n",
       "  2.2479678293464747,\n",
       "  2.2221706762914124,\n",
       "  2.2372654285158355,\n",
       "  2.24777350255395,\n",
       "  2.1986975995590052,\n",
       "  2.2316943212217626,\n",
       "  2.2752934620200898,\n",
       "  2.1328293863311307,\n",
       "  2.207960346630843,\n",
       "  2.340594530047894,\n",
       "  2.22323711018806,\n",
       "  2.206320108832129,\n",
       "  2.136425778942374,\n",
       "  2.266219730214658,\n",
       "  2.205847492174149,\n",
       "  2.2273486672837883,\n",
       "  2.3300924294034906,\n",
       "  2.267919837809494,\n",
       "  2.224938050988165,\n",
       "  2.2397953209343457,\n",
       "  2.2314362347281205,\n",
       "  2.227205114040811,\n",
       "  2.2387891051596287,\n",
       "  2.223979705103693,\n",
       "  2.2207429633610487,\n",
       "  2.258603615027847,\n",
       "  2.2794623368193596,\n",
       "  2.1913417256505547,\n",
       "  2.222673930859347,\n",
       "  2.232912856845356,\n",
       "  2.332802095674462,\n",
       "  2.2654733246568775,\n",
       "  2.2439681279631216,\n",
       "  2.2197979951453255,\n",
       "  2.198733107563063,\n",
       "  2.21213381972492,\n",
       "  2.246268601998135,\n",
       "  2.17740154590509,\n",
       "  2.180393339426137,\n",
       "  2.179286730280623,\n",
       "  2.3189159621478987,\n",
       "  2.203553958206263,\n",
       "  2.2280437961001707,\n",
       "  2.2591803444014857,\n",
       "  2.227587756993406,\n",
       "  2.2209981427063825,\n",
       "  2.1903371980126307,\n",
       "  2.243344067892865,\n",
       "  2.275058780282649,\n",
       "  2.244246203190742,\n",
       "  2.225880181813304,\n",
       "  2.249029799003437,\n",
       "  2.254926312808309,\n",
       "  2.2227584560722247,\n",
       "  2.2234077681558144,\n",
       "  2.24111520382493,\n",
       "  2.2563212119985323,\n",
       "  2.2496427831213697,\n",
       "  2.2424986059425187,\n",
       "  2.2883392726821112,\n",
       "  2.2406006377724883,\n",
       "  2.223209741164953,\n",
       "  2.255973520451057,\n",
       "  2.2502353364240983,\n",
       "  2.228070380983671,\n",
       "  2.1901590527697032,\n",
       "  2.2398211362830502,\n",
       "  2.2257412876829306,\n",
       "  2.257009918362861,\n",
       "  2.2098297074488578,\n",
       "  2.213137499335682,\n",
       "  2.242770755629221,\n",
       "  2.21718050088494,\n",
       "  2.2078970110908953,\n",
       "  2.1891036996289235,\n",
       "  2.236566940116593,\n",
       "  2.2463552954036974,\n",
       "  2.211759970172385,\n",
       "  2.184270367628633,\n",
       "  2.2193141481506737,\n",
       "  2.217737176002992,\n",
       "  2.218111200718052,\n",
       "  2.2209096714257632,\n",
       "  2.2547803612666146,\n",
       "  2.1734562290494135,\n",
       "  2.226045360492654,\n",
       "  2.173177994603082,\n",
       "  2.2059566371726334,\n",
       "  2.228303529430201,\n",
       "  2.2088515071608725,\n",
       "  2.256579657692287,\n",
       "  2.2000963906895863,\n",
       "  2.1988630095953474,\n",
       "  2.25271662045363,\n",
       "  2.2326977310864775,\n",
       "  2.2713631928391913,\n",
       "  2.196910561889298,\n",
       "  2.226842150089308,\n",
       "  2.2463894800070245,\n",
       "  2.193490015248002,\n",
       "  2.2265904462653294,\n",
       "  2.210558660781273,\n",
       "  2.1611761661927025,\n",
       "  2.2225565963566165,\n",
       "  2.2307364975429027,\n",
       "  2.163763250021243,\n",
       "  2.192232129635938,\n",
       "  2.2218125210588333,\n",
       "  2.1921929154285373,\n",
       "  2.183283491726466,\n",
       "  2.172748618272366,\n",
       "  2.162502490741481,\n",
       "  2.2529622703872385,\n",
       "  2.146581871402931,\n",
       "  2.2332872362355265,\n",
       "  2.1211891600236186,\n",
       "  2.177043093428537,\n",
       "  2.216395216164567,\n",
       "  2.288175228573889,\n",
       "  2.204435629136435,\n",
       "  2.193055668447708,\n",
       "  2.2168501197387425,\n",
       "  2.212521309315868,\n",
       "  2.1700358996988967,\n",
       "  2.2399425501553423,\n",
       "  2.144639931298458,\n",
       "  2.2129463813877615,\n",
       "  2.2192575111793498,\n",
       "  2.200473653443497,\n",
       "  2.195929721611226,\n",
       "  2.1833651313911395,\n",
       "  2.1844901971474733,\n",
       "  2.1352400916856875,\n",
       "  2.2141059778949876,\n",
       "  2.17683507302153,\n",
       "  2.1744822131533623,\n",
       "  2.163432394164854,\n",
       "  2.2202448532553483,\n",
       "  2.1924521733504068,\n",
       "  2.1304417299870155,\n",
       "  2.1773561022920624,\n",
       "  2.1002028599257248,\n",
       "  2.1370462858542214,\n",
       "  2.205958347853379,\n",
       "  2.179749953057867,\n",
       "  2.146451461517864,\n",
       "  2.1512837368960733,\n",
       "  2.2364114144631877,\n",
       "  2.16565442495281,\n",
       "  2.169663153902919,\n",
       "  2.11411936820397,\n",
       "  2.167409473540719,\n",
       "  2.0871932662023958,\n",
       "  2.211106866695677,\n",
       "  2.0662619773840287,\n",
       "  2.0793429148122393,\n",
       "  2.132031562708768,\n",
       "  2.1577064209660204,\n",
       "  2.104888774825084,\n",
       "  2.1851419891990362,\n",
       "  2.155761172184875,\n",
       "  2.170546971459883,\n",
       "  2.1232295191595907,\n",
       "  2.1095175535338,\n",
       "  2.0668886360241268,\n",
       "  2.1366880154503347,\n",
       "  2.175980740650416,\n",
       "  2.1436711274124485,\n",
       "  2.1465657065439836,\n",
       "  2.111489477290325,\n",
       "  2.1057337510314404,\n",
       "  2.0883821922285657,\n",
       "  2.132032946995868,\n",
       "  2.0942024319893813,\n",
       "  2.112053453665947,\n",
       "  2.032965380128149,\n",
       "  2.163667702744571,\n",
       "  2.1349439967901978,\n",
       "  2.1229224977426266,\n",
       "  2.1140581944230825,\n",
       "  2.093447339028376,\n",
       "  2.1087546875678367,\n",
       "  2.0823272331506195,\n",
       "  2.1101148100585947,\n",
       "  2.0468595848622386,\n",
       "  2.101119461361313,\n",
       "  2.031394397100456,\n",
       "  2.118465205016932,\n",
       "  1.9508374802163482,\n",
       "  2.107139182772534,\n",
       "  2.1029117753475113,\n",
       "  2.0119543754555886,\n",
       "  2.1007100258935854,\n",
       "  1.9122273400480896,\n",
       "  2.0522599129942543,\n",
       "  2.008360426999878,\n",
       "  1.918526593605504,\n",
       "  1.9060940408647378,\n",
       "  2.0720148848312014,\n",
       "  1.978478793694796,\n",
       "  1.9199705059415713,\n",
       "  2.0073021814437166,\n",
       "  1.8873489857326071,\n",
       "  1.743325506611805,\n",
       "  1.8824548125814156,\n",
       "  1.8605887113885529,\n",
       "  1.9290414738135815,\n",
       "  2.0274249985393378,\n",
       "  2.063291554015632,\n",
       "  1.9474020360180826,\n",
       "  1.8077649649892966,\n",
       "  1.8289887470742654,\n",
       "  1.8955685593304445,\n",
       "  1.901478939691255,\n",
       "  1.9048018171809225,\n",
       "  1.9185053947137072,\n",
       "  1.9035354085663243,\n",
       "  1.7928399228945766,\n",
       "  1.7565871223867575,\n",
       "  1.7894497986401139,\n",
       "  2.043451719287519,\n",
       "  1.9039581419552203,\n",
       "  1.8252448286920595,\n",
       "  1.9464741564909802,\n",
       "  1.8098561819511811,\n",
       "  1.8918012998257483,\n",
       "  1.7053592425324842,\n",
       "  1.7491707835252603,\n",
       "  2.004477605784405,\n",
       "  1.8331441484464817,\n",
       "  1.796608156481366,\n",
       "  1.7757313359211533,\n",
       "  1.8940614220065162,\n",
       "  1.9151120315299424,\n",
       "  1.751651067353759,\n",
       "  1.8265336075235636,\n",
       "  1.6411045961443382,\n",
       "  1.7933334455393635,\n",
       "  1.7312337644579268,\n",
       "  1.864188724425431,\n",
       "  1.6975178242498064,\n",
       "  1.6269868728814227,\n",
       "  1.6741292483412453,\n",
       "  1.696692227506987,\n",
       "  1.768806267248039,\n",
       "  1.8551974591897782,\n",
       "  1.7013817270112377,\n",
       "  1.7250658669581522,\n",
       "  1.7137229242134544,\n",
       "  1.8362655986925802,\n",
       "  1.7366686202963064,\n",
       "  1.8952870311484356,\n",
       "  1.7714669149647244,\n",
       "  1.7551830628682017,\n",
       "  1.763783925279617,\n",
       "  1.5066641787676147,\n",
       "  1.532171612328917,\n",
       "  1.497324099500957,\n",
       "  1.5650411998672966,\n",
       "  1.6850184826814685,\n",
       "  1.7998658323651038,\n",
       "  1.7885673988651472,\n",
       "  1.644562726548003,\n",
       "  1.6733465854729193,\n",
       "  1.5240066145006155,\n",
       "  1.6853656800374768,\n",
       "  1.727133742408431,\n",
       "  1.586188431596636,\n",
       "  1.762442808856965,\n",
       "  1.7645808543192123,\n",
       "  1.8255750307715333,\n",
       "  1.7939463404346148,\n",
       "  1.6630884660126295,\n",
       "  1.5472368970155352,\n",
       "  1.6220095386469406,\n",
       "  1.5909957763803821,\n",
       "  1.660297771434939,\n",
       "  1.643155707586019,\n",
       "  1.734134448662936,\n",
       "  1.428210664361134,\n",
       "  1.5703724815521913,\n",
       "  1.532744110406907,\n",
       "  1.4116031083682368,\n",
       "  1.699254238734898,\n",
       "  1.5065719646338673,\n",
       "  1.5846306843567413,\n",
       "  1.9741284094014158,\n",
       "  1.4926551411202897,\n",
       "  1.5242634207951866,\n",
       "  1.5261574544381478,\n",
       "  1.5985595811509627,\n",
       "  1.5781687876810868,\n",
       "  1.4593661912056384,\n",
       "  1.5497349619954293,\n",
       "  1.66853072166497,\n",
       "  1.4320809105175947,\n",
       "  1.4544284869549997,\n",
       "  1.5262795715036066,\n",
       "  1.4871458665700619,\n",
       "  1.5082797809078698,\n",
       "  1.4406113258283648,\n",
       "  1.5850117484808501,\n",
       "  1.5356999224668149,\n",
       "  1.4584020520531245,\n",
       "  1.2904346233622026,\n",
       "  1.4169716312604577,\n",
       "  1.535462515140682,\n",
       "  1.4415482289710129,\n",
       "  1.4298441585111286,\n",
       "  1.4495961512123252,\n",
       "  1.3102722364710058,\n",
       "  1.4497573161704325,\n",
       "  1.5026693518503953,\n",
       "  1.644184140565154,\n",
       "  1.447634731432218,\n",
       "  1.359333491900468,\n",
       "  1.3902848654953126,\n",
       "  1.4326186424017031,\n",
       "  1.4680071047586445,\n",
       "  1.4334801686245375,\n",
       "  1.5361106951561174,\n",
       "  1.4590259742478005,\n",
       "  1.4194947608190942,\n",
       "  1.4950856236910344,\n",
       "  1.5044755649798678,\n",
       "  1.4216248519063213,\n",
       "  1.5570566792052027,\n",
       "  1.3305616912045342,\n",
       "  1.4398356374929098,\n",
       "  1.3464712722650451,\n",
       "  1.5840888796579529,\n",
       "  1.5484960732668904,\n",
       "  1.330976297000322,\n",
       "  1.2452112906496124,\n",
       "  1.5109579178148362,\n",
       "  1.3096590594307702,\n",
       "  1.3399098022010298,\n",
       "  1.4523020824254116,\n",
       "  1.353777177649959,\n",
       "  1.4629353748775764,\n",
       "  1.3983461927811986,\n",
       "  1.2801600761931657,\n",
       "  1.5049168507791697,\n",
       "  1.585874639311335,\n",
       "  1.7180845126601296,\n",
       "  1.1969526229405643,\n",
       "  1.3717079759064388,\n",
       "  1.1734849383617485,\n",
       "  1.4492183372478455,\n",
       "  1.3209638433820543,\n",
       "  1.379830790852256,\n",
       "  1.2244689942862639,\n",
       "  1.4336576602870488,\n",
       "  1.3968647173139326,\n",
       "  1.3741078385766063,\n",
       "  1.2388242123273199,\n",
       "  1.2391885151680329,\n",
       "  1.5153768832041858,\n",
       "  1.1447733479082045,\n",
       "  1.248020354073903,\n",
       "  1.385430836221883,\n",
       "  1.0429006036825499,\n",
       "  1.6584374355714744,\n",
       "  1.2994981502473568,\n",
       "  1.2284346137252466,\n",
       "  1.3517778216434109,\n",
       "  1.3301580572666334,\n",
       "  1.3809301197691068,\n",
       "  1.1866369781881199,\n",
       "  1.2117722969473634,\n",
       "  1.1720993897705778,\n",
       "  1.4606281246267088,\n",
       "  1.066472415934636,\n",
       "  1.1624018919129822,\n",
       "  1.241250731085,\n",
       "  1.396347500036369,\n",
       "  1.0484139371338803,\n",
       "  1.2030707082612282,\n",
       "  1.3882036456973141,\n",
       "  1.2672629641176316,\n",
       "  1.2186772534624892,\n",
       "  1.0744718522827328,\n",
       "  1.2318543491005527,\n",
       "  1.2575040326121112,\n",
       "  1.1404544113730983,\n",
       "  1.252058403864953,\n",
       "  1.216161241895523,\n",
       "  1.1274155815835871,\n",
       "  1.1994354987552032,\n",
       "  1.1809317809034485,\n",
       "  1.163784900116563,\n",
       "  1.050244920519677,\n",
       "  1.2138115443335091,\n",
       "  1.3081622806294868,\n",
       "  1.1985014459961538,\n",
       "  1.2285346089313152,\n",
       "  1.1366395907190423,\n",
       "  1.2132062323228057,\n",
       "  1.0478400269308679,\n",
       "  1.1911325484445077,\n",
       "  1.1172626768126344,\n",
       "  1.2125054460036053,\n",
       "  1.067687643836422,\n",
       "  1.144911308566439,\n",
       "  1.4290210000742753,\n",
       "  1.1261062865023754,\n",
       "  1.1594735800398548,\n",
       "  1.1927713701195177,\n",
       "  1.2262826943360747,\n",
       "  0.8296575384507708,\n",
       "  1.1428080035235755,\n",
       "  1.1543429433404302,\n",
       "  1.0928706861614155,\n",
       "  0.9757086499818464,\n",
       "  1.1860260710132613,\n",
       "  1.251577779681518,\n",
       "  1.1679876239830105,\n",
       "  1.0067621483241285,\n",
       "  1.0318130572804027,\n",
       "  1.2098307525807972,\n",
       "  1.215506259369439,\n",
       "  1.3161231000022013,\n",
       "  1.3849819108304195,\n",
       "  1.1101801909684514,\n",
       "  1.1177484091231618,\n",
       "  1.3779525704638298,\n",
       "  1.198086754282558,\n",
       "  1.0039905576408996,\n",
       "  1.1596918171279817,\n",
       "  1.0632727926320682,\n",
       "  1.204526201632173,\n",
       "  1.0246804162860417,\n",
       "  0.8820472302479347,\n",
       "  1.1158630908073714,\n",
       "  0.9264095485153179,\n",
       "  1.1288498459273377,\n",
       "  1.011415773512425,\n",
       "  0.9506646223684924,\n",
       "  1.0351765060310874,\n",
       "  1.2009138808991096,\n",
       "  1.1067330532008535,\n",
       "  1.1770774072262002,\n",
       "  0.8693925683048859,\n",
       "  1.1732460202422692,\n",
       "  1.2093932977565964,\n",
       "  0.9391376153999865,\n",
       "  0.9562576976520022,\n",
       "  1.3079809123021942,\n",
       "  1.2759849893037334,\n",
       "  1.0860535415851118,\n",
       "  1.2419635418705772,\n",
       "  1.037089942053876,\n",
       "  0.977079126594515,\n",
       "  1.0449164200681393,\n",
       "  1.1639642878880352,\n",
       "  1.1489848461428733,\n",
       "  0.9595589061087959,\n",
       "  1.0544665197441845,\n",
       "  1.1313343848808726,\n",
       "  1.0998970351473851,\n",
       "  0.8257847434801516,\n",
       "  0.9937407278277739,\n",
       "  1.2680803919645933,\n",
       "  1.1834607195514872,\n",
       "  0.855449499678926,\n",
       "  1.0126234484801737,\n",
       "  1.058138890476476,\n",
       "  0.9510792179918228,\n",
       "  0.9867911485589023,\n",
       "  0.7928284481095528,\n",
       "  0.8584707605528513,\n",
       "  0.9107292856601508,\n",
       "  0.9352587837659158,\n",
       "  1.025950025211976,\n",
       "  0.8817683835498157,\n",
       "  1.1485712315754428,\n",
       "  0.9362031426019811,\n",
       "  1.104095651890926,\n",
       "  0.9761988901832612,\n",
       "  1.0339443493941924,\n",
       "  0.9723954045097708,\n",
       "  0.9901928776974144,\n",
       "  0.8167676988373586,\n",
       "  0.9224540562449994,\n",
       "  1.009787083106503,\n",
       "  1.3389328820611546,\n",
       "  1.2258201016163908,\n",
       "  0.8999352190837983,\n",
       "  0.7987820608909106,\n",
       "  1.006291574431863,\n",
       "  1.1033119768536959,\n",
       "  1.1786777775940158,\n",
       "  0.9229550974440152,\n",
       "  0.8227956525085784,\n",
       "  0.9722330356098352,\n",
       "  0.8212189852486564,\n",
       "  0.7868606551372677,\n",
       "  1.0181163022648931,\n",
       "  1.0918870989620604,\n",
       "  0.8584871372373641,\n",
       "  0.9193029775132672,\n",
       "  0.9351324612299635,\n",
       "  0.8927765730813435,\n",
       "  0.7916120347381919,\n",
       "  1.019924786051094,\n",
       "  0.8784072923701838,\n",
       "  0.9778834436729416,\n",
       "  0.9447488691665226,\n",
       "  0.946891455315706,\n",
       "  1.1266857118452498,\n",
       "  1.1288804590195594,\n",
       "  0.9628178874965763,\n",
       "  0.9706918745176815,\n",
       "  1.170023169269955,\n",
       "  1.10318210597135,\n",
       "  0.7247079252655261,\n",
       "  0.9036924077279017,\n",
       "  0.7553076940393006,\n",
       "  0.9832011119363191,\n",
       "  0.8489881151387262,\n",
       "  0.9213711286149053,\n",
       "  0.9787872081254693,\n",
       "  0.7716897607800149,\n",
       "  0.7428894807950148,\n",
       "  0.9072889593606289,\n",
       "  0.9284666061963699,\n",
       "  1.0172951466407885,\n",
       "  0.7405729458763176,\n",
       "  0.9896890255944021,\n",
       "  0.9912981809690451,\n",
       "  0.82353545498329,\n",
       "  0.7764953302638704,\n",
       "  0.8891264355107081,\n",
       "  1.0098205627567505,\n",
       "  0.9104608073947044,\n",
       "  0.9620291387275296,\n",
       "  0.9923435918961848,\n",
       "  0.7536766730960546,\n",
       "  0.7581918294652433,\n",
       "  0.7409934701248393,\n",
       "  0.9150490214646806,\n",
       "  0.9272203573897717,\n",
       "  0.9585388026757607,\n",
       "  0.9067702846900861,\n",
       "  0.905672554135947,\n",
       "  0.7165555887108335,\n",
       "  0.9249206987402773,\n",
       "  1.0724908884092077,\n",
       "  0.8908411201627396,\n",
       "  0.7758602069350707,\n",
       "  0.8747946024484352,\n",
       "  0.9244758281208177,\n",
       "  0.7230933243375514,\n",
       "  1.0464728444086042,\n",
       "  0.8543866159112147,\n",
       "  0.9393297634418344,\n",
       "  0.9866752757162941,\n",
       "  1.2464504234982263,\n",
       "  0.8996713978544666,\n",
       "  0.850866517848067,\n",
       "  1.0727363858636345,\n",
       "  0.947563538711876,\n",
       "  0.6903433164141523,\n",
       "  0.9674233013583391,\n",
       "  1.0443509789793284,\n",
       "  0.9681940829310623,\n",
       "  1.0330739663239632,\n",
       "  0.8464528234826008,\n",
       "  0.9346185873610949,\n",
       "  0.9545850762868405,\n",
       "  0.7806700518184858,\n",
       "  0.9019263526801653,\n",
       "  0.9614297748121055,\n",
       "  0.9584284491490833,\n",
       "  1.00953792799839,\n",
       "  0.8882138209431152,\n",
       "  1.04868984066281,\n",
       "  0.8741621473695784,\n",
       "  0.7438685919204685,\n",
       "  0.8872311050711646,\n",
       "  0.986863698944297,\n",
       "  0.8203721224984855,\n",
       "  0.9321094111827373,\n",
       "  0.763436950607714,\n",
       "  0.93431690456229,\n",
       "  0.9439620469324898,\n",
       "  0.7141860054511019,\n",
       "  0.7262934612357558,\n",
       "  0.7547534079454623,\n",
       "  0.9119215829074265,\n",
       "  0.9574723540344319,\n",
       "  0.9112878269330499,\n",
       "  0.8711442050089903,\n",
       "  0.9178654520263378,\n",
       "  0.7197973754997912,\n",
       "  1.0139427819927895,\n",
       "  0.8938733250793974,\n",
       "  0.9520243553295586,\n",
       "  0.7663855250505569,\n",
       "  0.9358153306135558,\n",
       "  0.7689181348758667,\n",
       "  0.8360465358419147,\n",
       "  0.9637500524499253,\n",
       "  0.7458740434413429,\n",
       "  1.309501174044302,\n",
       "  0.9397883539790667,\n",
       "  0.7691715942259298,\n",
       "  0.7383720197248567,\n",
       "  0.7610861547771247,\n",
       "  0.8164484428241566,\n",
       "  0.6844768261396664,\n",
       "  0.9215124282438616,\n",
       "  0.8715961809861217,\n",
       "  0.8090309067600194,\n",
       "  0.9726798173077439,\n",
       "  0.73498641677398,\n",
       "  0.6751312224560438,\n",
       "  1.2597899060297477,\n",
       "  1.0347442169148373,\n",
       "  1.008974128398251,\n",
       "  0.536386104945513,\n",
       "  0.93979956249656,\n",
       "  0.8965411314937226,\n",
       "  0.7002562793175564,\n",
       "  0.8964822706648569,\n",
       "  0.8576594833762556,\n",
       "  1.0044680813369313,\n",
       "  0.9486161894479535,\n",
       "  0.9733246675760089,\n",
       "  0.8720087779441088,\n",
       "  1.0049775677438144,\n",
       "  0.9304915346912933,\n",
       "  0.8744184560328119,\n",
       "  0.8796822110191148,\n",
       "  0.7650033793984895,\n",
       "  0.9708343497005403,\n",
       "  0.8024626901123336,\n",
       "  0.9147012575661845,\n",
       "  0.8365821655005162,\n",
       "  0.9429828303722309,\n",
       "  0.9334889842883006,\n",
       "  0.8725942579610968,\n",
       "  0.6557942186076056,\n",
       "  0.8581504522006463,\n",
       "  0.9561580191852924,\n",
       "  0.849837997411073,\n",
       "  0.734308610991075,\n",
       "  0.7091055497778416,\n",
       "  0.6496678950995446,\n",
       "  0.8915731605880725,\n",
       "  0.7491681574630343,\n",
       "  0.8501308845579105,\n",
       "  0.7343559079677803,\n",
       "  0.9383285120740257,\n",
       "  0.7444158200013803,\n",
       "  0.846752426282457,\n",
       "  0.851369979860071,\n",
       "  0.7906510683953785,\n",
       "  0.6638117879741952,\n",
       "  0.9460496188115078,\n",
       "  0.8975430708895902,\n",
       "  1.0060705301903912,\n",
       "  0.8729674320950788,\n",
       "  0.845681024380688,\n",
       "  0.7140058964502877,\n",
       "  0.9790313097883553,\n",
       "  0.7714576883759975,\n",
       "  0.9139352437242492,\n",
       "  0.9477694656478378,\n",
       "  0.8813861940241356,\n",
       "  0.8543224199106029,\n",
       "  0.8355848549942241,\n",
       "  0.7830740795754181,\n",
       "  0.8621977943479264,\n",
       "  0.828209542002883,\n",
       "  0.805999219463896,\n",
       "  0.9498787395646284,\n",
       "  0.5357850037064888,\n",
       "  0.7592271672618877,\n",
       "  0.7253979829926508,\n",
       "  0.9684620160055175,\n",
       "  0.8983443542049465,\n",
       "  0.9139025654633515,\n",
       "  0.8011476799065974,\n",
       "  1.1708856025846923,\n",
       "  0.7709833125172733,\n",
       "  0.7729622745238733,\n",
       "  0.836714076179978,\n",
       "  0.778424772026802,\n",
       "  0.8968937699485129,\n",
       "  0.8974182494850731,\n",
       "  0.8246051216226595,\n",
       "  0.5992339811091897,\n",
       "  0.8494472294476595,\n",
       "  0.9704995044592115,\n",
       "  0.8524071182536338,\n",
       "  0.7511712991104544,\n",
       "  1.044089635255482,\n",
       "  0.8890009114958333,\n",
       "  0.8390681973329067,\n",
       "  0.8901035215195177,\n",
       "  0.6746584808920628,\n",
       "  0.8207443970745492,\n",
       "  0.8517183506185296,\n",
       "  0.5931025836761742,\n",
       "  0.9012955546862772,\n",
       "  1.0565698423172898,\n",
       "  0.7784205378978284,\n",
       "  0.984431643387702,\n",
       "  1.2393099576606466,\n",
       "  0.816922647034943,\n",
       "  0.7211723107052482,\n",
       "  0.6981951738476659,\n",
       "  0.7660462106279623,\n",
       "  0.9328765423351297,\n",
       "  0.813477040569244,\n",
       "  0.7565110688256058,\n",
       "  0.7843459283307119,\n",
       "  0.9741599198553891,\n",
       "  0.8536517212156849,\n",
       "  0.9224594673816071,\n",
       "  0.7612404793775114,\n",
       "  0.9092574336263121,\n",
       "  0.7598429564758519,\n",
       "  0.7538812927613822,\n",
       "  0.7091898965807268,\n",
       "  0.740417849111864,\n",
       "  0.7782665604457266,\n",
       "  0.7551995628084613,\n",
       "  0.9020894511098602,\n",
       "  0.8161955068093404,\n",
       "  0.8963244552070411,\n",
       "  0.7368034679285488,\n",
       "  1.0420465863373882,\n",
       "  0.8575571459764526,\n",
       "  0.8470206247124145,\n",
       "  0.8398455704864684,\n",
       "  0.9298183024665828,\n",
       "  0.7384937912578251,\n",
       "  0.9140162918117793,\n",
       "  0.9489224524345186,\n",
       "  0.7409361909818446,\n",
       "  0.8489543366328554,\n",
       "  0.8141147996311852,\n",
       "  0.5756234584699773,\n",
       "  0.8965955167134393,\n",
       "  0.8613687802266651,\n",
       "  0.6637489545172518,\n",
       "  0.7925512981363365,\n",
       "  0.6669157538596775,\n",
       "  0.8472916608765337,\n",
       "  0.7486137400168866,\n",
       "  0.881116627404077,\n",
       "  0.885474487183881,\n",
       "  0.9276143123985694,\n",
       "  0.7601815752126588,\n",
       "  0.850750426002543,\n",
       "  0.6692676204454283,\n",
       "  0.8452315974438902,\n",
       "  0.8965183155359071,\n",
       "  0.81235796760258,\n",
       "  0.9673525706331351,\n",
       "  0.8714311341355034,\n",
       "  0.751237589600147,\n",
       "  0.7141505293322663,\n",
       "  0.7678056518080334,\n",
       "  0.8923848902462613,\n",
       "  0.7641196546402166,\n",
       "  0.8456220979501415,\n",
       "  0.6579317037931367,\n",
       "  0.8537507094227234,\n",
       "  0.841241583630444,\n",
       "  0.6850571559502606,\n",
       "  0.7751977358832338,\n",
       "  0.7310085857422803,\n",
       "  0.8659517565534781,\n",
       "  0.810470291551246,\n",
       "  0.9931370200988567,\n",
       "  0.7249761954514713,\n",
       "  0.6890246257102207,\n",
       "  0.6041892385591037,\n",
       "  0.8142406751992944,\n",
       "  0.693762380237343,\n",
       "  0.7246439538258518,\n",
       "  0.6934176347553922,\n",
       "  0.9995952037225327,\n",
       "  0.70405226063846,\n",
       "  0.9111263074752236,\n",
       "  0.6388313262788369,\n",
       "  0.6997527531619486,\n",
       "  0.893105372822211,\n",
       "  0.6188941370943154,\n",
       "  0.8231426032323444,\n",
       "  0.7737172896953483,\n",
       "  0.9373650574168116,\n",
       "  0.8074876852928449,\n",
       "  0.8010743221668715,\n",
       "  0.8756334281062026,\n",
       "  0.8660562440911916,\n",
       "  0.6864762599161169,\n",
       "  0.7708874907871828,\n",
       "  0.8633709947627414,\n",
       "  0.72486315017873,\n",
       "  0.8674132707866641,\n",
       "  1.1147483487194962,\n",
       "  0.9172429533502496,\n",
       "  0.7899983564334604,\n",
       "  1.0194745741688716,\n",
       "  0.8243506833384674,\n",
       "  0.8358994724838259,\n",
       "  0.9839857595566616,\n",
       "  0.8904153491401192,\n",
       "  0.6731426211401391,\n",
       "  0.7581060095324869,\n",
       "  0.6888540590036909,\n",
       "  0.6280141992888151,\n",
       "  0.9061874970373885,\n",
       "  0.8428850784999314,\n",
       "  0.8267223270269508,\n",
       "  0.8772461515725697,\n",
       "  0.8224713470478304,\n",
       "  0.8623869573065533,\n",
       "  0.8066367587528559,\n",
       "  0.7857029190361855,\n",
       "  0.8009784485807011,\n",
       "  0.7633407840508463,\n",
       "  0.9973194276101813,\n",
       "  0.6518664758396711,\n",
       "  0.843110222890433,\n",
       "  0.9616596051303857,\n",
       "  0.679584740323521,\n",
       "  0.7382170459106104,\n",
       "  0.7217940158746154,\n",
       "  0.7982917966388297,\n",
       "  0.7313623151019435,\n",
       "  0.652427204201127,\n",
       "  0.8638418651675815,\n",
       "  0.8456883651287787,\n",
       "  0.6787711461261497,\n",
       "  0.7382718126347524,\n",
       "  0.5988330777559776,\n",
       "  0.7556128338950195,\n",
       "  0.7930562495468599,\n",
       "  0.7086537658894622,\n",
       "  0.820810301857739,\n",
       "  0.6782774216761429,\n",
       "  0.9183283984597386,\n",
       "  0.7913441555675199,\n",
       "  0.7720660409691318,\n",
       "  0.6374171897348887,\n",
       "  0.7873535411797999,\n",
       "  0.6639606601194826,\n",
       "  0.7644724449851457,\n",
       "  0.8694958213119124,\n",
       "  0.9223877497939917,\n",
       "  0.7600946541692221,\n",
       "  0.6473520053505432,\n",
       "  0.6707521347740317,\n",
       "  0.729199500647204,\n",
       "  0.8476778866204558,\n",
       "  0.7234478724466187,\n",
       "  0.8185804573728211,\n",
       "  0.6784097263991824,\n",
       "  0.6581520078488238,\n",
       "  0.8083872832923542,\n",
       "  0.8262797373135313,\n",
       "  0.8159253609802404,\n",
       "  0.8377688262387775,\n",
       "  0.7299575467511646,\n",
       "  0.5611643158403703,\n",
       "  0.7346614519642989,\n",
       "  0.7759599868406685,\n",
       "  0.5781531335397316,\n",
       "  0.8122818699824765,\n",
       "  0.6932648881769081,\n",
       "  0.7627650016358936,\n",
       "  1.0019452601479633,\n",
       "  0.7802468856330415,\n",
       "  0.6156115028385859,\n",
       "  0.501280150438185,\n",
       "  0.9097388863668696,\n",
       "  0.696570322808302,\n",
       "  0.7126809351352065,\n",
       "  1.0013163377772787,\n",
       "  0.7678801305154246,\n",
       "  0.7016225320777403,\n",
       "  0.8108669684979111,\n",
       "  0.7891914469381575,\n",
       "  0.7528794874869691,\n",
       "  0.9733300429748472,\n",
       "  0.723609436430618,\n",
       "  0.6805215238094209,\n",
       "  0.7287861314016131,\n",
       "  0.9011431868332891,\n",
       "  0.6969317236612188,\n",
       "  0.6582476601888746,\n",
       "  0.8626903485236735,\n",
       "  0.8154256280231991,\n",
       "  0.9218392375511668,\n",
       "  0.6682711047324524,\n",
       "  0.6981455198480075,\n",
       "  0.7431586474914815,\n",
       "  0.7268190146054839,\n",
       "  0.9192256958420263,\n",
       "  0.8878976621154374,\n",
       "  0.6609915834553082,\n",
       "  0.6042983885557762,\n",
       "  0.6442961982898792,\n",
       "  0.7612937819989696,\n",
       "  0.8179798247478244,\n",
       "  0.6991805587772845,\n",
       "  0.8003686119497045,\n",
       "  0.6886554542106023,\n",
       "  0.9169614159465133,\n",
       "  0.7066054261922077,\n",
       "  0.6824715345223896,\n",
       "  0.680779291706397,\n",
       "  0.7469966451194546,\n",
       "  0.7863245142804987,\n",
       "  0.729535333004462,\n",
       "  0.700819440812465,\n",
       "  0.5456031729436264,\n",
       "  0.6993121352801792,\n",
       "  0.6555097231288667,\n",
       "  0.7088570486582505,\n",
       "  0.5097869873768893,\n",
       "  0.8411870964475615,\n",
       "  0.5484432019474716,\n",
       "  0.8854453968993069,\n",
       "  0.6303629538803459,\n",
       "  0.9844932228329635,\n",
       "  0.8474354277362074,\n",
       "  0.7956653807767788,\n",
       "  0.7999157041247974,\n",
       "  0.6380362362654375,\n",
       "  0.8445114644210634,\n",
       "  0.7393516764168945,\n",
       "  0.8723767528906456,\n",
       "  0.7680439988855581,\n",
       "  0.7761489085656064,\n",
       "  0.8343237254988138,\n",
       "  0.6234933618071226,\n",
       "  0.6550653709588459,\n",
       "  ...],\n",
       " [0.6985857142857143,\n",
       "  0.7880571428571429,\n",
       "  0.8079857142857143,\n",
       "  0.8172285714285714,\n",
       "  0.8238285714285715,\n",
       "  0.8272857142857143,\n",
       "  0.8285285714285714,\n",
       "  0.8375,\n",
       "  0.8409857142857143,\n",
       "  0.8434142857142857,\n",
       "  0.8430571428571428,\n",
       "  0.8460714285714286,\n",
       "  0.8454571428571429,\n",
       "  0.8507857142857143,\n",
       "  0.8532571428571428,\n",
       "  0.854],\n",
       " [0.6911268038071845,\n",
       "  0.7817009517961314,\n",
       "  0.8013509364445809,\n",
       "  0.8087196806877495,\n",
       "  0.8114829597789377,\n",
       "  0.8151673319005219,\n",
       "  0.8206938900828984,\n",
       "  0.8271415412956709,\n",
       "  0.8256063862450107,\n",
       "  0.828062634326067,\n",
       "  0.829290758366595,\n",
       "  0.8338962235185754,\n",
       "  0.8314399754375192,\n",
       "  0.8348173165489714,\n",
       "  0.8375805956401596,\n",
       "  0.8403438747313479])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "import pickle\n",
    "results_s = None\n",
    "with open(\"save_new.pkl\", \"rb\") as result:\n",
    "  results_s = pickle.load(result)\n",
    "results_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Params: conv1_w Shape: (5, 5, 3, 8)\n",
      "Loading Params: conv1_b Shape: (8,)\n",
      "Loading Params: conv2_w Shape: (6, 6, 8, 4)\n",
      "Loading Params: conv2_b Shape: (4,)\n",
      "Loading Params: fc1_w Shape: (2500, 10)\n",
      "Loading Params: fc1_b Shape: (10,)\n",
      "Loading Params: fc2_w Shape: (10, 10)\n",
      "Loading Params: fc2_b Shape: (10,)\n",
      "(Iteration 1 / 2730) loss: 0.5114457496456871\n",
      "(Iteration 101 / 2730) loss: 0.48602731272052563\n",
      "(Iteration 201 / 2730) loss: 0.32383455603011685\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "model = SmallConvolutionalNetwork()\n",
    "loss_f = cross_entropy()\n",
    "\n",
    "\n",
    "n_results = None\n",
    "#############################################################################\n",
    "# TODO: Use the train_net function you completed to train a network         #\n",
    "#############################################################################\n",
    "optimizer =  Adam(model.net, 0.0004995)\n",
    "\n",
    "model.net.load(opt_params)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "lr_decay = .999\n",
    "lr_decay_every = 10\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "n_results = train_net(data_dict, model, loss_f, optimizer, batch_size, epochs, \n",
    "                    lr_decay, lr_decay_every, show_every=100, verbose=True)\n",
    "n_opt_params, n_loss_hist, n_train_acc_hist, n_val_acc_hist = n_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to generate the training plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "opt_params, loss_hist, train_acc_hist, val_acc_hist = results\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "loss_hist_ = loss_hist[1::100]  # sparse the curve a bit\n",
    "plt.plot(loss_hist_, '-o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(train_acc_hist, '-o', label='Training')\n",
    "plt.plot(val_acc_hist, '-o', label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Layers [5pts]\n",
    "\n",
    "An interesting finding from early research in convolutional networks was that the learned convolutions resembled filters used for things like edge detection. Complete the code below to visualize the filters in the first convolutional layer of your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im_array = None\n",
    "nrows, ncols = None, None\n",
    "\n",
    "###################################################\n",
    "# TODO: read the weights in the convolutional     #\n",
    "# layer and reshape them to a grid of images to   #\n",
    "# view with matplotlib.                           #\n",
    "###################################################\n",
    "filters = model.net.get_params(\"conv1_w\")\n",
    "filters = np.sum(filters, axis=2) * 255\n",
    "filters = filters.astype(np.uint8)\n",
    "filters_shaped = np.moveaxis(filters, -1, 0).tolist()\n",
    "\n",
    "_, axs = plt.subplots(2, 4, figsize = (16, 16))\n",
    "axs = axs.flatten()\n",
    "for img, ax in zip(filters_shaped, axs):\n",
    "    ax.imshow(img)\n",
    "plt.show()\n",
    "###################################################\n",
    "#                END OF YOUR CODE                 #\n",
    "###################################################\n",
    "\n",
    "# plt.imshow(im_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inline Question: Comment below on what kinds of filters you see. Include your response in your submission [5pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the darker areas corresponding to background/noise while whiter represents the edges and greyish representing some kind of noise, below is my interpretation of the 8 filters from the 1st convolutional layer (going from left to right, row by row)\n",
    "\n",
    "1. The first filter looks like it is highlighting a slight curve which might correspond to the curved areas of 6, 8, 9 or 0.\n",
    "2. The filter looks like to have captured more noise than the others with a single dot denoted by the white pixel. It can be either a noise or some information captured from the dataset.\n",
    "3. It seems like the L-shaped area is corresponding to a edge of the digit 5\n",
    "4. The bright parts of the filter looks like a small curving edge which might be corresponding to regions in the digit 6.\n",
    "5. The bright vertical pixels seems to be representing a straight vertical line. It might be corresponding to the same in digits - 1, 5, 7, 9.\n",
    "6. The bright horizontal line seems to be corresponding to an horizontal edge. Like the top line of 5. or 7\n",
    "7. The curve looking area seems to be corresponding to a downward curve or a small curve like in the ending of digit 5.\n",
    "8. The kind of C shaped bright pixels looks like edges with a bit of sides coming out of it. Like in the middle part of 5.\n",
    "\n",
    "Note: I have used digits in the explanation to aid the visualization of the reader. It might not correspond to that actual digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "Please prepare a PDF document `problem_2_solution.pdf` in the root directory of this repository with all plots and inline answers of your solution. Concretely, the document should contain the following items in strict order:\n",
    "1. Training loss / accuracy curves for CNN training\n",
    "2. Visualization of convolutional filters\n",
    "3. Answers to inline questions about convolutional filters\n",
    "\n",
    "Note that you still need to submit the jupyter notebook with all generated solutions. We will randomly pick submissions and check that the plots in the PDF and in the notebook are equivalent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
