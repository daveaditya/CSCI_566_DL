{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Incorporating CNNs\n",
    "\n",
    "* Learning Objective: In this problem, you will learn how to deeply understand how Convolutional Neural Networks work by implementing one.\n",
    "* Provided Code: We provide the skeletons of classes you need to complete. Forward checking and gradient checkings are provided for verifying your implementation as well.\n",
    "* TODOs: you will implement a Convolutional Layer and a MaxPooling Layer to improve on your classification results in part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from lib.mlp.fully_conn import *\n",
    "from lib.mlp.layer_utils import *\n",
    "from lib.mlp.datasets import *\n",
    "from lib.mlp.train import *\n",
    "from lib.cnn.layer_utils import *\n",
    "from lib.cnn.cnn_models import *\n",
    "from lib.grad_check import *\n",
    "from lib.optim import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data (SVHN)\n",
    "Run the following code block to download SVHN dataset and load in the properly splitted SVHN data. The script `get_datasets.sh` use `wget` to download the SVHN dataset. If you have a trouble with executing `get_datasets.sh`, you can manually download the dataset and extract files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-20 18:53:53--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
      "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
      "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 182040794 (174M) [text/plain]\n",
      "Saving to: ‘data/train_32x32.mat’\n",
      "\n",
      "train_32x32.mat     100%[===================>] 173.61M   657KB/s    in 5m 5s   \n",
      "\n",
      "2022-02-20 18:58:58 (583 KB/s) - ‘data/train_32x32.mat’ saved [182040794/182040794]\n",
      "\n",
      "--2022-02-20 18:58:58--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
      "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
      "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 64275384 (61M) [text/plain]\n",
      "Saving to: ‘data/test_32x32.mat’\n",
      "\n",
      "test_32x32.mat      100%[===================>]  61.30M   591KB/s    in 1m 51s  \n",
      "\n",
      "2022-02-20 19:00:49 (567 KB/s) - ‘data/test_32x32.mat’ saved [64275384/64275384]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./get_datasets.sh\n",
    "# !get_datasets.sh for windows users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: data_train Shape: (70000, 32, 32, 3)\n",
      "Name: labels_train Shape: (70000,)\n",
      "Name: data_val Shape: (3257, 32, 32, 3)\n",
      "Name: labels_val Shape: (3257,)\n",
      "Name: data_test Shape: (26032, 32, 32, 3)\n",
      "Name: labels_test Shape: (26032,)\n"
     ]
    }
   ],
   "source": [
    "data = SVHN_data()\n",
    "for k, v in data.items():\n",
    "    print (\"Name: {} Shape: {}\".format(k, v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "We will use convolutional neural networks to try to improve on the results from Problem 1. Convolutional layers make the assumption that local pixels are more important for prediction than far-away pixels. This allows us to form networks that are robust to small changes in positioning in images.\n",
    "\n",
    "### Convolutional Layer Output size calculation [2pts]\n",
    "\n",
    "As you have learned, two important parameters of a convolutional layer are its stride and padding. To warm up, we will need to calculate the output size of a convolutional layer given its stride and padding. To do this, open the `lib/cnn/layer_utils.py` file and fill out the TODO section in the `get_output_size` function in the ConvLayer2D class. \n",
    "\n",
    "Implement your function so that it returns the correct size as indicated by the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received [32, 16, 16, 16] and expected [32, 16, 16, 16]\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "input_image = np.zeros([32, 28, 28, 3]) # a stack of 32 28 by 28 rgb images\n",
    "\n",
    "in_channels = input_image.shape[-1] #must agree with the last dimension of the input image\n",
    "k_size = 4 \n",
    "n_filt = 16\n",
    "\n",
    "conv_layer = ConvLayer2D(in_channels, k_size, n_filt, stride=2, padding=3)\n",
    "output_size = conv_layer.get_output_size(input_image.shape) \n",
    "\n",
    "print(\"Received {} and expected [32, 16, 16, 16]\".format(output_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer Forward Pass [5pts]\n",
    "\n",
    "Now, we will implement the forward pass of a convolutional layer. Fill in the TODO block in the `forward` function of the ConvLayer2D class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received output shape: (1, 4, 4, 2), Expected output shape: (1, 4, 4, 2)\n",
      "Difference:  5.110565335399418e-08\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "# Test the convolutional forward function\n",
    "input_image = np.linspace(-0.1, 0.4, num=1*8*8*1).reshape([1, 8, 8, 1]) # a single 8 by 8 grayscale image\n",
    "in_channels, k_size, n_filt = 1, 5, 2\n",
    "\n",
    "weight_size = k_size*k_size*in_channels*n_filt\n",
    "bias_size = n_filt\n",
    "\n",
    "single_conv = ConvLayer2D(in_channels, k_size, n_filt, stride=1, padding=0, name=\"conv_test\")\n",
    "\n",
    "w = np.linspace(-0.2, 0.2, num=weight_size).reshape(k_size, k_size, in_channels, n_filt)\n",
    "b = np.linspace(-0.3, 0.3, num=bias_size)\n",
    "\n",
    "single_conv.params[single_conv.w_name] = w\n",
    "single_conv.params[single_conv.b_name] = b\n",
    "\n",
    "out = single_conv.forward(input_image)\n",
    "\n",
    "print(\"Received output shape: {}, Expected output shape: (1, 4, 4, 2)\".format(out.shape))\n",
    "\n",
    "correct_out = np.array([[\n",
    "   [[-0.03874312, 0.57000324],\n",
    "   [-0.03955296, 0.57081309],\n",
    "   [-0.04036281, 0.57162293],\n",
    "   [-0.04117266, 0.57243278]],\n",
    "\n",
    "  [[-0.0452219, 0.57648202],\n",
    "   [-0.04603175, 0.57729187],\n",
    "   [-0.04684159, 0.57810172],\n",
    "   [-0.04765144, 0.57891156]],\n",
    "\n",
    "  [[-0.05170068, 0.5829608 ],\n",
    "   [-0.05251053, 0.58377065],\n",
    "   [-0.05332038, 0.5845805 ],\n",
    "   [-0.05413022, 0.58539035]],\n",
    "\n",
    "  [[-0.05817946, 0.58943959],\n",
    "   [-0.05898931, 0.59024943],\n",
    "   [-0.05979916, 0.59105928],\n",
    "   [-0.06060901, 0.59186913]]]])\n",
    "\n",
    "\n",
    "# Compare your output with the above pre-computed ones. \n",
    "# The difference should not be larger than 1e-8\n",
    "print (\"Difference: \", rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Layer Backward [5pts]\n",
    "\n",
    "Now complete the backward pass of a convolutional layer. Fill in the TODO block in the `backward` function of the ConvLayer2D class. Check you results with this code and expect differences of less than 1e-6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimg Error:  2.6294797003498437e-07\n",
      "dw Error:  1.5793360396074264e-08\n",
      "db Error:  3.029810082779965e-10\n",
      "dimg Shape:  (15, 8, 8, 3) (15, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "# Test the conv backward function\n",
    "img = np.random.randn(15, 8, 8, 3)\n",
    "w = np.random.randn(4, 4, 3, 12)\n",
    "b = np.random.randn(12)\n",
    "dout = np.random.randn(15, 4, 4, 12)\n",
    "\n",
    "single_conv = ConvLayer2D(input_channels=3, kernel_size=4, number_filters=12, stride=2, padding=1, name=\"conv_test\")\n",
    "single_conv.params[single_conv.w_name] = w\n",
    "single_conv.params[single_conv.b_name] = b\n",
    "\n",
    "dimg_num = eval_numerical_gradient_array(lambda x: single_conv.forward(img), img, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: single_conv.forward(img), w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: single_conv.forward(img), b, dout)\n",
    "\n",
    "out = single_conv.forward(img)\n",
    "\n",
    "dimg = single_conv.backward(dout)\n",
    "dw = single_conv.grads[single_conv.w_name]\n",
    "db = single_conv.grads[single_conv.b_name]\n",
    "\n",
    "# The error should be around 1e-8\n",
    "print(\"dimg Error: \", rel_error(dimg_num, dimg))\n",
    "# The errors should be around 1e-8\n",
    "print(\"dw Error: \", rel_error(dw_num, dw))\n",
    "print(\"db Error: \", rel_error(db_num, db))\n",
    "# The shapes should be same\n",
    "print(\"dimg Shape: \", dimg.shape, img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max pooling Layer\n",
    "Now we will implement maxpooling layers, which can help to reduce the image size while preserving the overall structure of the image.\n",
    "\n",
    "### Forward Pass max pooling [5pts]\n",
    "Fill out the TODO block in the `forward` function of the MaxPoolingLayer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received output shape: (1, 3, 3, 1), Expected output shape: (1, 3, 3, 1)\n",
      "Difference:  1.8750000280978013e-08\n"
     ]
    }
   ],
   "source": [
    "# Test the convolutional forward function\n",
    "input_image = np.linspace(-0.1, 0.4, num=64).reshape([1, 8, 8, 1]) # a single 8 by 8 grayscale image\n",
    "\n",
    "maxpool= MaxPoolingLayer(pool_size=4, stride=2, name=\"maxpool_test\")\n",
    "out = maxpool.forward(input_image)\n",
    "\n",
    "print(\"Received output shape: {}, Expected output shape: (1, 3, 3, 1)\".format(out.shape))\n",
    "\n",
    "correct_out = np.array([[\n",
    "   [[0.11428571],\n",
    "   [0.13015873],\n",
    "   [0.14603175]],\n",
    "\n",
    "  [[0.24126984],\n",
    "   [0.25714286],\n",
    "   [0.27301587]],\n",
    "\n",
    "  [[0.36825397],\n",
    "   [0.38412698],\n",
    "   [0.4       ]]]])\n",
    "\n",
    "# Compare your output with the above pre-computed ones. \n",
    "# The difference should not be larger than 1e-8\n",
    "print (\"Difference: \", rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Pass Max pooling [5pts]\n",
    "Fill out the `backward` function in the MaxPoolingLayer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimg Error:  3.2772667075661996e-12\n",
      "dimg Shape:  (15, 8, 8, 3) (15, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "img = np.random.randn(15, 8, 8, 3)\n",
    "\n",
    "dout = np.random.randn(15, 3, 3, 3)\n",
    "\n",
    "maxpool= MaxPoolingLayer(pool_size=4, stride=2, name=\"maxpool_test\")\n",
    "\n",
    "dimg_num = eval_numerical_gradient_array(lambda x: maxpool.forward(img), img, dout)\n",
    "\n",
    "out = maxpool.forward(img)\n",
    "dimg = maxpool.backward(dout)\n",
    "\n",
    "# The error should be around 1e-8\n",
    "print(\"dimg Error: \", rel_error(dimg_num, dimg))\n",
    "# The shapes should be same\n",
    "print(\"dimg Shape: \", dimg.shape, img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a Small Fully Connected Network [3pts]\n",
    "Please find the `TestCNN` class in `lib/cnn/cnn_models.py`.\n",
    "Again you only need to complete few lines of code in the TODO block.\n",
    "Please design a Convolutional --> Maxpool --> flatten --> fc network where the shapes of parameters match the given shapes.\n",
    "Please insert the corresponding names you defined for each layer to param_name_w, and param_name_b respectively.\n",
    "Here you only modify the param_name part, the _w, and _b are automatically assigned during network setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ... \n",
      "Passed!\n",
      "Testing test-time forward pass ... \n",
      "Passed!\n",
      "Testing the loss ...\n",
      "Passed!\n",
      "Testing the gradients (error should be no larger than 1e-6) ...\n",
      "conv_b relative error: 3.95e-09\n",
      "conv_w relative error: 9.10e-10\n",
      "fc_b relative error: 9.76e-11\n",
      "fc_w relative error: 3.89e-07\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "model = TestCNN()\n",
    "loss_func = cross_entropy()\n",
    "\n",
    "B, H, W, iC = 4, 8, 8, 3 #batch, height, width, in_channels\n",
    "k = 3 #kernel size\n",
    "oC, Hi, O = 3, 27, 5 # out channels, Hidden Layer input, Output size\n",
    "std = 0.02\n",
    "x = np.random.randn(B,H,W,iC)\n",
    "y = np.random.randint(O, size=B)\n",
    "\n",
    "print (\"Testing initialization ... \")\n",
    "\n",
    "###################################################\n",
    "# TODO: param_name should be replaced accordingly  #\n",
    "###################################################\n",
    "w1_std = abs(model.net.get_params(\"conv_w\").std() - std)\n",
    "b1 = model.net.get_params(\"conv_b\").std()\n",
    "w2_std = abs(model.net.get_params(\"fc_w\").std() - std)\n",
    "b2 = model.net.get_params(\"fc_b\").std()\n",
    "###################################################\n",
    "#                END OF YOUR CODE                 #\n",
    "###################################################\n",
    "\n",
    "assert w1_std < std / 10, \"First layer weights do not seem right\"\n",
    "assert np.all(b1 == 0), \"First layer biases do not seem right\"\n",
    "assert w2_std < std / 10, \"Second layer weights do not seem right\"\n",
    "assert np.all(b2 == 0), \"Second layer biases do not seem right\"\n",
    "print (\"Passed!\")\n",
    "\n",
    "print (\"Testing test-time forward pass ... \")\n",
    "w1 = np.linspace(-0.7, 0.3, num=k*k*iC*oC).reshape(k,k,iC,oC)\n",
    "w2 = np.linspace(-0.2, 0.2, num=Hi*O).reshape(Hi, O)\n",
    "b1 = np.linspace(-0.6, 0.2, num=oC)\n",
    "b2 = np.linspace(-0.9, 0.1, num=O)\n",
    "\n",
    "###################################################\n",
    "# TODO: param_name should be replaced accordingly  #\n",
    "###################################################\n",
    "model.net.assign(\"conv_w\", w1)\n",
    "model.net.assign(\"conv_b\", b1)\n",
    "model.net.assign(\"fc_w\", w2)\n",
    "model.net.assign(\"fc_b\", b2)\n",
    "###################################################\n",
    "#                END OF YOUR CODE                 #\n",
    "###################################################\n",
    "\n",
    "feats = np.linspace(-5.5, 4.5, num=B*H*W*iC).reshape(B,H,W,iC)\n",
    "scores = model.forward(feats)\n",
    "correct_scores = np.asarray([[-13.85107294, -11.52845818,  -9.20584342,  -6.88322866,  -4.5606139 ],\n",
    " [-11.44514171, -10.21200524 , -8.97886878 , -7.74573231 , -6.51259584],\n",
    " [ -9.03921048,  -8.89555231 , -8.75189413 , -8.60823596,  -8.46457778],\n",
    " [ -6.63327925 , -7.57909937 , -8.52491949 , -9.4707396 , -10.41655972]])\n",
    "scores_diff = np.sum(np.abs(scores - correct_scores))\n",
    "assert scores_diff < 1e-6, \"Your implementation might be wrong!\"\n",
    "print (\"Passed!\")\n",
    "\n",
    "print (\"Testing the loss ...\",)\n",
    "y = np.asarray([0, 2, 1, 4])\n",
    "loss = loss_func.forward(scores, y)\n",
    "dLoss = loss_func.backward()\n",
    "correct_loss = 4.56046848799693\n",
    "assert abs(loss - correct_loss) < 1e-10, \"Your implementation might be wrong!\"\n",
    "print (\"Passed!\")\n",
    "\n",
    "print (\"Testing the gradients (error should be no larger than 1e-6) ...\")\n",
    "din = model.backward(dLoss)\n",
    "for layer in model.net.layers:\n",
    "    if not layer.params:\n",
    "        continue\n",
    "    for name in sorted(layer.grads):\n",
    "        f = lambda _: loss_func.forward(model.forward(feats), y)\n",
    "        grad_num = eval_numerical_gradient(f, layer.params[name], verbose=False)\n",
    "        print ('%s relative error: %.2e' % (name, rel_error(grad_num, layer.grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Network [25pts]\n",
    "In this section, we defined a `SmallConvolutionalNetwork` class for you to fill in the TODO block in `lib/cnn/cnn_models.py`.\n",
    "\n",
    "Here please design a network with at most two convolutions and two maxpooling layers (you may use less).\n",
    "You can adjust the parameters for any layer, and include layers other than those listed above that you have implemented.\n",
    "You are also free to select any optimizer you have implemented (with any learning rate).\n",
    "\n",
    "Try to find a combination that is able to achieve 88% validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange the data\n",
    "data_dict = {\n",
    "    \"data_train\": (data[\"data_train\"], data[\"labels_train\"]),\n",
    "    \"data_val\": (data[\"data_val\"], data[\"labels_val\"]),\n",
    "    \"data_test\": (data[\"data_test\"], data[\"labels_test\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (70000, 32, 32, 3)\n",
      "Flattened data input size: 3072\n",
      "Number of data classes: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape:\", data_dict[\"data_train\"][0].shape)\n",
    "print(\"Flattened data input size:\", np.prod(data[\"data_train\"].shape[1:]))\n",
    "print(\"Number of data classes:\", max(data['labels_train']) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 8736) loss: 2.3025692361523573\n",
      "(Iteration 11 / 8736) loss: 2.301131189418036\n",
      "(Iteration 21 / 8736) loss: 2.2860649533493866\n",
      "(Iteration 31 / 8736) loss: 2.221109912842827\n",
      "(Iteration 41 / 8736) loss: 2.2290769569746334\n",
      "(Iteration 51 / 8736) loss: 2.2400685617898093\n",
      "(Iteration 61 / 8736) loss: 2.250430597875989\n",
      "(Iteration 71 / 8736) loss: 2.26803713314918\n",
      "(Iteration 81 / 8736) loss: 2.2160666061241687\n",
      "(Iteration 91 / 8736) loss: 2.2303456716343573\n",
      "(Iteration 101 / 8736) loss: 2.2709827590455194\n",
      "(Iteration 111 / 8736) loss: 2.2109240321973247\n",
      "(Iteration 121 / 8736) loss: 2.2655509932366904\n",
      "(Iteration 131 / 8736) loss: 2.2314824013070957\n",
      "(Iteration 141 / 8736) loss: 2.2716762084580573\n",
      "(Iteration 151 / 8736) loss: 2.2783913251465964\n",
      "(Iteration 161 / 8736) loss: 2.2574348274719496\n",
      "(Iteration 171 / 8736) loss: 2.1968933477766615\n",
      "(Iteration 181 / 8736) loss: 2.231393260209555\n",
      "(Iteration 191 / 8736) loss: 2.2339351016620395\n",
      "(Iteration 201 / 8736) loss: 2.2872238981398887\n",
      "(Iteration 211 / 8736) loss: 2.286153518173568\n",
      "(Iteration 221 / 8736) loss: 2.228039485440323\n",
      "(Iteration 231 / 8736) loss: 2.2344668687944385\n",
      "(Iteration 241 / 8736) loss: 2.2223279250917987\n",
      "(Iteration 251 / 8736) loss: 2.1796721584185783\n",
      "(Iteration 261 / 8736) loss: 2.254128721067678\n",
      "(Iteration 271 / 8736) loss: 2.1910594086099997\n",
      "(Iteration 281 / 8736) loss: 2.2785287227426694\n",
      "(Iteration 291 / 8736) loss: 2.2837987076825415\n",
      "(Iteration 301 / 8736) loss: 2.187511211563512\n",
      "(Iteration 311 / 8736) loss: 2.2362536676495846\n",
      "(Iteration 321 / 8736) loss: 2.230943088907542\n",
      "(Iteration 331 / 8736) loss: 2.2086938834518297\n",
      "(Iteration 341 / 8736) loss: 2.2106823299877605\n",
      "(Iteration 351 / 8736) loss: 2.201864456166168\n",
      "(Iteration 361 / 8736) loss: 2.224875625187746\n",
      "(Iteration 371 / 8736) loss: 2.288174811785664\n",
      "(Iteration 381 / 8736) loss: 2.2358631455713445\n",
      "(Iteration 391 / 8736) loss: 2.2087666697308346\n",
      "(Iteration 401 / 8736) loss: 2.2258143947950426\n",
      "(Iteration 411 / 8736) loss: 2.188737157828337\n",
      "(Iteration 421 / 8736) loss: 2.2055058362265485\n",
      "(Iteration 431 / 8736) loss: 2.1783088795438066\n",
      "(Iteration 441 / 8736) loss: 2.061659972712775\n",
      "(Iteration 451 / 8736) loss: 2.112531442103179\n",
      "(Iteration 461 / 8736) loss: 2.1634158360936744\n",
      "(Iteration 471 / 8736) loss: 2.0195857737297938\n",
      "(Iteration 481 / 8736) loss: 1.8703983156096595\n",
      "(Iteration 491 / 8736) loss: 2.0360539875296944\n",
      "(Iteration 501 / 8736) loss: 2.1394075381281357\n",
      "(Iteration 511 / 8736) loss: 1.9769670900161334\n",
      "(Iteration 521 / 8736) loss: 2.0140539936105415\n",
      "(Iteration 531 / 8736) loss: 1.8536145266665056\n",
      "(Iteration 541 / 8736) loss: 1.9301064106872328\n",
      "(Epoch 1 / 16) Training Accuracy: 0.29241428571428574, Validation Accuracy: 0.2818544673011974\n",
      "(Iteration 551 / 8736) loss: 1.9027103052401206\n",
      "(Iteration 561 / 8736) loss: 1.8735460951125238\n",
      "(Iteration 571 / 8736) loss: 1.8601377025253076\n",
      "(Iteration 581 / 8736) loss: 2.01971221217273\n",
      "(Iteration 591 / 8736) loss: 1.8178714480309\n",
      "(Iteration 601 / 8736) loss: 1.7539445163699132\n",
      "(Iteration 611 / 8736) loss: 1.9203465406567772\n",
      "(Iteration 621 / 8736) loss: 1.8456493778891747\n",
      "(Iteration 631 / 8736) loss: 1.7189500439116905\n",
      "(Iteration 641 / 8736) loss: 1.749509932588786\n",
      "(Iteration 651 / 8736) loss: 1.6999947568863192\n",
      "(Iteration 661 / 8736) loss: 1.790451739420281\n",
      "(Iteration 671 / 8736) loss: 1.8675805192180885\n",
      "(Iteration 681 / 8736) loss: 1.8459121958894606\n",
      "(Iteration 691 / 8736) loss: 1.718099147073573\n",
      "(Iteration 701 / 8736) loss: 1.6502761032073918\n",
      "(Iteration 711 / 8736) loss: 1.7778785452671322\n",
      "(Iteration 721 / 8736) loss: 1.9255256150905984\n",
      "(Iteration 731 / 8736) loss: 1.7366097366807078\n",
      "(Iteration 741 / 8736) loss: 1.618780329755198\n",
      "(Iteration 751 / 8736) loss: 1.699308207828738\n",
      "(Iteration 761 / 8736) loss: 1.5847953509717367\n",
      "(Iteration 771 / 8736) loss: 1.7066597454993007\n",
      "(Iteration 781 / 8736) loss: 1.8249040205001559\n",
      "(Iteration 791 / 8736) loss: 1.5776565750193856\n",
      "(Iteration 801 / 8736) loss: 1.5855782223233161\n",
      "(Iteration 811 / 8736) loss: 1.7507704151035681\n",
      "(Iteration 821 / 8736) loss: 1.6214296102885677\n",
      "(Iteration 831 / 8736) loss: 1.4653718101299171\n",
      "(Iteration 841 / 8736) loss: 1.6763192478219968\n",
      "(Iteration 851 / 8736) loss: 1.655667783298704\n",
      "(Iteration 861 / 8736) loss: 1.7671881804963792\n",
      "(Iteration 871 / 8736) loss: 1.6990826655007645\n",
      "(Iteration 881 / 8736) loss: 1.6344592310013832\n",
      "(Iteration 891 / 8736) loss: 1.7350024302318001\n",
      "(Iteration 901 / 8736) loss: 1.5993393174363848\n",
      "(Iteration 911 / 8736) loss: 1.5273444137025192\n",
      "(Iteration 921 / 8736) loss: 1.469364533195264\n",
      "(Iteration 931 / 8736) loss: 1.6001585964767695\n",
      "(Iteration 941 / 8736) loss: 1.4179039634437165\n",
      "(Iteration 951 / 8736) loss: 1.3941068882473964\n",
      "(Iteration 961 / 8736) loss: 1.4245139497868733\n",
      "(Iteration 971 / 8736) loss: 1.5189665385083437\n",
      "(Iteration 981 / 8736) loss: 1.5207010841551203\n",
      "(Iteration 991 / 8736) loss: 1.597323595016803\n",
      "(Iteration 1001 / 8736) loss: 1.5883211386414646\n",
      "(Iteration 1011 / 8736) loss: 1.5465343601055888\n",
      "(Iteration 1021 / 8736) loss: 1.3204480490763073\n",
      "(Iteration 1031 / 8736) loss: 1.5309439779506402\n",
      "(Iteration 1041 / 8736) loss: 1.426487648073913\n",
      "(Iteration 1051 / 8736) loss: 1.245173262103121\n",
      "(Iteration 1061 / 8736) loss: 1.4126042902176987\n",
      "(Iteration 1071 / 8736) loss: 1.4949888693341358\n",
      "(Iteration 1081 / 8736) loss: 1.372969809275048\n",
      "(Iteration 1091 / 8736) loss: 1.4521529956608534\n",
      "(Epoch 2 / 16) Training Accuracy: 0.5243571428571429, Validation Accuracy: 0.5118206938900829\n",
      "(Iteration 1101 / 8736) loss: 1.5463913600408734\n",
      "(Iteration 1111 / 8736) loss: 1.3605237310348326\n",
      "(Iteration 1121 / 8736) loss: 1.4104033324000116\n",
      "(Iteration 1131 / 8736) loss: 1.4838855584949462\n",
      "(Iteration 1141 / 8736) loss: 1.2548789809664072\n",
      "(Iteration 1151 / 8736) loss: 1.6041386889470262\n",
      "(Iteration 1161 / 8736) loss: 1.419304811418302\n",
      "(Iteration 1171 / 8736) loss: 1.3337729387351354\n",
      "(Iteration 1181 / 8736) loss: 1.5212879328051347\n",
      "(Iteration 1191 / 8736) loss: 1.3410376721645594\n",
      "(Iteration 1201 / 8736) loss: 1.4387234550665906\n",
      "(Iteration 1211 / 8736) loss: 1.4045360683404742\n",
      "(Iteration 1221 / 8736) loss: 1.4380649636386413\n",
      "(Iteration 1231 / 8736) loss: 1.2889331470450827\n",
      "(Iteration 1241 / 8736) loss: 1.1386397891347764\n",
      "(Iteration 1251 / 8736) loss: 1.364234334910487\n",
      "(Iteration 1261 / 8736) loss: 1.4434664804001187\n",
      "(Iteration 1271 / 8736) loss: 1.1975413766337024\n",
      "(Iteration 1281 / 8736) loss: 1.418619908810123\n",
      "(Iteration 1291 / 8736) loss: 1.192365877659548\n",
      "(Iteration 1301 / 8736) loss: 1.2983454868473046\n",
      "(Iteration 1311 / 8736) loss: 1.3611316200217236\n",
      "(Iteration 1321 / 8736) loss: 1.2971248225891976\n",
      "(Iteration 1331 / 8736) loss: 1.5410382490949663\n",
      "(Iteration 1341 / 8736) loss: 1.4114259044158604\n",
      "(Iteration 1351 / 8736) loss: 1.186268197395739\n",
      "(Iteration 1361 / 8736) loss: 1.4974115090758937\n",
      "(Iteration 1371 / 8736) loss: 1.3060313951138796\n",
      "(Iteration 1381 / 8736) loss: 1.3768526367418306\n",
      "(Iteration 1391 / 8736) loss: 1.1526490751995704\n",
      "(Iteration 1401 / 8736) loss: 1.141907838105803\n",
      "(Iteration 1411 / 8736) loss: 1.1113029211642345\n",
      "(Iteration 1421 / 8736) loss: 1.3201654098503113\n",
      "(Iteration 1431 / 8736) loss: 1.1786264940559503\n",
      "(Iteration 1441 / 8736) loss: 1.1931747291964614\n",
      "(Iteration 1451 / 8736) loss: 1.4653202912303944\n",
      "(Iteration 1461 / 8736) loss: 1.3946246919260556\n",
      "(Iteration 1471 / 8736) loss: 1.3450276979895157\n",
      "(Iteration 1481 / 8736) loss: 1.44920981448007\n",
      "(Iteration 1491 / 8736) loss: 1.283572464771626\n",
      "(Iteration 1501 / 8736) loss: 1.1130780583788193\n",
      "(Iteration 1511 / 8736) loss: 1.4167057958928801\n",
      "(Iteration 1521 / 8736) loss: 1.3124499228455178\n",
      "(Iteration 1531 / 8736) loss: 1.1591715469014832\n",
      "(Iteration 1541 / 8736) loss: 1.1922456771236525\n",
      "(Iteration 1551 / 8736) loss: 1.2667196239178267\n",
      "(Iteration 1561 / 8736) loss: 1.291543216265326\n",
      "(Iteration 1571 / 8736) loss: 1.1056019109335729\n",
      "(Iteration 1581 / 8736) loss: 1.2676766571947453\n",
      "(Iteration 1591 / 8736) loss: 1.5173837733365583\n",
      "(Iteration 1601 / 8736) loss: 1.2356379781378937\n",
      "(Iteration 1611 / 8736) loss: 1.1665661005207981\n",
      "(Iteration 1621 / 8736) loss: 1.2086809750951555\n",
      "(Iteration 1631 / 8736) loss: 1.1924579178322134\n",
      "(Epoch 3 / 16) Training Accuracy: 0.6091285714285715, Validation Accuracy: 0.591341725514277\n",
      "(Iteration 1641 / 8736) loss: 1.1765657203275062\n",
      "(Iteration 1651 / 8736) loss: 1.272532922101043\n",
      "(Iteration 1661 / 8736) loss: 1.2559048156224277\n",
      "(Iteration 1671 / 8736) loss: 1.1429661465814425\n",
      "(Iteration 1681 / 8736) loss: 1.0909738165567526\n",
      "(Iteration 1691 / 8736) loss: 1.097862869481099\n",
      "(Iteration 1701 / 8736) loss: 1.2147437994694663\n",
      "(Iteration 1711 / 8736) loss: 1.1946698863317011\n",
      "(Iteration 1721 / 8736) loss: 1.3080588554367258\n",
      "(Iteration 1731 / 8736) loss: 1.2354487469109996\n",
      "(Iteration 1741 / 8736) loss: 1.2768935117355464\n",
      "(Iteration 1751 / 8736) loss: 1.0238140079739635\n",
      "(Iteration 1761 / 8736) loss: 1.098499110858016\n",
      "(Iteration 1771 / 8736) loss: 1.3392158444849849\n",
      "(Iteration 1781 / 8736) loss: 1.057959850854127\n",
      "(Iteration 1791 / 8736) loss: 1.098649025239243\n",
      "(Iteration 1801 / 8736) loss: 0.9979549813276518\n",
      "(Iteration 1811 / 8736) loss: 1.0385249460963102\n",
      "(Iteration 1821 / 8736) loss: 1.1224804586180193\n",
      "(Iteration 1831 / 8736) loss: 1.2245390882275622\n",
      "(Iteration 1841 / 8736) loss: 1.110056301371146\n",
      "(Iteration 1851 / 8736) loss: 1.4534258590038094\n",
      "(Iteration 1861 / 8736) loss: 1.2103658004357956\n",
      "(Iteration 1871 / 8736) loss: 1.0605063138096735\n",
      "(Iteration 1881 / 8736) loss: 1.1241304991639918\n",
      "(Iteration 1891 / 8736) loss: 1.030355658087689\n",
      "(Iteration 1901 / 8736) loss: 1.2237273396773192\n",
      "(Iteration 1911 / 8736) loss: 1.344483908105939\n",
      "(Iteration 1921 / 8736) loss: 1.3719100041888512\n",
      "(Iteration 1931 / 8736) loss: 1.3107910095897661\n",
      "(Iteration 1941 / 8736) loss: 1.2955298971224571\n",
      "(Iteration 1951 / 8736) loss: 1.1654385070960174\n",
      "(Iteration 1961 / 8736) loss: 1.0674481933373583\n",
      "(Iteration 1971 / 8736) loss: 1.0590994523639818\n",
      "(Iteration 1981 / 8736) loss: 1.1945852470896468\n",
      "(Iteration 1991 / 8736) loss: 1.0310764681382063\n",
      "(Iteration 2001 / 8736) loss: 1.1028351087837605\n",
      "(Iteration 2011 / 8736) loss: 1.0717926967026727\n",
      "(Iteration 2021 / 8736) loss: 1.035714627918232\n",
      "(Iteration 2031 / 8736) loss: 1.0317717233285333\n",
      "(Iteration 2041 / 8736) loss: 0.9805523604849106\n",
      "(Iteration 2051 / 8736) loss: 0.9720143202329509\n",
      "(Iteration 2061 / 8736) loss: 1.0439407426942922\n",
      "(Iteration 2071 / 8736) loss: 1.0631848227208716\n",
      "(Iteration 2081 / 8736) loss: 1.0330913176969752\n",
      "(Iteration 2091 / 8736) loss: 1.0422556289929816\n",
      "(Iteration 2101 / 8736) loss: 1.1400494436015662\n",
      "(Iteration 2111 / 8736) loss: 0.9527996619505411\n",
      "(Iteration 2121 / 8736) loss: 1.1966207452472735\n",
      "(Iteration 2131 / 8736) loss: 1.112239851770165\n",
      "(Iteration 2141 / 8736) loss: 1.039660267088087\n",
      "(Iteration 2151 / 8736) loss: 1.0459772481813208\n",
      "(Iteration 2161 / 8736) loss: 1.1316278016362862\n",
      "(Iteration 2171 / 8736) loss: 1.0122925343736826\n",
      "(Iteration 2181 / 8736) loss: 0.8493363139588131\n",
      "(Epoch 4 / 16) Training Accuracy: 0.6648428571428572, Validation Accuracy: 0.6466073073380412\n",
      "(Iteration 2191 / 8736) loss: 0.9391450983398925\n",
      "(Iteration 2201 / 8736) loss: 0.9434262919119496\n",
      "(Iteration 2211 / 8736) loss: 1.0581091404297551\n",
      "(Iteration 2221 / 8736) loss: 1.0167777962589444\n",
      "(Iteration 2231 / 8736) loss: 1.046642490806569\n",
      "(Iteration 2241 / 8736) loss: 0.983573809164068\n",
      "(Iteration 2251 / 8736) loss: 1.113736268823748\n",
      "(Iteration 2261 / 8736) loss: 0.9407394780656015\n",
      "(Iteration 2271 / 8736) loss: 0.9220458447095927\n",
      "(Iteration 2281 / 8736) loss: 0.9070458493477975\n",
      "(Iteration 2291 / 8736) loss: 1.3114965299867067\n",
      "(Iteration 2301 / 8736) loss: 0.9897527141850159\n",
      "(Iteration 2311 / 8736) loss: 0.9993490533505546\n",
      "(Iteration 2321 / 8736) loss: 0.9721781261589278\n",
      "(Iteration 2331 / 8736) loss: 1.013693847779614\n",
      "(Iteration 2341 / 8736) loss: 0.9652228483541415\n",
      "(Iteration 2351 / 8736) loss: 0.8463087951261494\n",
      "(Iteration 2361 / 8736) loss: 1.075825826698301\n",
      "(Iteration 2371 / 8736) loss: 1.0801992133271814\n",
      "(Iteration 2381 / 8736) loss: 1.007107645786547\n",
      "(Iteration 2391 / 8736) loss: 0.9864189925650666\n",
      "(Iteration 2401 / 8736) loss: 1.1828537522086486\n",
      "(Iteration 2411 / 8736) loss: 1.0206361697776536\n",
      "(Iteration 2421 / 8736) loss: 1.063100491551506\n",
      "(Iteration 2431 / 8736) loss: 1.0709082277845152\n",
      "(Iteration 2441 / 8736) loss: 1.0212942072489701\n",
      "(Iteration 2451 / 8736) loss: 1.1329409208763823\n",
      "(Iteration 2461 / 8736) loss: 1.0519320512507455\n",
      "(Iteration 2471 / 8736) loss: 1.150702720883771\n",
      "(Iteration 2481 / 8736) loss: 0.8725976977042345\n",
      "(Iteration 2491 / 8736) loss: 1.1406890342843392\n",
      "(Iteration 2501 / 8736) loss: 0.9003713319817822\n",
      "(Iteration 2511 / 8736) loss: 0.7902820844062441\n",
      "(Iteration 2521 / 8736) loss: 1.063860867150411\n",
      "(Iteration 2531 / 8736) loss: 0.9003818637478066\n",
      "(Iteration 2541 / 8736) loss: 0.9605277196477222\n",
      "(Iteration 2551 / 8736) loss: 1.1614869651505448\n",
      "(Iteration 2561 / 8736) loss: 1.2793488887251965\n",
      "(Iteration 2571 / 8736) loss: 0.9630773244330744\n",
      "(Iteration 2581 / 8736) loss: 1.2514190837999701\n",
      "(Iteration 2591 / 8736) loss: 0.9586839838209497\n",
      "(Iteration 2601 / 8736) loss: 1.1241466036392234\n",
      "(Iteration 2611 / 8736) loss: 0.9565711140287178\n",
      "(Iteration 2621 / 8736) loss: 1.1132901064920326\n",
      "(Iteration 2631 / 8736) loss: 0.8125488038822332\n",
      "(Iteration 2641 / 8736) loss: 0.9712190493868004\n",
      "(Iteration 2651 / 8736) loss: 1.0622901201565262\n",
      "(Iteration 2661 / 8736) loss: 0.9921088532699519\n",
      "(Iteration 2671 / 8736) loss: 0.820580010520863\n",
      "(Iteration 2681 / 8736) loss: 1.0327582321038322\n",
      "(Iteration 2691 / 8736) loss: 0.9022152256977323\n",
      "(Iteration 2701 / 8736) loss: 1.1651702544682285\n",
      "(Iteration 2711 / 8736) loss: 0.9942678517144021\n",
      "(Iteration 2721 / 8736) loss: 0.9345403762711887\n",
      "(Epoch 5 / 16) Training Accuracy: 0.6901714285714285, Validation Accuracy: 0.6757752533005834\n",
      "(Iteration 2731 / 8736) loss: 1.1422593181398697\n",
      "(Iteration 2741 / 8736) loss: 1.0463956395945702\n",
      "(Iteration 2751 / 8736) loss: 0.9652459899560796\n",
      "(Iteration 2761 / 8736) loss: 0.9513366961674862\n",
      "(Iteration 2771 / 8736) loss: 1.1149804308497127\n",
      "(Iteration 2781 / 8736) loss: 0.9402609513495739\n",
      "(Iteration 2791 / 8736) loss: 0.9833093699732078\n",
      "(Iteration 2801 / 8736) loss: 0.8472626179393519\n",
      "(Iteration 2811 / 8736) loss: 1.1591136057194915\n",
      "(Iteration 2821 / 8736) loss: 0.8351901347179359\n",
      "(Iteration 2831 / 8736) loss: 0.9987045347017955\n",
      "(Iteration 2841 / 8736) loss: 1.0591465905966184\n",
      "(Iteration 2851 / 8736) loss: 0.9897907074835883\n",
      "(Iteration 2861 / 8736) loss: 0.7946610493318748\n",
      "(Iteration 2871 / 8736) loss: 1.0158942028296545\n",
      "(Iteration 2881 / 8736) loss: 0.9625510441216817\n",
      "(Iteration 2891 / 8736) loss: 1.0356792365096934\n",
      "(Iteration 2901 / 8736) loss: 1.0298206356321726\n",
      "(Iteration 2911 / 8736) loss: 0.810578075892136\n",
      "(Iteration 2921 / 8736) loss: 0.8527083697397809\n",
      "(Iteration 2931 / 8736) loss: 0.8272868602880178\n",
      "(Iteration 2941 / 8736) loss: 0.9476234285037971\n",
      "(Iteration 2951 / 8736) loss: 0.9723198626400293\n",
      "(Iteration 2961 / 8736) loss: 0.9839130844688978\n",
      "(Iteration 2971 / 8736) loss: 1.1155847059424404\n",
      "(Iteration 2981 / 8736) loss: 1.1005192648860427\n",
      "(Iteration 2991 / 8736) loss: 0.9185866926660994\n",
      "(Iteration 3001 / 8736) loss: 1.0175914941044888\n",
      "(Iteration 3011 / 8736) loss: 0.9557478723948639\n",
      "(Iteration 3021 / 8736) loss: 1.085320758121958\n",
      "(Iteration 3031 / 8736) loss: 0.9355232613445174\n",
      "(Iteration 3041 / 8736) loss: 1.0688500467429853\n",
      "(Iteration 3051 / 8736) loss: 1.0874127898768333\n",
      "(Iteration 3061 / 8736) loss: 0.9134716488092067\n",
      "(Iteration 3071 / 8736) loss: 0.8933229660893324\n",
      "(Iteration 3081 / 8736) loss: 0.8777241359096652\n",
      "(Iteration 3091 / 8736) loss: 0.9851843683849176\n",
      "(Iteration 3101 / 8736) loss: 1.118831502425514\n",
      "(Iteration 3111 / 8736) loss: 1.1143869444744092\n",
      "(Iteration 3121 / 8736) loss: 0.90744005539141\n",
      "(Iteration 3131 / 8736) loss: 0.8720229311829466\n",
      "(Iteration 3141 / 8736) loss: 0.9733530047777746\n",
      "(Iteration 3151 / 8736) loss: 0.9022060841137789\n",
      "(Iteration 3161 / 8736) loss: 0.9699476112140867\n",
      "(Iteration 3171 / 8736) loss: 0.9472187480035148\n",
      "(Iteration 3181 / 8736) loss: 1.0417942242945442\n",
      "(Iteration 3191 / 8736) loss: 1.1477548423956356\n",
      "(Iteration 3201 / 8736) loss: 0.8472397461782891\n",
      "(Iteration 3211 / 8736) loss: 1.0601572587430825\n",
      "(Iteration 3221 / 8736) loss: 0.7329819965924042\n",
      "(Iteration 3231 / 8736) loss: 0.915728021822132\n",
      "(Iteration 3241 / 8736) loss: 0.8103519481533917\n",
      "(Iteration 3251 / 8736) loss: 1.09254463001814\n",
      "(Iteration 3261 / 8736) loss: 0.9203092224716805\n",
      "(Iteration 3271 / 8736) loss: 0.9165050314293949\n",
      "(Epoch 6 / 16) Training Accuracy: 0.726, Validation Accuracy: 0.7153822536076143\n",
      "(Iteration 3281 / 8736) loss: 0.8031802995800522\n",
      "(Iteration 3291 / 8736) loss: 0.8802411695592761\n",
      "(Iteration 3301 / 8736) loss: 0.8494218156077387\n",
      "(Iteration 3311 / 8736) loss: 0.7919950761078881\n",
      "(Iteration 3321 / 8736) loss: 0.7037203844271049\n",
      "(Iteration 3331 / 8736) loss: 0.7682061187531499\n",
      "(Iteration 3341 / 8736) loss: 0.8550126221534506\n",
      "(Iteration 3351 / 8736) loss: 0.7938199760673453\n",
      "(Iteration 3361 / 8736) loss: 0.846028289357251\n",
      "(Iteration 3371 / 8736) loss: 0.8445031419741036\n",
      "(Iteration 3381 / 8736) loss: 0.9872168992911217\n",
      "(Iteration 3391 / 8736) loss: 0.9637642250379204\n",
      "(Iteration 3401 / 8736) loss: 0.7588812083000547\n",
      "(Iteration 3411 / 8736) loss: 1.0146398495109732\n",
      "(Iteration 3421 / 8736) loss: 0.8243507521811347\n",
      "(Iteration 3431 / 8736) loss: 0.8836389661948468\n",
      "(Iteration 3441 / 8736) loss: 0.9793272652992492\n",
      "(Iteration 3451 / 8736) loss: 0.9124868317636622\n",
      "(Iteration 3461 / 8736) loss: 0.9550304250117349\n",
      "(Iteration 3471 / 8736) loss: 0.8496544680084437\n",
      "(Iteration 3481 / 8736) loss: 0.774527634977978\n",
      "(Iteration 3491 / 8736) loss: 0.7011049214729571\n",
      "(Iteration 3501 / 8736) loss: 0.8808433780229881\n",
      "(Iteration 3511 / 8736) loss: 0.783541791502631\n",
      "(Iteration 3521 / 8736) loss: 0.8654177683983985\n",
      "(Iteration 3531 / 8736) loss: 0.8597703749782694\n",
      "(Iteration 3541 / 8736) loss: 0.9449426475190742\n",
      "(Iteration 3551 / 8736) loss: 0.8039939397804475\n",
      "(Iteration 3561 / 8736) loss: 1.000494641586537\n",
      "(Iteration 3571 / 8736) loss: 1.024942515624191\n",
      "(Iteration 3581 / 8736) loss: 0.71210103722683\n",
      "(Iteration 3591 / 8736) loss: 0.8772684403487048\n",
      "(Iteration 3601 / 8736) loss: 0.7449773270801556\n",
      "(Iteration 3611 / 8736) loss: 0.8011461936131864\n",
      "(Iteration 3621 / 8736) loss: 0.8808036506346538\n",
      "(Iteration 3631 / 8736) loss: 0.8276398451943279\n",
      "(Iteration 3641 / 8736) loss: 0.9050452744016718\n",
      "(Iteration 3651 / 8736) loss: 0.6637416443352715\n",
      "(Iteration 3661 / 8736) loss: 0.802719343969563\n",
      "(Iteration 3671 / 8736) loss: 0.7339288605114966\n",
      "(Iteration 3681 / 8736) loss: 0.9688839419140509\n",
      "(Iteration 3691 / 8736) loss: 0.8652900844940966\n",
      "(Iteration 3701 / 8736) loss: 0.7822592936616326\n",
      "(Iteration 3711 / 8736) loss: 0.8611247674921501\n",
      "(Iteration 3721 / 8736) loss: 0.7920437578074064\n",
      "(Iteration 3731 / 8736) loss: 0.9785576295017262\n",
      "(Iteration 3741 / 8736) loss: 0.9766527605263604\n",
      "(Iteration 3751 / 8736) loss: 0.8564135876675272\n",
      "(Iteration 3761 / 8736) loss: 0.7596367346403204\n",
      "(Iteration 3771 / 8736) loss: 0.7850196324223339\n",
      "(Iteration 3781 / 8736) loss: 0.6946524014513896\n",
      "(Iteration 3791 / 8736) loss: 0.6808919453697663\n",
      "(Iteration 3801 / 8736) loss: 0.8062943002391249\n",
      "(Iteration 3811 / 8736) loss: 0.7739663847951226\n",
      "(Iteration 3821 / 8736) loss: 0.7359809511732518\n",
      "(Epoch 7 / 16) Training Accuracy: 0.7461142857142857, Validation Accuracy: 0.7396377034080442\n",
      "(Iteration 3831 / 8736) loss: 0.8574489084880695\n",
      "(Iteration 3841 / 8736) loss: 0.9015092241639978\n",
      "(Iteration 3851 / 8736) loss: 0.7086171592317284\n",
      "(Iteration 3861 / 8736) loss: 0.9283811919082625\n",
      "(Iteration 3871 / 8736) loss: 0.8837456194632319\n",
      "(Iteration 3881 / 8736) loss: 0.9255032084781194\n",
      "(Iteration 3891 / 8736) loss: 0.7902706781782473\n",
      "(Iteration 3901 / 8736) loss: 0.6781386455181357\n",
      "(Iteration 3911 / 8736) loss: 0.9258195674282272\n",
      "(Iteration 3921 / 8736) loss: 0.964449495271559\n",
      "(Iteration 3931 / 8736) loss: 0.8424820149737969\n",
      "(Iteration 3941 / 8736) loss: 0.6961636117778202\n",
      "(Iteration 3951 / 8736) loss: 0.7934904474706744\n",
      "(Iteration 3961 / 8736) loss: 0.7748611134511623\n",
      "(Iteration 3971 / 8736) loss: 0.8956393761809125\n",
      "(Iteration 3981 / 8736) loss: 0.9770845268650274\n",
      "(Iteration 3991 / 8736) loss: 0.8072896497257344\n",
      "(Iteration 4001 / 8736) loss: 0.8706923964367053\n",
      "(Iteration 4011 / 8736) loss: 0.8189944640137705\n",
      "(Iteration 4021 / 8736) loss: 0.7111337156966073\n",
      "(Iteration 4031 / 8736) loss: 0.8194169966961714\n",
      "(Iteration 4041 / 8736) loss: 0.7584206850878941\n",
      "(Iteration 4051 / 8736) loss: 0.8617175006022499\n",
      "(Iteration 4061 / 8736) loss: 0.9638700156707817\n",
      "(Iteration 4071 / 8736) loss: 0.6581015535757108\n",
      "(Iteration 4081 / 8736) loss: 0.7654582284340882\n",
      "(Iteration 4091 / 8736) loss: 0.7708423708010763\n",
      "(Iteration 4101 / 8736) loss: 0.7852580739055511\n",
      "(Iteration 4111 / 8736) loss: 0.9774994902022605\n",
      "(Iteration 4121 / 8736) loss: 0.916910666910804\n",
      "(Iteration 4131 / 8736) loss: 0.8325010449355764\n",
      "(Iteration 4141 / 8736) loss: 0.8497582712090462\n",
      "(Iteration 4151 / 8736) loss: 0.8976976154843221\n",
      "(Iteration 4161 / 8736) loss: 0.8231745599543295\n",
      "(Iteration 4171 / 8736) loss: 0.9655896884015873\n",
      "(Iteration 4181 / 8736) loss: 0.8050398545832259\n",
      "(Iteration 4191 / 8736) loss: 0.8589794875922131\n",
      "(Iteration 4201 / 8736) loss: 0.6671496533440073\n",
      "(Iteration 4211 / 8736) loss: 0.8130849380186242\n",
      "(Iteration 4221 / 8736) loss: 0.9606494822641378\n",
      "(Iteration 4231 / 8736) loss: 0.6607338272287452\n",
      "(Iteration 4241 / 8736) loss: 1.0418803200378284\n",
      "(Iteration 4251 / 8736) loss: 0.7797324597701\n",
      "(Iteration 4261 / 8736) loss: 0.7601522827038234\n",
      "(Iteration 4271 / 8736) loss: 0.9756150250044635\n",
      "(Iteration 4281 / 8736) loss: 0.8822264331945684\n",
      "(Iteration 4291 / 8736) loss: 0.7447453267283983\n",
      "(Iteration 4301 / 8736) loss: 0.7327007140364614\n",
      "(Iteration 4311 / 8736) loss: 0.7676818611943741\n",
      "(Iteration 4321 / 8736) loss: 0.7149782393347464\n",
      "(Iteration 4331 / 8736) loss: 0.707459786865668\n",
      "(Iteration 4341 / 8736) loss: 0.7396306153284659\n",
      "(Iteration 4351 / 8736) loss: 0.7875624299701051\n",
      "(Iteration 4361 / 8736) loss: 0.9404267659588154\n",
      "(Epoch 8 / 16) Training Accuracy: 0.7656, Validation Accuracy: 0.7617439361375499\n",
      "(Iteration 4371 / 8736) loss: 0.6118274537549915\n",
      "(Iteration 4381 / 8736) loss: 0.5920628672417632\n",
      "(Iteration 4391 / 8736) loss: 0.679080362781718\n",
      "(Iteration 4401 / 8736) loss: 0.898804379733356\n",
      "(Iteration 4411 / 8736) loss: 0.8247448539447013\n",
      "(Iteration 4421 / 8736) loss: 0.831586785578723\n",
      "(Iteration 4431 / 8736) loss: 0.8644838982305358\n",
      "(Iteration 4441 / 8736) loss: 0.9618546912567358\n",
      "(Iteration 4451 / 8736) loss: 0.7255888290501167\n",
      "(Iteration 4461 / 8736) loss: 0.7910563999079272\n",
      "(Iteration 4471 / 8736) loss: 0.8790614920051881\n",
      "(Iteration 4481 / 8736) loss: 0.7121353028936992\n",
      "(Iteration 4491 / 8736) loss: 0.7285339959863103\n",
      "(Iteration 4501 / 8736) loss: 0.8003828256462325\n",
      "(Iteration 4511 / 8736) loss: 0.7724095156529673\n",
      "(Iteration 4521 / 8736) loss: 0.8266932292375405\n",
      "(Iteration 4531 / 8736) loss: 0.8544416761784077\n",
      "(Iteration 4541 / 8736) loss: 0.8009246478725993\n",
      "(Iteration 4551 / 8736) loss: 0.8904700999727931\n",
      "(Iteration 4561 / 8736) loss: 0.7548039351194907\n",
      "(Iteration 4571 / 8736) loss: 0.7416716275829637\n",
      "(Iteration 4581 / 8736) loss: 0.918781847173921\n",
      "(Iteration 4591 / 8736) loss: 0.6906013832329623\n",
      "(Iteration 4601 / 8736) loss: 0.8362459690394121\n",
      "(Iteration 4611 / 8736) loss: 0.7437224483153928\n",
      "(Iteration 4621 / 8736) loss: 0.8118512707834314\n",
      "(Iteration 4631 / 8736) loss: 0.6186121336178431\n",
      "(Iteration 4641 / 8736) loss: 0.7513657097001291\n",
      "(Iteration 4651 / 8736) loss: 0.8075629612287832\n",
      "(Iteration 4661 / 8736) loss: 0.8778430031035156\n",
      "(Iteration 4671 / 8736) loss: 0.8606371085933082\n",
      "(Iteration 4681 / 8736) loss: 0.7491775323320343\n",
      "(Iteration 4691 / 8736) loss: 0.6307735786833617\n",
      "(Iteration 4701 / 8736) loss: 0.8320901011778034\n",
      "(Iteration 4711 / 8736) loss: 0.6826674277200794\n",
      "(Iteration 4721 / 8736) loss: 0.747999184576678\n",
      "(Iteration 4731 / 8736) loss: 0.7937175795315832\n",
      "(Iteration 4741 / 8736) loss: 0.5679812292440662\n",
      "(Iteration 4751 / 8736) loss: 0.8130078549978332\n",
      "(Iteration 4761 / 8736) loss: 0.7295265627771429\n",
      "(Iteration 4771 / 8736) loss: 0.6697708997632016\n",
      "(Iteration 4781 / 8736) loss: 0.7725510658092392\n",
      "(Iteration 4791 / 8736) loss: 0.7441923000506493\n",
      "(Iteration 4801 / 8736) loss: 0.7293743319322779\n",
      "(Iteration 4811 / 8736) loss: 0.7383066207749761\n",
      "(Iteration 4821 / 8736) loss: 0.7902423447493276\n",
      "(Iteration 4831 / 8736) loss: 1.1779379985484026\n",
      "(Iteration 4841 / 8736) loss: 0.7405864835286623\n",
      "(Iteration 4851 / 8736) loss: 1.0499202695564067\n",
      "(Iteration 4861 / 8736) loss: 0.647302377371936\n",
      "(Iteration 4871 / 8736) loss: 0.8601567925084493\n",
      "(Iteration 4881 / 8736) loss: 0.9344948970916025\n",
      "(Iteration 4891 / 8736) loss: 0.6614660741911247\n",
      "(Iteration 4901 / 8736) loss: 0.6117169564074298\n",
      "(Iteration 4911 / 8736) loss: 0.6546394838503937\n",
      "(Epoch 9 / 16) Training Accuracy: 0.7730714285714285, Validation Accuracy: 0.7712618974516426\n",
      "(Iteration 4921 / 8736) loss: 1.0049303653464159\n",
      "(Iteration 4931 / 8736) loss: 0.7263048372345824\n",
      "(Iteration 4941 / 8736) loss: 0.87845981966554\n",
      "(Iteration 4951 / 8736) loss: 0.6849491164398881\n",
      "(Iteration 4961 / 8736) loss: 0.6921756180532415\n",
      "(Iteration 4971 / 8736) loss: 0.7564913368157328\n",
      "(Iteration 4981 / 8736) loss: 0.7355043213110508\n",
      "(Iteration 4991 / 8736) loss: 1.0162278922807049\n",
      "(Iteration 5001 / 8736) loss: 0.7487020565757195\n",
      "(Iteration 5011 / 8736) loss: 0.8117300998578231\n",
      "(Iteration 5021 / 8736) loss: 0.7102933801233055\n",
      "(Iteration 5031 / 8736) loss: 0.7954876901518019\n",
      "(Iteration 5041 / 8736) loss: 0.9414383380783283\n",
      "(Iteration 5051 / 8736) loss: 0.6366595079800057\n",
      "(Iteration 5061 / 8736) loss: 0.7061344484809315\n",
      "(Iteration 5071 / 8736) loss: 0.6448916155579169\n",
      "(Iteration 5081 / 8736) loss: 0.6383297015572293\n",
      "(Iteration 5091 / 8736) loss: 0.5254197463296478\n",
      "(Iteration 5101 / 8736) loss: 0.7663778836959547\n",
      "(Iteration 5111 / 8736) loss: 0.839872955380244\n",
      "(Iteration 5121 / 8736) loss: 0.7076378606766034\n",
      "(Iteration 5131 / 8736) loss: 0.7667336030421914\n",
      "(Iteration 5141 / 8736) loss: 0.8017259020408681\n",
      "(Iteration 5151 / 8736) loss: 0.7566763024612075\n",
      "(Iteration 5161 / 8736) loss: 0.9975626497784951\n",
      "(Iteration 5171 / 8736) loss: 0.8395188721427417\n",
      "(Iteration 5181 / 8736) loss: 0.6676373265076057\n",
      "(Iteration 5191 / 8736) loss: 0.8050357675853163\n",
      "(Iteration 5201 / 8736) loss: 0.9439352508537522\n",
      "(Iteration 5211 / 8736) loss: 0.7642116341250759\n",
      "(Iteration 5221 / 8736) loss: 0.953905099485941\n",
      "(Iteration 5231 / 8736) loss: 0.6888800236427026\n",
      "(Iteration 5241 / 8736) loss: 0.7560643132080249\n",
      "(Iteration 5251 / 8736) loss: 0.9147861059696026\n",
      "(Iteration 5261 / 8736) loss: 0.7464597058097713\n",
      "(Iteration 5271 / 8736) loss: 0.8508418057237237\n",
      "(Iteration 5281 / 8736) loss: 0.8505912215975837\n",
      "(Iteration 5291 / 8736) loss: 0.8570924775787249\n",
      "(Iteration 5301 / 8736) loss: 0.6751402637625118\n",
      "(Iteration 5311 / 8736) loss: 0.7661077701068795\n",
      "(Iteration 5321 / 8736) loss: 0.699868463301126\n",
      "(Iteration 5331 / 8736) loss: 0.8705995574663692\n",
      "(Iteration 5341 / 8736) loss: 0.8297201212460373\n",
      "(Iteration 5351 / 8736) loss: 0.7097704837630036\n",
      "(Iteration 5361 / 8736) loss: 0.6750505908864278\n",
      "(Iteration 5371 / 8736) loss: 0.4787741568764996\n",
      "(Iteration 5381 / 8736) loss: 0.786905513348307\n",
      "(Iteration 5391 / 8736) loss: 0.6796012457462489\n",
      "(Iteration 5401 / 8736) loss: 0.6204500941361556\n",
      "(Iteration 5411 / 8736) loss: 0.876919956325252\n",
      "(Iteration 5421 / 8736) loss: 0.5043549521605117\n",
      "(Iteration 5431 / 8736) loss: 0.5954467196276138\n",
      "(Iteration 5441 / 8736) loss: 0.9861134157310338\n",
      "(Iteration 5451 / 8736) loss: 0.7290298352796326\n",
      "(Epoch 10 / 16) Training Accuracy: 0.7882571428571429, Validation Accuracy: 0.7801657967454713\n",
      "Decaying learning rate of the optimizer to 0.00029969999999999997\n",
      "(Iteration 5461 / 8736) loss: 0.7890164295516723\n",
      "(Iteration 5471 / 8736) loss: 0.7515111229220776\n",
      "(Iteration 5481 / 8736) loss: 0.7331819100157989\n",
      "(Iteration 5491 / 8736) loss: 0.9545253987770357\n",
      "(Iteration 5501 / 8736) loss: 0.7827636467152106\n",
      "(Iteration 5511 / 8736) loss: 0.6292677497685099\n",
      "(Iteration 5521 / 8736) loss: 0.6401217164332544\n",
      "(Iteration 5531 / 8736) loss: 0.8132777889957337\n",
      "(Iteration 5541 / 8736) loss: 0.7464610022405862\n",
      "(Iteration 5551 / 8736) loss: 0.685392801387376\n",
      "(Iteration 5561 / 8736) loss: 0.8148762198232239\n",
      "(Iteration 5571 / 8736) loss: 0.8115157039744127\n",
      "(Iteration 5581 / 8736) loss: 0.784878163467949\n",
      "(Iteration 5591 / 8736) loss: 0.7756077469669527\n",
      "(Iteration 5601 / 8736) loss: 0.8672327691518806\n",
      "(Iteration 5611 / 8736) loss: 0.7662132547353131\n",
      "(Iteration 5621 / 8736) loss: 0.636228758476182\n",
      "(Iteration 5631 / 8736) loss: 0.5740220899168064\n",
      "(Iteration 5641 / 8736) loss: 0.4151576586552345\n",
      "(Iteration 5651 / 8736) loss: 0.6609948233382693\n",
      "(Iteration 5661 / 8736) loss: 0.6797457382146004\n",
      "(Iteration 5671 / 8736) loss: 0.6940077592637296\n",
      "(Iteration 5681 / 8736) loss: 0.6350715483611808\n",
      "(Iteration 5691 / 8736) loss: 0.6686399792285127\n",
      "(Iteration 5701 / 8736) loss: 0.8549962633470317\n",
      "(Iteration 5711 / 8736) loss: 0.7264191622217657\n",
      "(Iteration 5721 / 8736) loss: 0.7970744674822691\n",
      "(Iteration 5731 / 8736) loss: 0.6650587193705565\n",
      "(Iteration 5741 / 8736) loss: 0.7257951423883924\n",
      "(Iteration 5751 / 8736) loss: 0.8759106752032122\n",
      "(Iteration 5761 / 8736) loss: 0.9140863069885796\n",
      "(Iteration 5771 / 8736) loss: 0.7302376031371609\n",
      "(Iteration 5781 / 8736) loss: 0.7975651487060916\n",
      "(Iteration 5791 / 8736) loss: 0.6867309052466584\n",
      "(Iteration 5801 / 8736) loss: 0.7236004324736299\n",
      "(Iteration 5811 / 8736) loss: 0.7158628427722027\n",
      "(Iteration 5821 / 8736) loss: 0.7672812079129432\n",
      "(Iteration 5831 / 8736) loss: 0.8489960767233244\n",
      "(Iteration 5841 / 8736) loss: 0.49452050754679633\n",
      "(Iteration 5851 / 8736) loss: 0.6304416771306808\n",
      "(Iteration 5861 / 8736) loss: 0.48646866890565865\n",
      "(Iteration 5871 / 8736) loss: 0.7973809194312658\n",
      "(Iteration 5881 / 8736) loss: 0.6409689774522369\n",
      "(Iteration 5891 / 8736) loss: 1.0671128953179707\n",
      "(Iteration 5901 / 8736) loss: 0.5704325560218323\n",
      "(Iteration 5911 / 8736) loss: 0.7096982979956858\n",
      "(Iteration 5921 / 8736) loss: 0.7320192930706988\n",
      "(Iteration 5931 / 8736) loss: 0.6821567797702738\n",
      "(Iteration 5941 / 8736) loss: 0.6787755408809445\n",
      "(Iteration 5951 / 8736) loss: 0.5848070465358906\n",
      "(Iteration 5961 / 8736) loss: 0.7104507380026063\n",
      "(Iteration 5971 / 8736) loss: 0.7323077209100621\n",
      "(Iteration 5981 / 8736) loss: 0.5963789487187523\n",
      "(Iteration 5991 / 8736) loss: 0.5674547454931077\n",
      "(Iteration 6001 / 8736) loss: 0.6411695990582964\n",
      "(Epoch 11 / 16) Training Accuracy: 0.7953142857142858, Validation Accuracy: 0.7887626650291679\n",
      "(Iteration 6011 / 8736) loss: 0.7372860322469095\n",
      "(Iteration 6021 / 8736) loss: 0.6352658340346375\n",
      "(Iteration 6031 / 8736) loss: 0.699478778443406\n",
      "(Iteration 6041 / 8736) loss: 0.738494580420028\n",
      "(Iteration 6051 / 8736) loss: 0.6675281153480205\n",
      "(Iteration 6061 / 8736) loss: 0.7748255911690617\n",
      "(Iteration 6071 / 8736) loss: 0.8563646367802469\n",
      "(Iteration 6081 / 8736) loss: 0.6739565324767414\n",
      "(Iteration 6091 / 8736) loss: 0.8785210285109228\n",
      "(Iteration 6101 / 8736) loss: 0.8420012549020982\n",
      "(Iteration 6111 / 8736) loss: 0.7437959125555242\n",
      "(Iteration 6121 / 8736) loss: 0.7866166246527396\n",
      "(Iteration 6131 / 8736) loss: 0.7463859377270012\n",
      "(Iteration 6141 / 8736) loss: 0.6697275609663237\n",
      "(Iteration 6151 / 8736) loss: 0.6867802527328308\n",
      "(Iteration 6161 / 8736) loss: 0.6883944825793409\n",
      "(Iteration 6171 / 8736) loss: 0.7039319282661841\n",
      "(Iteration 6181 / 8736) loss: 0.5708780706795745\n",
      "(Iteration 6191 / 8736) loss: 0.6154078686341139\n",
      "(Iteration 6201 / 8736) loss: 0.5471461831065844\n",
      "(Iteration 6211 / 8736) loss: 0.804045486659489\n",
      "(Iteration 6221 / 8736) loss: 0.8020658592110751\n",
      "(Iteration 6231 / 8736) loss: 0.6647396972453766\n",
      "(Iteration 6241 / 8736) loss: 0.6493728422846747\n",
      "(Iteration 6251 / 8736) loss: 0.6445716699815094\n",
      "(Iteration 6261 / 8736) loss: 0.5870501204772295\n",
      "(Iteration 6271 / 8736) loss: 0.8245188685437138\n",
      "(Iteration 6281 / 8736) loss: 0.651483423940849\n",
      "(Iteration 6291 / 8736) loss: 0.7752328738625416\n",
      "(Iteration 6301 / 8736) loss: 0.7446848685614356\n",
      "(Iteration 6311 / 8736) loss: 0.6309705580774301\n",
      "(Iteration 6321 / 8736) loss: 0.741036356191307\n",
      "(Iteration 6331 / 8736) loss: 0.49880400690910526\n",
      "(Iteration 6341 / 8736) loss: 0.6869666175762655\n",
      "(Iteration 6351 / 8736) loss: 0.7112769022945943\n",
      "(Iteration 6361 / 8736) loss: 0.6717061986974591\n",
      "(Iteration 6371 / 8736) loss: 0.7137748556993619\n",
      "(Iteration 6381 / 8736) loss: 0.7073247033980463\n",
      "(Iteration 6391 / 8736) loss: 0.5839597345072187\n",
      "(Iteration 6401 / 8736) loss: 0.44678613434142905\n",
      "(Iteration 6411 / 8736) loss: 0.7737867336034622\n",
      "(Iteration 6421 / 8736) loss: 0.4118388721389969\n",
      "(Iteration 6431 / 8736) loss: 0.5544494488368358\n",
      "(Iteration 6441 / 8736) loss: 0.8479843678604163\n",
      "(Iteration 6451 / 8736) loss: 0.6167955874124957\n",
      "(Iteration 6461 / 8736) loss: 0.6350881979477438\n",
      "(Iteration 6471 / 8736) loss: 0.8305272789827729\n",
      "(Iteration 6481 / 8736) loss: 0.6660343215302571\n",
      "(Iteration 6491 / 8736) loss: 0.6902102879992493\n",
      "(Iteration 6501 / 8736) loss: 0.6145738360884082\n",
      "(Iteration 6511 / 8736) loss: 0.9583571410015007\n",
      "(Iteration 6521 / 8736) loss: 0.4433602720324811\n",
      "(Iteration 6531 / 8736) loss: 0.6431315133235883\n",
      "(Iteration 6541 / 8736) loss: 0.9086141153097176\n",
      "(Iteration 6551 / 8736) loss: 0.788004780540603\n",
      "(Epoch 12 / 16) Training Accuracy: 0.8015, Validation Accuracy: 0.7955173472520725\n",
      "(Iteration 6561 / 8736) loss: 0.8117532885399007\n",
      "(Iteration 6571 / 8736) loss: 0.7200178531292488\n",
      "(Iteration 6581 / 8736) loss: 0.6293759866359976\n",
      "(Iteration 6591 / 8736) loss: 0.6054269417349214\n",
      "(Iteration 6601 / 8736) loss: 0.6961441348700664\n",
      "(Iteration 6611 / 8736) loss: 0.6344932113443074\n",
      "(Iteration 6621 / 8736) loss: 0.6353379325808952\n",
      "(Iteration 6631 / 8736) loss: 0.7461270032567393\n",
      "(Iteration 6641 / 8736) loss: 0.7755576593303527\n",
      "(Iteration 6651 / 8736) loss: 0.751359345852467\n",
      "(Iteration 6661 / 8736) loss: 0.8258844250079037\n",
      "(Iteration 6671 / 8736) loss: 0.5268463206395055\n",
      "(Iteration 6681 / 8736) loss: 0.8372865165603676\n",
      "(Iteration 6691 / 8736) loss: 0.49791294057581126\n",
      "(Iteration 6701 / 8736) loss: 0.7553823341197121\n",
      "(Iteration 6711 / 8736) loss: 0.5966734733145592\n",
      "(Iteration 6721 / 8736) loss: 0.6061147193766042\n",
      "(Iteration 6731 / 8736) loss: 0.5411284995216994\n",
      "(Iteration 6741 / 8736) loss: 0.7184162683716434\n",
      "(Iteration 6751 / 8736) loss: 0.8792632309491932\n",
      "(Iteration 6761 / 8736) loss: 0.8425867527712616\n",
      "(Iteration 6771 / 8736) loss: 0.5978162449274397\n",
      "(Iteration 6781 / 8736) loss: 0.5447063809350039\n",
      "(Iteration 6791 / 8736) loss: 0.5827716457700994\n",
      "(Iteration 6801 / 8736) loss: 0.7531522699571398\n",
      "(Iteration 6811 / 8736) loss: 0.741419806585944\n",
      "(Iteration 6821 / 8736) loss: 0.5078126322982507\n",
      "(Iteration 6831 / 8736) loss: 0.5888468907286518\n",
      "(Iteration 6841 / 8736) loss: 0.7451888512296287\n",
      "(Iteration 6851 / 8736) loss: 0.8113688009771955\n",
      "(Iteration 6861 / 8736) loss: 0.5300358210643638\n",
      "(Iteration 6871 / 8736) loss: 0.7907108808095561\n",
      "(Iteration 6881 / 8736) loss: 0.6771606971866355\n",
      "(Iteration 6891 / 8736) loss: 0.4911100440469661\n",
      "(Iteration 6901 / 8736) loss: 0.6127828045334657\n",
      "(Iteration 6911 / 8736) loss: 0.5897395361705311\n",
      "(Iteration 6921 / 8736) loss: 0.6307941064750057\n",
      "(Iteration 6931 / 8736) loss: 0.6473818834636546\n",
      "(Iteration 6941 / 8736) loss: 1.026983236633181\n",
      "(Iteration 6951 / 8736) loss: 0.6676298458894468\n",
      "(Iteration 6961 / 8736) loss: 0.6774659320502244\n",
      "(Iteration 6971 / 8736) loss: 0.6503379355539622\n",
      "(Iteration 6981 / 8736) loss: 0.7376710555552255\n",
      "(Iteration 6991 / 8736) loss: 0.706257778298964\n",
      "(Iteration 7001 / 8736) loss: 0.5765911952091581\n",
      "(Iteration 7011 / 8736) loss: 0.8302432739795521\n",
      "(Iteration 7021 / 8736) loss: 0.6541293345080438\n",
      "(Iteration 7031 / 8736) loss: 0.6396779089458273\n",
      "(Iteration 7041 / 8736) loss: 0.6649547277562934\n",
      "(Iteration 7051 / 8736) loss: 0.7790687206012151\n",
      "(Iteration 7061 / 8736) loss: 0.6640100116767843\n",
      "(Iteration 7071 / 8736) loss: 0.6185014042907458\n",
      "(Iteration 7081 / 8736) loss: 0.61711544276402\n",
      "(Iteration 7091 / 8736) loss: 0.6896260790559408\n",
      "(Epoch 13 / 16) Training Accuracy: 0.8097285714285715, Validation Accuracy: 0.8056493705864293\n",
      "(Iteration 7101 / 8736) loss: 0.5491667565262645\n",
      "(Iteration 7111 / 8736) loss: 0.5878114308116829\n",
      "(Iteration 7121 / 8736) loss: 0.6595224859196502\n",
      "(Iteration 7131 / 8736) loss: 0.6394018737312801\n",
      "(Iteration 7141 / 8736) loss: 0.7781843601646221\n",
      "(Iteration 7151 / 8736) loss: 0.6787093892541569\n",
      "(Iteration 7161 / 8736) loss: 0.7890895665408955\n",
      "(Iteration 7171 / 8736) loss: 0.6790923609899499\n",
      "(Iteration 7181 / 8736) loss: 0.607127916564131\n",
      "(Iteration 7191 / 8736) loss: 0.7570232469532275\n",
      "(Iteration 7201 / 8736) loss: 0.7108998370445156\n",
      "(Iteration 7211 / 8736) loss: 0.6096478301025446\n",
      "(Iteration 7221 / 8736) loss: 0.7267074549559277\n",
      "(Iteration 7231 / 8736) loss: 0.6645768931807596\n",
      "(Iteration 7241 / 8736) loss: 0.6889256513033787\n",
      "(Iteration 7251 / 8736) loss: 0.6210380147332589\n",
      "(Iteration 7261 / 8736) loss: 0.8062789786830313\n",
      "(Iteration 7271 / 8736) loss: 0.7195896333105124\n",
      "(Iteration 7281 / 8736) loss: 0.6228259463565025\n",
      "(Iteration 7291 / 8736) loss: 0.6745305871920183\n",
      "(Iteration 7301 / 8736) loss: 0.5572038364890943\n",
      "(Iteration 7311 / 8736) loss: 0.7324666714038643\n",
      "(Iteration 7321 / 8736) loss: 0.686906307461116\n",
      "(Iteration 7331 / 8736) loss: 0.4598585446830969\n",
      "(Iteration 7341 / 8736) loss: 0.7283816386469386\n",
      "(Iteration 7351 / 8736) loss: 0.6747111520215316\n",
      "(Iteration 7361 / 8736) loss: 0.823151746941895\n",
      "(Iteration 7371 / 8736) loss: 0.530229215146629\n",
      "(Iteration 7381 / 8736) loss: 0.9238112482057711\n",
      "(Iteration 7391 / 8736) loss: 0.6281989070360379\n",
      "(Iteration 7401 / 8736) loss: 0.6132409641043292\n",
      "(Iteration 7411 / 8736) loss: 0.6739653573136672\n",
      "(Iteration 7421 / 8736) loss: 0.922003272871553\n",
      "(Iteration 7431 / 8736) loss: 0.6391199382094629\n",
      "(Iteration 7441 / 8736) loss: 0.5435013002030379\n",
      "(Iteration 7451 / 8736) loss: 0.815928144783353\n",
      "(Iteration 7461 / 8736) loss: 0.6090993331732859\n",
      "(Iteration 7471 / 8736) loss: 0.6258526209162244\n",
      "(Iteration 7481 / 8736) loss: 0.6241804406466603\n",
      "(Iteration 7491 / 8736) loss: 0.6604849268159853\n",
      "(Iteration 7501 / 8736) loss: 0.693588519948102\n",
      "(Iteration 7511 / 8736) loss: 0.5694263148790241\n",
      "(Iteration 7521 / 8736) loss: 0.8025237564866017\n",
      "(Iteration 7531 / 8736) loss: 0.5359355393601776\n",
      "(Iteration 7541 / 8736) loss: 0.5971380977537749\n",
      "(Iteration 7551 / 8736) loss: 0.8777254407714555\n",
      "(Iteration 7561 / 8736) loss: 0.6560206278844576\n",
      "(Iteration 7571 / 8736) loss: 0.586276748477203\n",
      "(Iteration 7581 / 8736) loss: 0.5514735723571758\n",
      "(Iteration 7591 / 8736) loss: 0.628801124272594\n",
      "(Iteration 7601 / 8736) loss: 0.7098240057846392\n",
      "(Iteration 7611 / 8736) loss: 0.7341121901354131\n",
      "(Iteration 7621 / 8736) loss: 0.5592729037970968\n",
      "(Iteration 7631 / 8736) loss: 0.6850865809775538\n",
      "(Iteration 7641 / 8736) loss: 0.737112619977783\n",
      "(Epoch 14 / 16) Training Accuracy: 0.8159714285714286, Validation Accuracy: 0.8108688977586737\n",
      "(Iteration 7651 / 8736) loss: 0.5793088157662931\n",
      "(Iteration 7661 / 8736) loss: 0.6224197128636645\n",
      "(Iteration 7671 / 8736) loss: 0.5858038496350872\n",
      "(Iteration 7681 / 8736) loss: 0.5094806439553081\n",
      "(Iteration 7691 / 8736) loss: 0.5189889195375461\n",
      "(Iteration 7701 / 8736) loss: 0.7684290836161869\n",
      "(Iteration 7711 / 8736) loss: 0.6751431376326743\n",
      "(Iteration 7721 / 8736) loss: 0.7121526955508276\n",
      "(Iteration 7731 / 8736) loss: 0.721280821593623\n",
      "(Iteration 7741 / 8736) loss: 0.5538478564745861\n",
      "(Iteration 7751 / 8736) loss: 0.5995050418114799\n",
      "(Iteration 7761 / 8736) loss: 0.6929762408981621\n",
      "(Iteration 7771 / 8736) loss: 0.7210733046588854\n",
      "(Iteration 7781 / 8736) loss: 0.599546961101167\n",
      "(Iteration 7791 / 8736) loss: 0.5632629547889637\n",
      "(Iteration 7801 / 8736) loss: 0.8286224757302219\n",
      "(Iteration 7811 / 8736) loss: 0.5521415635572676\n",
      "(Iteration 7821 / 8736) loss: 0.5530584916678378\n",
      "(Iteration 7831 / 8736) loss: 0.4237702807966764\n",
      "(Iteration 7841 / 8736) loss: 0.5152093803742976\n",
      "(Iteration 7851 / 8736) loss: 0.6292220469966714\n",
      "(Iteration 7861 / 8736) loss: 0.7695662237876214\n",
      "(Iteration 7871 / 8736) loss: 0.5947931426298287\n",
      "(Iteration 7881 / 8736) loss: 0.6169673236836807\n",
      "(Iteration 7891 / 8736) loss: 0.46865001891804847\n",
      "(Iteration 7901 / 8736) loss: 0.5422348113760187\n",
      "(Iteration 7911 / 8736) loss: 0.518794380664988\n",
      "(Iteration 7921 / 8736) loss: 0.7087893542460186\n",
      "(Iteration 7931 / 8736) loss: 0.6637125059912364\n",
      "(Iteration 7941 / 8736) loss: 0.6195288731186958\n",
      "(Iteration 7951 / 8736) loss: 0.6044513763882563\n",
      "(Iteration 7961 / 8736) loss: 0.7777749325942351\n",
      "(Iteration 7971 / 8736) loss: 0.5033946960738527\n",
      "(Iteration 7981 / 8736) loss: 0.6022577463957537\n",
      "(Iteration 7991 / 8736) loss: 0.43989759006790424\n",
      "(Iteration 8001 / 8736) loss: 0.7704343795820908\n",
      "(Iteration 8011 / 8736) loss: 0.7585602029330318\n",
      "(Iteration 8021 / 8736) loss: 0.6575258560977175\n",
      "(Iteration 8031 / 8736) loss: 0.599986237808629\n",
      "(Iteration 8041 / 8736) loss: 0.5442364213012575\n",
      "(Iteration 8051 / 8736) loss: 0.6347389554302272\n",
      "(Iteration 8061 / 8736) loss: 0.5142320203713345\n",
      "(Iteration 8071 / 8736) loss: 0.5424721869561117\n",
      "(Iteration 8081 / 8736) loss: 0.8123889783095997\n",
      "(Iteration 8091 / 8736) loss: 0.6254432060224256\n",
      "(Iteration 8101 / 8736) loss: 1.154609842520295\n",
      "(Iteration 8111 / 8736) loss: 0.6201321292097529\n",
      "(Iteration 8121 / 8736) loss: 0.6963514778713361\n",
      "(Iteration 8131 / 8736) loss: 0.5815942113077682\n",
      "(Iteration 8141 / 8736) loss: 0.6437994093714056\n",
      "(Iteration 8151 / 8736) loss: 0.747455725943577\n",
      "(Iteration 8161 / 8736) loss: 0.532358950934325\n",
      "(Iteration 8171 / 8736) loss: 0.5210347728313778\n",
      "(Iteration 8181 / 8736) loss: 0.5029925565017472\n",
      "(Epoch 15 / 16) Training Accuracy: 0.8183285714285714, Validation Accuracy: 0.8176235799815781\n",
      "(Iteration 8191 / 8736) loss: 0.5326592735771214\n",
      "(Iteration 8201 / 8736) loss: 0.5913120204014061\n",
      "(Iteration 8211 / 8736) loss: 0.6554708590643442\n",
      "(Iteration 8221 / 8736) loss: 0.8222353641379568\n",
      "(Iteration 8231 / 8736) loss: 0.625376670480634\n",
      "(Iteration 8241 / 8736) loss: 0.505339591038311\n",
      "(Iteration 8251 / 8736) loss: 0.4770867301387376\n",
      "(Iteration 8261 / 8736) loss: 0.8919326827789869\n",
      "(Iteration 8271 / 8736) loss: 0.7865421385833804\n",
      "(Iteration 8281 / 8736) loss: 0.6227081280378142\n",
      "(Iteration 8291 / 8736) loss: 0.6560186147262858\n",
      "(Iteration 8301 / 8736) loss: 0.5716834898404964\n",
      "(Iteration 8311 / 8736) loss: 0.8146341862564024\n",
      "(Iteration 8321 / 8736) loss: 0.6539427132577333\n",
      "(Iteration 8331 / 8736) loss: 0.5544168757373684\n",
      "(Iteration 8341 / 8736) loss: 0.6748356643757547\n",
      "(Iteration 8351 / 8736) loss: 0.580180752388165\n",
      "(Iteration 8361 / 8736) loss: 0.6771744732891812\n",
      "(Iteration 8371 / 8736) loss: 0.5034432158047122\n",
      "(Iteration 8381 / 8736) loss: 0.5586164329940967\n",
      "(Iteration 8391 / 8736) loss: 0.6551249853483686\n",
      "(Iteration 8401 / 8736) loss: 0.5966553192776943\n",
      "(Iteration 8411 / 8736) loss: 0.6874982097898448\n",
      "(Iteration 8421 / 8736) loss: 0.6634963620399317\n",
      "(Iteration 8431 / 8736) loss: 0.6424459849160148\n",
      "(Iteration 8441 / 8736) loss: 0.7713006691048486\n",
      "(Iteration 8451 / 8736) loss: 0.5578987152494368\n",
      "(Iteration 8461 / 8736) loss: 0.636354808419505\n",
      "(Iteration 8471 / 8736) loss: 0.7587318847870221\n",
      "(Iteration 8481 / 8736) loss: 0.6206746742044831\n",
      "(Iteration 8491 / 8736) loss: 0.560590634197008\n",
      "(Iteration 8501 / 8736) loss: 0.5526358911848736\n",
      "(Iteration 8511 / 8736) loss: 0.6342824040824522\n",
      "(Iteration 8521 / 8736) loss: 0.6902351571201177\n",
      "(Iteration 8531 / 8736) loss: 0.7479213511511841\n",
      "(Iteration 8541 / 8736) loss: 0.5696990358794545\n",
      "(Iteration 8551 / 8736) loss: 0.572616360522653\n",
      "(Iteration 8561 / 8736) loss: 0.519741840981092\n",
      "(Iteration 8571 / 8736) loss: 0.725358604334001\n",
      "(Iteration 8581 / 8736) loss: 0.7152951330528344\n",
      "(Iteration 8591 / 8736) loss: 0.5185178562904075\n",
      "(Iteration 8601 / 8736) loss: 0.5627539598643939\n",
      "(Iteration 8611 / 8736) loss: 0.8049840488750921\n",
      "(Iteration 8621 / 8736) loss: 0.5634039966775649\n",
      "(Iteration 8631 / 8736) loss: 0.6682437327350477\n",
      "(Iteration 8641 / 8736) loss: 0.849631936426159\n",
      "(Iteration 8651 / 8736) loss: 0.6809368267342972\n",
      "(Iteration 8661 / 8736) loss: 0.6498967090196869\n",
      "(Iteration 8671 / 8736) loss: 0.6624125032147826\n",
      "(Iteration 8681 / 8736) loss: 0.6261055766020315\n",
      "(Iteration 8691 / 8736) loss: 0.5537015751263734\n",
      "(Iteration 8701 / 8736) loss: 0.6840633445898671\n",
      "(Iteration 8711 / 8736) loss: 0.6555548973373746\n",
      "(Iteration 8721 / 8736) loss: 0.6220715959317439\n",
      "(Iteration 8731 / 8736) loss: 0.8358048809946479\n",
      "(Epoch 16 / 16) Training Accuracy: 0.8253285714285714, Validation Accuracy: 0.8225360761436905\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "model = SmallConvolutionalNetwork()\n",
    "loss_f = cross_entropy()\n",
    "\n",
    "\n",
    "results = None\n",
    "#############################################################################\n",
    "# TODO: Use the train_net function you completed to train a network         #\n",
    "#############################################################################\n",
    "optimizer =  Adam(model.net, 3e-4)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 16\n",
    "lr_decay = .999\n",
    "lr_decay_every = 10\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "results = train_net(data_dict, model, loss_f, optimizer, batch_size, epochs, \n",
    "                    lr_decay, lr_decay_every, show_every=10, verbose=True)\n",
    "opt_params, loss_hist, train_acc_hist, val_acc_hist = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"save_new.pkl\", \"wb\") as result:\n",
    "  result.write(pickle.dumps(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'conv1_w': array([[[[-1.02509461e-01,  7.55769935e-02,  2.02150191e-01,\n",
       "            -8.64808937e-02, -1.47261235e-01, -8.33692413e-02,\n",
       "            -2.24511258e-01, -8.15010328e-02],\n",
       "           [-5.40068093e-02,  4.76273819e-02,  1.96840868e-01,\n",
       "            -1.25876354e-01, -8.56156753e-02, -1.40164022e-01,\n",
       "            -2.05916842e-01, -5.07163806e-02],\n",
       "           [ 7.29720825e-03,  7.41368437e-02,  2.44050580e-01,\n",
       "            -3.83936343e-02, -9.25298014e-02, -3.98324362e-02,\n",
       "            -1.89931827e-01, -5.20270879e-02]],\n",
       "  \n",
       "          [[ 1.40301486e-02,  4.80076662e-02,  1.61993122e-01,\n",
       "            -1.66356953e-01, -5.13969770e-02, -1.26339265e-01,\n",
       "            -2.02185053e-01, -5.93954900e-02],\n",
       "           [ 8.57938889e-03,  5.35812792e-02,  1.34877087e-01,\n",
       "            -1.98961898e-01, -2.87712732e-02, -1.06219319e-01,\n",
       "            -2.43507883e-01,  3.60025896e-02],\n",
       "           [ 4.28341303e-02,  6.33601881e-03,  1.24154816e-01,\n",
       "            -1.03518936e-01, -3.26190086e-02, -6.87552560e-02,\n",
       "            -1.53192935e-01, -2.05470224e-02]],\n",
       "  \n",
       "          [[ 1.26379403e-01,  1.45325822e-01,  5.29473124e-02,\n",
       "            -1.40874473e-01,  4.16281647e-02, -7.47481792e-02,\n",
       "            -1.83694026e-01,  2.54722459e-02],\n",
       "           [ 1.36518908e-01,  1.42289791e-01,  6.39492441e-02,\n",
       "            -1.50022594e-01,  1.13429303e-02, -5.34360353e-02,\n",
       "            -2.11452260e-01,  1.76191005e-02],\n",
       "           [ 1.58167692e-01,  9.87776715e-02,  6.95973753e-02,\n",
       "            -8.58270659e-02, -1.23445202e-02, -2.97269767e-02,\n",
       "            -1.72814037e-01, -4.65571746e-02]],\n",
       "  \n",
       "          [[ 1.04659242e-01,  1.04169083e-01, -3.94019186e-02,\n",
       "             1.71340804e-02,  1.23170723e-02, -2.01165812e-02,\n",
       "            -1.62771468e-01, -1.24527558e-01],\n",
       "           [ 1.28236949e-01,  1.20632656e-01, -1.64143540e-02,\n",
       "            -3.60293284e-02,  3.72374367e-02, -5.08337973e-02,\n",
       "            -1.97763451e-01, -6.53064903e-02],\n",
       "           [ 1.61119559e-01,  1.08321397e-01,  2.02215420e-02,\n",
       "             1.78537998e-02,  3.37830513e-02,  8.74989869e-03,\n",
       "            -1.34679516e-01, -1.05787028e-01]],\n",
       "  \n",
       "          [[-7.82875779e-02,  5.93224980e-02,  1.20447299e-02,\n",
       "             1.68736984e-01,  1.92020639e-02, -7.22693981e-02,\n",
       "            -4.57993959e-02, -2.53018567e-01],\n",
       "           [-2.90492308e-02,  9.87890044e-02, -3.74155103e-02,\n",
       "             8.72689580e-02,  3.76496437e-02, -7.66343983e-02,\n",
       "            -1.08425162e-01, -2.16231077e-01],\n",
       "           [-2.85379217e-02,  7.64217846e-02,  3.55488589e-02,\n",
       "             2.13918460e-01, -2.03291086e-02, -4.98355291e-02,\n",
       "             1.18818444e-02, -3.75478368e-01]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.63365599e-01, -7.35199015e-03,  7.71278113e-02,\n",
       "             3.35146949e-02, -1.56634384e-01, -2.42092797e-01,\n",
       "            -1.61497746e-02, -3.28166898e-02],\n",
       "           [-1.70261039e-01,  7.47573687e-03,  9.14320976e-02,\n",
       "            -5.97967232e-02, -2.07382933e-01, -2.31525571e-01,\n",
       "            -2.09578595e-02, -1.50745396e-02],\n",
       "           [-1.49204043e-01,  3.55880182e-02,  1.50984803e-01,\n",
       "            -9.83150849e-03, -1.93099540e-01, -2.07344297e-01,\n",
       "            -1.17642868e-02, -4.43123565e-02]],\n",
       "  \n",
       "          [[-1.73777698e-02,  3.29378369e-02, -2.78735026e-02,\n",
       "            -4.07883110e-02, -9.78211527e-02, -2.03490677e-01,\n",
       "            -6.62495829e-02,  8.17012771e-02],\n",
       "           [-7.32637419e-02,  1.06372858e-02, -7.25227948e-02,\n",
       "            -1.18988664e-01, -8.51870801e-02, -2.19064725e-01,\n",
       "            -5.58784525e-02,  1.01038666e-01],\n",
       "           [-2.78006271e-02,  3.29650865e-02, -3.34197815e-02,\n",
       "            -6.55560235e-02, -8.19553704e-02, -2.06765544e-01,\n",
       "            -5.35346798e-02,  2.08796845e-02]],\n",
       "  \n",
       "          [[ 8.54474266e-02,  1.18969822e-01, -1.27103725e-01,\n",
       "            -6.40091797e-02, -1.69580205e-02, -1.29622999e-01,\n",
       "            -5.96080641e-02,  1.70583902e-01],\n",
       "           [ 8.46281244e-02,  1.22723195e-01, -1.52072477e-01,\n",
       "            -1.06031932e-01,  8.90482084e-04, -1.05503981e-01,\n",
       "            -5.72796248e-02,  1.73794628e-01],\n",
       "           [ 7.73397424e-02,  6.98517325e-02, -1.16872397e-01,\n",
       "            -7.10728476e-02, -1.27970625e-02, -1.22632998e-01,\n",
       "            -7.08890750e-02,  9.95866143e-02]],\n",
       "  \n",
       "          [[ 1.17791008e-01,  2.07643647e-01, -1.33001226e-01,\n",
       "            -1.84942780e-02,  5.35241369e-02, -7.05495689e-02,\n",
       "            -4.92769806e-02,  8.78635148e-02],\n",
       "           [ 1.38763662e-01,  2.08186137e-01, -1.40984347e-01,\n",
       "             1.68285486e-02,  6.99348697e-02, -8.03373372e-02,\n",
       "            -6.49892119e-02,  1.29597948e-01],\n",
       "           [ 1.32245337e-01,  2.02533323e-01, -1.19483024e-01,\n",
       "             8.03204086e-02,  5.56169601e-02, -1.18524220e-01,\n",
       "            -4.34772755e-02,  8.70010822e-02]],\n",
       "  \n",
       "          [[ 5.00063090e-02,  2.41965768e-01, -9.43893585e-02,\n",
       "             2.21219641e-01,  7.02378631e-02, -9.14421922e-02,\n",
       "             1.53025526e-02, -1.06353261e-01],\n",
       "           [ 7.30956606e-02,  2.17790831e-01, -1.35353526e-01,\n",
       "             1.48958152e-01,  8.73428459e-02, -9.01134572e-02,\n",
       "            -3.43492222e-02, -9.11286697e-03],\n",
       "           [ 5.08845097e-02,  2.19907055e-01, -4.85817836e-02,\n",
       "             2.24957057e-01,  1.08789202e-01, -1.21707060e-01,\n",
       "             6.79024186e-02, -1.34278546e-01]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.65136583e-01, -1.67439582e-01,  2.71164733e-02,\n",
       "             7.52589949e-02, -1.80792290e-01, -1.59204937e-01,\n",
       "             7.18341760e-02, -9.16395514e-02],\n",
       "           [-2.28320833e-01, -1.41431626e-01,  1.16829505e-01,\n",
       "             7.12108748e-02, -2.13670445e-01, -1.79206424e-01,\n",
       "             8.58651392e-02, -3.18173286e-02],\n",
       "           [-1.41805904e-01, -1.59306066e-01,  8.41654683e-02,\n",
       "             1.22143282e-01, -1.71283041e-01, -1.37671054e-01,\n",
       "             4.81413004e-02, -6.72396292e-02]],\n",
       "  \n",
       "          [[-3.09994008e-02, -1.74054159e-01, -1.02475907e-01,\n",
       "            -8.98968693e-03, -6.69737344e-02, -7.39008842e-02,\n",
       "            -1.31484138e-02,  7.04244443e-02],\n",
       "           [-4.22988499e-02, -1.60572301e-01, -1.38998820e-01,\n",
       "            -6.43627183e-02, -7.39090807e-02, -1.05647895e-01,\n",
       "            -2.32557193e-03,  1.13892359e-01],\n",
       "           [-7.16096513e-02, -1.74533664e-01, -1.32603996e-01,\n",
       "            -4.01348205e-02, -9.12253973e-02, -9.09332762e-02,\n",
       "            -3.64907998e-02,  8.82977693e-02]],\n",
       "  \n",
       "          [[ 4.44531256e-02, -8.82864740e-02, -1.99939983e-01,\n",
       "            -2.24777890e-02,  3.71130115e-02,  9.86814806e-03,\n",
       "            -4.00679967e-02,  2.12212134e-01],\n",
       "           [ 1.05834302e-01, -7.20705893e-02, -1.97913007e-01,\n",
       "            -5.17814880e-02,  3.42334669e-02,  1.20466979e-02,\n",
       "            -1.73236022e-02,  2.58629959e-01],\n",
       "           [ 8.00994714e-02, -5.66963585e-02, -1.82949788e-01,\n",
       "            -1.71192862e-02,  3.11275253e-02,  1.16952407e-02,\n",
       "             1.36219271e-02,  1.69379505e-01]],\n",
       "  \n",
       "          [[ 1.03847909e-01,  1.07131399e-02, -1.39177176e-01,\n",
       "             2.93982878e-02,  9.73620111e-02,  8.48246825e-02,\n",
       "            -9.41456976e-03,  1.91504315e-01],\n",
       "           [ 1.25223342e-01, -1.89909608e-02, -2.07863443e-01,\n",
       "            -2.44563373e-02,  1.27701121e-01,  8.60968081e-02,\n",
       "            -5.03274790e-02,  2.37897301e-01],\n",
       "           [ 1.44612241e-01,  5.68301593e-03, -1.54289351e-01,\n",
       "             8.61620219e-02,  1.01792740e-01,  6.43464910e-02,\n",
       "             1.12851573e-03,  1.34575276e-01]],\n",
       "  \n",
       "          [[ 7.89019446e-02,  6.66682429e-02, -2.95967265e-02,\n",
       "             1.37790813e-01,  1.49265769e-01,  5.34395798e-02,\n",
       "             2.67636686e-02, -7.39436739e-03],\n",
       "           [ 6.98046260e-02,  6.78734615e-02, -8.18780566e-02,\n",
       "             1.42493613e-01,  1.63240309e-01,  8.80593585e-02,\n",
       "            -4.14520228e-03,  8.40833298e-02],\n",
       "           [ 8.23672913e-02,  3.12385469e-02, -5.03098810e-02,\n",
       "             1.70047123e-01,  1.38132286e-01,  5.77371013e-02,\n",
       "             1.14278940e-02, -5.14320549e-02]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.41912240e-01, -1.59744027e-01,  2.92879844e-02,\n",
       "             1.54274072e-01, -1.65591755e-01,  1.20526766e-02,\n",
       "             1.56982552e-01, -6.32446956e-02],\n",
       "           [-1.53482682e-01, -1.41792838e-01,  6.97145340e-02,\n",
       "             1.05859555e-01, -1.34772294e-01,  2.53284320e-02,\n",
       "             1.19321217e-01, -1.27913964e-02],\n",
       "           [-1.27523059e-01, -1.43504737e-01,  1.07548443e-01,\n",
       "             9.21980841e-02, -1.05506257e-01,  2.90527198e-03,\n",
       "             8.68384126e-02, -7.47308666e-02]],\n",
       "  \n",
       "          [[-4.99712400e-02, -2.35424074e-01, -1.08845405e-01,\n",
       "             2.66355082e-02, -4.30012777e-02,  7.34108340e-02,\n",
       "             8.27368238e-02,  9.85031387e-02],\n",
       "           [-6.20241239e-02, -2.21800706e-01, -1.04641944e-01,\n",
       "            -1.65817070e-02, -6.08134951e-02,  9.96443345e-02,\n",
       "             7.56757456e-02,  1.11716475e-01],\n",
       "           [-5.82784976e-03, -2.18561121e-01, -8.81627939e-02,\n",
       "            -2.45144291e-02, -3.44186178e-02,  1.02732937e-01,\n",
       "             1.88670308e-02,  2.45821682e-02]],\n",
       "  \n",
       "          [[ 4.71550013e-02, -2.06122625e-01, -1.42365895e-01,\n",
       "            -4.01970718e-02,  4.66749002e-02,  2.04331965e-01,\n",
       "             5.25966126e-02,  1.22287310e-01],\n",
       "           [ 6.46037596e-02, -2.12219125e-01, -1.61466177e-01,\n",
       "            -1.11952175e-01,  2.86482276e-02,  2.32372668e-01,\n",
       "             2.51636805e-02,  1.89036030e-01],\n",
       "           [ 5.08657145e-02, -2.11237632e-01, -1.31654664e-01,\n",
       "            -6.96124624e-03,  5.14290669e-02,  1.78043263e-01,\n",
       "             7.16703930e-03,  1.42667948e-01]],\n",
       "  \n",
       "          [[ 7.84465010e-02, -1.90208885e-01, -1.05197791e-01,\n",
       "            -1.59456398e-02,  1.21162135e-01,  2.21102625e-01,\n",
       "             2.80483659e-02,  1.23801759e-01],\n",
       "           [ 1.23769973e-01, -1.73014989e-01, -1.45944167e-01,\n",
       "            -4.98223717e-02,  1.62376594e-01,  2.57865592e-01,\n",
       "            -2.96450203e-02,  1.98311993e-01],\n",
       "           [ 1.28933226e-01, -1.51074262e-01, -9.89649174e-02,\n",
       "            -4.13005323e-02,  1.01532534e-01,  2.08246607e-01,\n",
       "             7.34467381e-03,  7.87215072e-02]],\n",
       "  \n",
       "          [[ 2.69257774e-02, -8.67686565e-02, -1.88487099e-02,\n",
       "             5.25736721e-02,  1.54419780e-01,  2.30154271e-01,\n",
       "            -6.50542398e-02, -8.80420636e-02],\n",
       "           [ 8.37513008e-02, -1.15043529e-01, -5.40460272e-03,\n",
       "             2.58181947e-02,  2.07554597e-01,  2.10793972e-01,\n",
       "            -1.13228678e-02,  4.93686058e-02],\n",
       "           [ 6.08499474e-02, -8.57987292e-02,  1.60029542e-02,\n",
       "             3.77092816e-02,  1.38341556e-01,  1.74454752e-01,\n",
       "            -2.25038467e-02, -1.31719542e-01]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.37093970e-01,  1.30880698e-01,  2.16145514e-02,\n",
       "             1.61954587e-01, -9.77477148e-02,  3.58660736e-02,\n",
       "             2.54876340e-01, -3.08522823e-02],\n",
       "           [-9.71769273e-02,  1.41553746e-01,  1.33135255e-01,\n",
       "             1.23225530e-01, -1.31165421e-01,  2.24312728e-04,\n",
       "             2.37325963e-01, -2.62588009e-02],\n",
       "           [-9.25380234e-02,  1.52401950e-01,  1.46088566e-01,\n",
       "             1.23746613e-01, -6.16527168e-02,  5.08432850e-03,\n",
       "             2.17919324e-01, -6.12228145e-02]],\n",
       "  \n",
       "          [[-4.15178686e-02,  3.06197558e-02, -3.88193644e-02,\n",
       "            -6.70322700e-03, -5.29614421e-02,  3.06878265e-02,\n",
       "             1.81983074e-01,  1.10495578e-03],\n",
       "           [-4.05830927e-02,  5.82954648e-03,  4.80790418e-05,\n",
       "             9.96517477e-03, -1.63189041e-02,  5.23576528e-02,\n",
       "             1.99700338e-01,  3.93838846e-02],\n",
       "           [-1.02303657e-01,  1.82853311e-02, -8.51119942e-03,\n",
       "             4.98269310e-03, -8.35362601e-03,  3.73644345e-02,\n",
       "             1.78229586e-01, -6.53920990e-02]],\n",
       "  \n",
       "          [[-2.37112833e-02, -1.31035298e-02, -4.74258806e-02,\n",
       "            -1.06885363e-01,  5.47813696e-02,  1.17334239e-01,\n",
       "             1.45800814e-01,  4.62193654e-02],\n",
       "           [ 2.70098413e-03, -2.23855990e-02, -3.86239414e-02,\n",
       "            -6.70785480e-02,  3.61935045e-02,  9.02757718e-02,\n",
       "             1.32399179e-01,  9.05665871e-02],\n",
       "           [-3.13764847e-02,  3.50924534e-02, -8.15938599e-02,\n",
       "            -8.09406758e-02,  5.77929444e-02,  1.15156968e-01,\n",
       "             1.33201134e-01, -4.08897107e-02]],\n",
       "  \n",
       "          [[-6.87360254e-02, -3.46407483e-02, -1.99062964e-02,\n",
       "            -1.33490822e-01,  8.49985149e-02,  1.65570817e-01,\n",
       "             8.99070950e-02, -8.64766155e-02],\n",
       "           [-3.91632692e-02, -1.41755727e-03, -6.64022513e-02,\n",
       "            -1.15543563e-01,  1.27118379e-01,  1.95345122e-01,\n",
       "             6.06747296e-02, -6.58405276e-03],\n",
       "           [-4.39764518e-02,  3.99130254e-02,  4.33461656e-03,\n",
       "            -7.65395171e-02,  1.01503014e-01,  1.42846989e-01,\n",
       "             1.29939867e-01, -1.17933823e-01]],\n",
       "  \n",
       "          [[-1.50268093e-01,  2.05456737e-02,  3.74002281e-02,\n",
       "            -1.00097796e-01,  4.10206320e-02,  1.01763242e-01,\n",
       "             5.01053639e-02, -3.04075769e-01],\n",
       "           [-1.16850263e-01,  3.29044568e-02,  1.49967570e-02,\n",
       "            -1.35278416e-01,  1.08360917e-01,  1.50663762e-01,\n",
       "             8.94275889e-02, -2.12134970e-01],\n",
       "           [-1.29361437e-01,  7.89016710e-02,  6.22938889e-02,\n",
       "            -5.43998000e-02,  3.79304395e-02,  6.29183084e-02,\n",
       "             1.19742618e-01, -3.60947767e-01]]]]),\n",
       "  'conv1_b': array([ 0.28344512,  0.02999126,  0.02751623, -0.03512319,  0.19762636,\n",
       "          0.01943421,  0.03399402,  0.13418208]),\n",
       "  'conv2_w': array([[[[-4.94839798e-02,  4.18981426e-02, -1.18403966e-01,\n",
       "            -1.32981993e-01],\n",
       "           [ 6.77024519e-02,  6.16586321e-02,  1.80029904e-01,\n",
       "             1.70267476e-02],\n",
       "           [ 7.95154429e-02,  8.89727937e-02,  9.86352497e-03,\n",
       "            -3.94376944e-03],\n",
       "           ...,\n",
       "           [-4.06555374e-01, -1.66421742e-01, -1.09413261e-02,\n",
       "             1.64763541e-01],\n",
       "           [ 6.11051044e-02, -6.23529290e-03, -3.49457398e-01,\n",
       "            -1.02680467e-01],\n",
       "           [-3.76590233e-01,  7.53138413e-02, -1.81592546e-02,\n",
       "            -1.00408807e-01]],\n",
       "  \n",
       "          [[ 1.66615326e-01,  1.50709832e-01, -1.59711382e-01,\n",
       "             1.85229403e-02],\n",
       "           [ 9.28217146e-02, -2.99542150e-02,  3.01876351e-02,\n",
       "            -1.69784938e-02],\n",
       "           [ 1.14603595e-01, -4.50041749e-02, -2.82733897e-02,\n",
       "             3.83174348e-02],\n",
       "           ...,\n",
       "           [-3.61541574e-01, -1.58274726e-01,  1.10403202e-01,\n",
       "             1.67502717e-01],\n",
       "           [-5.77303757e-02, -3.16612048e-02, -2.18590384e-01,\n",
       "            -1.24144649e-01],\n",
       "           [-5.96750985e-02,  1.50909083e-01, -7.07342502e-02,\n",
       "             5.61464442e-02]],\n",
       "  \n",
       "          [[ 1.86071661e-01,  1.24601158e-01, -1.07288554e-01,\n",
       "             5.57621863e-02],\n",
       "           [-1.88479756e-02, -8.69102248e-02, -7.01532878e-02,\n",
       "            -1.00197651e-01],\n",
       "           [ 1.27413123e-01, -1.21515423e-01,  5.11052513e-03,\n",
       "             4.26470688e-02],\n",
       "           ...,\n",
       "           [-3.32763799e-01, -1.16569082e-01,  2.27680971e-01,\n",
       "             1.01073438e-01],\n",
       "           [-2.50459297e-02, -4.82610344e-02, -9.76349778e-02,\n",
       "            -1.15130899e-01],\n",
       "           [ 1.19104049e-01,  1.71533066e-01, -2.10412412e-01,\n",
       "             6.63355251e-02]],\n",
       "  \n",
       "          [[ 1.04065497e-01, -6.64908919e-02, -5.99625893e-02,\n",
       "             1.28154730e-01],\n",
       "           [-1.48059318e-01, -2.32327437e-01, -1.20985600e-01,\n",
       "            -5.13772335e-02],\n",
       "           [ 2.44801857e-02, -7.56549866e-02,  7.48255531e-02,\n",
       "             2.38054130e-02],\n",
       "           ...,\n",
       "           [-1.38370506e-01, -1.03809188e-01,  1.73585296e-01,\n",
       "             1.97863969e-02],\n",
       "           [ 2.90312627e-02,  4.41289739e-02, -2.05380872e-02,\n",
       "            -1.39484898e-01],\n",
       "           [ 7.40560775e-02,  1.54563114e-01, -2.23853508e-01,\n",
       "             4.67975040e-02]],\n",
       "  \n",
       "          [[ 3.16558752e-02, -2.56210771e-01, -5.51592399e-02,\n",
       "             2.64337029e-01],\n",
       "           [-8.35885314e-02, -1.66040512e-01, -2.41733787e-01,\n",
       "            -6.46810298e-03],\n",
       "           [-1.20005363e-01, -2.54568890e-03,  3.65702528e-02,\n",
       "             1.07728808e-02],\n",
       "           ...,\n",
       "           [ 1.49203632e-01,  2.92391685e-03,  1.47040197e-01,\n",
       "            -5.02704649e-02],\n",
       "           [ 1.05316005e-01,  1.50479279e-01, -6.34694547e-02,\n",
       "            -1.34684211e-01],\n",
       "           [-2.38981931e-02, -1.04806971e-02, -2.00748333e-01,\n",
       "             1.78106898e-02]],\n",
       "  \n",
       "          [[ 6.04177933e-03, -3.70223704e-01, -3.14104630e-02,\n",
       "             1.95779619e-01],\n",
       "           [-1.27736111e-01, -3.09997786e-02, -2.61069682e-01,\n",
       "            -2.94046082e-02],\n",
       "           [-3.49573354e-01,  7.17484779e-02,  1.31831562e-02,\n",
       "             6.93697725e-04],\n",
       "           ...,\n",
       "           [ 4.25669291e-01,  1.11907578e-01,  1.16500974e-01,\n",
       "            -6.64843938e-04],\n",
       "           [ 5.49747123e-02,  2.23526153e-01,  3.62651363e-02,\n",
       "            -2.78652836e-01],\n",
       "           [-6.14086716e-02, -2.07241321e-01, -1.42981969e-01,\n",
       "             2.08087641e-02]]],\n",
       "  \n",
       "  \n",
       "         [[[-2.03264165e-01,  7.43689273e-02,  3.87609720e-03,\n",
       "            -1.20999999e-01],\n",
       "           [ 8.87595358e-02,  1.14933075e-01,  4.65582794e-01,\n",
       "             1.56127921e-01],\n",
       "           [ 2.60459026e-02,  9.46675000e-02, -3.74568166e-02,\n",
       "             3.78049581e-02],\n",
       "           ...,\n",
       "           [-3.25101310e-01, -1.16373769e-01, -1.17205564e-01,\n",
       "             1.31450671e-01],\n",
       "           [ 2.09285675e-01,  1.12668917e-01, -1.46479800e-01,\n",
       "             4.48903459e-02],\n",
       "           [-4.04928777e-01, -4.84104681e-02, -1.92349446e-01,\n",
       "            -7.02377186e-02]],\n",
       "  \n",
       "          [[ 1.33055145e-01,  1.47369862e-01, -2.13326805e-02,\n",
       "             9.37002643e-02],\n",
       "           [ 1.23224073e-01,  1.21340187e-01,  2.55096896e-01,\n",
       "            -1.63616351e-02],\n",
       "           [ 6.63794520e-02, -3.10728692e-02, -1.51157588e-02,\n",
       "             3.94887782e-02],\n",
       "           ...,\n",
       "           [-2.44066306e-01, -1.41847021e-01, -1.10309447e-01,\n",
       "             5.95653119e-02],\n",
       "           [ 2.15069712e-01,  4.38784112e-02,  6.40644323e-03,\n",
       "            -1.24341104e-02],\n",
       "           [-9.91590776e-02,  5.94976827e-02, -2.13761999e-01,\n",
       "             9.06220820e-02]],\n",
       "  \n",
       "          [[ 1.57078413e-01,  2.01037162e-01,  2.65131850e-03,\n",
       "             6.41775565e-02],\n",
       "           [ 4.90286247e-02, -1.23807169e-01,  3.18954278e-02,\n",
       "            -2.67356013e-01],\n",
       "           [ 1.45402975e-01, -1.01217762e-01,  2.08837059e-02,\n",
       "             3.80313402e-02],\n",
       "           ...,\n",
       "           [-2.21113084e-01, -1.48439612e-01, -5.52735893e-02,\n",
       "            -7.12696591e-02],\n",
       "           [ 2.79890877e-01, -5.82701234e-02, -1.84527467e-02,\n",
       "            -9.20907411e-02],\n",
       "           [ 1.05853723e-01,  1.13752737e-01, -2.16694132e-01,\n",
       "             1.00727623e-01]],\n",
       "  \n",
       "          [[ 8.65408986e-02,  8.26346394e-02,  7.09997413e-02,\n",
       "             1.30514627e-01],\n",
       "           [-7.10799452e-02, -3.05332405e-01, -2.08230115e-01,\n",
       "            -3.19844734e-01],\n",
       "           [ 4.87886834e-02, -7.03136457e-02,  1.06877009e-01,\n",
       "             3.13014517e-02],\n",
       "           ...,\n",
       "           [-2.16611866e-01, -1.49712108e-01, -7.43972243e-02,\n",
       "            -2.45750459e-01],\n",
       "           [ 1.74435434e-01, -5.39487065e-02,  5.38993692e-03,\n",
       "            -1.12246375e-01],\n",
       "           [ 1.35463007e-01,  1.00939928e-01, -1.57915908e-01,\n",
       "             1.07776821e-01]],\n",
       "  \n",
       "          [[ 1.12742303e-01, -2.42329610e-01,  1.22554516e-01,\n",
       "             1.47120358e-01],\n",
       "           [-1.11995581e-01, -2.64468940e-01, -4.07079611e-01,\n",
       "            -3.32082437e-01],\n",
       "           [-7.58790482e-02,  2.22052213e-02,  5.27382058e-02,\n",
       "             3.58807214e-02],\n",
       "           ...,\n",
       "           [-1.04225129e-01, -1.51168160e-01, -2.08866951e-02,\n",
       "            -3.19778535e-01],\n",
       "           [ 3.88530199e-02,  5.41745049e-02,  1.60126491e-03,\n",
       "            -1.36186379e-01],\n",
       "           [ 1.07701734e-01, -8.59210677e-02, -5.61960682e-02,\n",
       "             8.25634572e-02]],\n",
       "  \n",
       "          [[ 8.15266773e-02, -3.51397073e-01,  1.67546262e-01,\n",
       "             1.14284069e-01],\n",
       "           [-1.37762958e-01, -1.62154404e-02, -5.21264495e-01,\n",
       "            -3.04162757e-01],\n",
       "           [-2.90147796e-01,  6.15030780e-02, -6.64948383e-02,\n",
       "            -3.84460153e-03],\n",
       "           ...,\n",
       "           [ 2.04227563e-01, -2.21590847e-02,  8.69619104e-02,\n",
       "            -2.35222962e-01],\n",
       "           [-1.61898036e-01,  1.21094763e-01,  4.79687191e-02,\n",
       "            -2.41888692e-01],\n",
       "           [ 1.11073270e-01, -2.93048126e-01,  1.04573266e-01,\n",
       "             5.68423466e-02]]],\n",
       "  \n",
       "  \n",
       "         [[[-3.03343447e-01,  4.95568642e-03, -6.21233315e-03,\n",
       "            -8.19882932e-02],\n",
       "           [ 9.50026364e-03,  2.57189950e-03,  5.29223213e-01,\n",
       "            -2.53506963e-02],\n",
       "           [-3.57096876e-02,  9.66542307e-02,  2.31454775e-02,\n",
       "             6.63291839e-02],\n",
       "           ...,\n",
       "           [-2.02135269e-01, -7.56131136e-02, -2.70409201e-01,\n",
       "             5.38044147e-02],\n",
       "           [ 9.98455733e-02,  1.68178279e-01, -7.32606471e-02,\n",
       "             8.31724772e-02],\n",
       "           [-4.52107901e-01,  3.21964560e-02, -2.69031410e-01,\n",
       "            -2.19702250e-02]],\n",
       "  \n",
       "          [[ 6.60183311e-02,  1.52241316e-01,  4.09275299e-02,\n",
       "             8.95184819e-02],\n",
       "           [ 1.47625681e-01, -3.22086528e-03,  1.67196683e-01,\n",
       "            -2.70513242e-01],\n",
       "           [ 5.07835443e-02,  2.94661978e-03,  5.40233530e-02,\n",
       "             3.58616565e-02],\n",
       "           ...,\n",
       "           [-2.35773982e-01, -6.33952761e-02, -1.81651279e-01,\n",
       "            -1.41731983e-01],\n",
       "           [ 2.20017926e-01,  1.25282940e-01, -5.96518204e-02,\n",
       "            -5.48364140e-02],\n",
       "           [-2.08300867e-01,  1.30339184e-01, -1.84002561e-01,\n",
       "             1.20408864e-01]],\n",
       "  \n",
       "          [[ 8.91767290e-02,  2.20685925e-01,  4.33902235e-02,\n",
       "             1.08706963e-01],\n",
       "           [ 1.02282440e-01, -9.82919095e-02, -1.36724604e-01,\n",
       "            -5.15603676e-01],\n",
       "           [ 1.15462015e-01, -1.27541248e-01,  5.97203260e-02,\n",
       "             3.23540789e-02],\n",
       "           ...,\n",
       "           [-2.87284442e-01, -4.12414048e-02, -6.87812043e-02,\n",
       "            -4.30910528e-01],\n",
       "           [ 3.97497543e-01,  4.92440193e-02,  1.72296165e-02,\n",
       "            -1.96152450e-01],\n",
       "           [ 1.39827369e-03,  1.19584472e-01, -1.21684860e-01,\n",
       "             1.15733055e-01]],\n",
       "  \n",
       "          [[ 1.17068698e-01,  1.01311161e-01,  1.13430480e-01,\n",
       "             1.38562631e-01],\n",
       "           [-2.40383980e-02, -2.43485166e-01, -4.69916557e-01,\n",
       "            -4.93200370e-01],\n",
       "           [ 1.19342573e-01, -6.51726521e-02,  1.45508069e-01,\n",
       "             5.25525343e-02],\n",
       "           ...,\n",
       "           [-3.59931898e-01, -6.80603070e-02,  5.31092193e-02,\n",
       "            -3.78645192e-01],\n",
       "           [ 2.82689040e-01, -1.75422515e-02,  1.08537123e-01,\n",
       "            -2.66185731e-01],\n",
       "           [ 1.04830487e-01,  9.17633886e-02, -1.93645437e-02,\n",
       "             5.52566057e-02]],\n",
       "  \n",
       "          [[ 1.50434025e-01, -2.22962714e-01,  1.31728328e-01,\n",
       "             1.28626980e-01],\n",
       "           [-4.21349118e-02, -1.91919073e-01, -7.13769302e-01,\n",
       "            -3.32406922e-01],\n",
       "           [ 4.82158624e-02,  3.90568589e-02,  5.10162418e-02,\n",
       "            -2.30304701e-02],\n",
       "           ...,\n",
       "           [-2.37343010e-01, -1.22658514e-01,  1.12207846e-01,\n",
       "            -1.33381401e-01],\n",
       "           [ 3.41694898e-02,  2.67444436e-02,  1.27544096e-01,\n",
       "            -2.21356666e-01],\n",
       "           [ 9.11789776e-02, -6.07905903e-02,  2.96752686e-02,\n",
       "             6.75345246e-02]],\n",
       "  \n",
       "          [[ 1.65505494e-01, -3.29413131e-01,  2.04777196e-01,\n",
       "             7.24706017e-02],\n",
       "           [-7.46150083e-02, -4.62081100e-02, -8.12489908e-01,\n",
       "            -5.94130215e-02],\n",
       "           [-1.67264826e-01,  1.02206728e-01, -1.45950278e-01,\n",
       "            -3.42982100e-02],\n",
       "           ...,\n",
       "           [-2.18485333e-01, -3.23258785e-02,  1.69418551e-01,\n",
       "             4.77270495e-02],\n",
       "           [-3.12824006e-01,  1.03097825e-01,  1.05357683e-01,\n",
       "            -8.53093168e-02],\n",
       "           [ 1.31951969e-01, -3.30566962e-01,  1.65944441e-01,\n",
       "            -3.43057587e-02]]],\n",
       "  \n",
       "  \n",
       "         [[[-3.53754210e-01,  3.73095810e-02, -1.33706884e-02,\n",
       "            -8.46204354e-02],\n",
       "           [-7.58526598e-02, -1.52583640e-01,  3.27759581e-02,\n",
       "            -4.94167732e-01],\n",
       "           [-4.01765215e-02,  1.19582689e-01,  8.78539691e-02,\n",
       "            -1.58188159e-03],\n",
       "           ...,\n",
       "           [ 4.83310694e-02,  7.89284498e-02, -1.56698809e-01,\n",
       "            -1.79906249e-01],\n",
       "           [-2.81608620e-02,  1.43353463e-01, -1.35672619e-02,\n",
       "            -1.18915318e-02],\n",
       "           [-3.49565824e-01,  5.77253344e-03, -1.34000429e-01,\n",
       "            -1.87186053e-02]],\n",
       "  \n",
       "          [[-7.25936654e-02,  1.46679444e-01,  4.35868842e-02,\n",
       "             7.06464360e-02],\n",
       "           [ 6.72797978e-02, -1.09445681e-01, -1.69246979e-01,\n",
       "            -5.03682070e-01],\n",
       "           [ 3.82678750e-03, -3.19577376e-02,  1.44821972e-01,\n",
       "             9.76646035e-03],\n",
       "           ...,\n",
       "           [-5.68056340e-02,  4.06606664e-02, -6.20467433e-02,\n",
       "            -3.92919315e-01],\n",
       "           [ 6.55532821e-02,  1.22507677e-01,  1.33926610e-02,\n",
       "            -1.14747412e-01],\n",
       "           [-2.12923017e-01,  1.23260273e-01,  3.92025214e-02,\n",
       "             9.88961425e-02]],\n",
       "  \n",
       "          [[ 4.35768068e-02,  1.90077805e-01,  9.47638275e-02,\n",
       "             8.09700772e-02],\n",
       "           [ 4.27633201e-02, -1.46324892e-01, -3.39770883e-01,\n",
       "            -4.70036236e-01],\n",
       "           [ 7.84651347e-02, -7.08805248e-02,  1.32464366e-01,\n",
       "            -8.73122480e-03],\n",
       "           ...,\n",
       "           [-1.26596818e-01, -1.86332774e-02,  5.39881961e-02,\n",
       "            -2.38860605e-01],\n",
       "           [ 2.50902605e-01,  1.90697112e-02,  8.55340955e-02,\n",
       "            -1.71155483e-01],\n",
       "           [-1.29401487e-01,  1.13646813e-01,  8.17990445e-02,\n",
       "             6.35340251e-02]],\n",
       "  \n",
       "          [[ 5.63535050e-02,  1.37806888e-01,  1.36926168e-01,\n",
       "             9.67002348e-02],\n",
       "           [ 4.18525944e-02, -1.02478891e-01, -4.16442981e-01,\n",
       "            -3.13582993e-01],\n",
       "           [ 8.72736979e-02, -4.61009003e-02,  5.51082325e-02,\n",
       "             2.45451432e-02],\n",
       "           ...,\n",
       "           [-2.32414460e-01, -8.75165697e-02,  1.17160974e-01,\n",
       "            -3.40001779e-02],\n",
       "           [ 3.16515549e-01, -2.41927315e-02,  1.75034950e-01,\n",
       "            -1.74998852e-01],\n",
       "           [-1.04272070e-01,  1.09384835e-01,  1.27784889e-01,\n",
       "             3.97230162e-02]],\n",
       "  \n",
       "          [[ 1.01956938e-01, -1.02711579e-01,  1.73250800e-01,\n",
       "             4.23134249e-02],\n",
       "           [ 3.80820022e-02, -7.82346205e-02, -4.75949811e-01,\n",
       "            -1.06928181e-01],\n",
       "           [ 5.80434080e-02,  5.08547060e-02,  1.18722915e-02,\n",
       "            -2.03858144e-02],\n",
       "           ...,\n",
       "           [-2.54686947e-01, -1.38721559e-01,  1.09919008e-01,\n",
       "             8.84877218e-02],\n",
       "           [ 2.04142946e-01, -3.41762200e-02,  1.87143642e-01,\n",
       "             1.66226651e-02],\n",
       "           [-6.08292592e-02, -3.86793037e-02,  1.38982872e-01,\n",
       "             2.44556983e-02]],\n",
       "  \n",
       "          [[ 1.86920126e-01, -2.70213734e-01,  2.09064162e-01,\n",
       "            -4.53973167e-03],\n",
       "           [ 6.56289321e-02,  1.12922285e-01, -5.31027012e-01,\n",
       "             1.54682808e-01],\n",
       "           [-8.49251748e-02,  5.39084682e-02, -1.55275032e-01,\n",
       "            -4.81767846e-02],\n",
       "           ...,\n",
       "           [-3.94365269e-01, -2.76058812e-02,  9.77559760e-03,\n",
       "             1.01518440e-01],\n",
       "           [-2.02476132e-01,  4.19156261e-02,  3.29645387e-02,\n",
       "             1.04085414e-01],\n",
       "           [ 9.72199026e-02, -2.68070978e-01,  1.67145881e-01,\n",
       "            -1.35438344e-01]]],\n",
       "  \n",
       "  \n",
       "         [[[-2.94040405e-01,  4.61124279e-02, -2.51775912e-02,\n",
       "            -4.43311445e-02],\n",
       "           [-1.56844124e-01, -1.89703804e-01, -5.34102452e-01,\n",
       "            -4.55035009e-01],\n",
       "           [-3.44656857e-02,  5.89522052e-02,  8.97605546e-02,\n",
       "            -3.20592330e-02],\n",
       "           ...,\n",
       "           [ 1.47107314e-01,  1.08587266e-01, -2.27779402e-02,\n",
       "            -2.63431631e-01],\n",
       "           [-1.58610233e-01,  2.63120481e-02,  6.63680537e-02,\n",
       "             4.86790476e-03],\n",
       "           [-1.27838317e-01,  1.57629902e-02,  3.20372247e-02,\n",
       "            -5.34425954e-02]],\n",
       "  \n",
       "          [[-1.01260349e-01,  1.43950589e-01,  6.32317760e-02,\n",
       "             9.11099122e-02],\n",
       "           [-5.18081346e-03, -1.68936146e-01, -3.64843777e-01,\n",
       "            -3.40743601e-01],\n",
       "           [ 1.27587458e-02, -5.57373640e-02,  4.47223507e-02,\n",
       "            -4.38292003e-03],\n",
       "           ...,\n",
       "           [ 1.19420441e-01,  2.62890246e-02,  2.64492340e-02,\n",
       "            -2.55576665e-01],\n",
       "           [-2.98049294e-02,  2.80639349e-02,  7.77767806e-02,\n",
       "            -5.66144752e-02],\n",
       "           [-1.33953481e-02,  7.83339278e-02,  1.42677075e-01,\n",
       "             3.11696481e-02]],\n",
       "  \n",
       "          [[-5.56066895e-02,  1.74156989e-01,  1.08409927e-01,\n",
       "             1.20656679e-01],\n",
       "           [-2.02467569e-02, -1.02813730e-01, -3.60573967e-01,\n",
       "            -2.48136434e-01],\n",
       "           [ 2.34252342e-02, -7.29292861e-02, -2.74509970e-02,\n",
       "             1.61159791e-02],\n",
       "           ...,\n",
       "           [ 4.48131428e-02, -5.12787802e-02,  8.10768249e-02,\n",
       "            -2.95213795e-02],\n",
       "           [ 1.46785196e-01, -4.95852601e-02,  4.65449293e-02,\n",
       "            -3.44624501e-02],\n",
       "           [-5.53544857e-02,  1.36289736e-01,  1.69745206e-01,\n",
       "             3.00615006e-02]],\n",
       "  \n",
       "          [[-1.97828840e-02,  9.91236844e-02,  1.02384874e-01,\n",
       "             7.65797057e-02],\n",
       "           [ 2.50359885e-02, -7.72902139e-02, -3.10944949e-01,\n",
       "            -1.05193565e-01],\n",
       "           [ 1.01375711e-01, -2.45643928e-02, -6.24163370e-02,\n",
       "            -8.18156100e-03],\n",
       "           ...,\n",
       "           [-9.56296125e-02, -1.46809432e-01,  1.10567864e-02,\n",
       "             7.45651577e-02],\n",
       "           [ 2.66406906e-01, -6.02760895e-02,  6.85080546e-02,\n",
       "            -7.16363163e-03],\n",
       "           [-8.00412570e-02,  8.04075256e-02,  1.32820665e-01,\n",
       "             1.23078232e-02]],\n",
       "  \n",
       "          [[-2.10145505e-03, -5.13889766e-02,  9.43936958e-02,\n",
       "             6.21119339e-02],\n",
       "           [ 6.78876303e-02,  6.07481616e-02, -2.48126462e-01,\n",
       "            -4.74393800e-02],\n",
       "           [ 6.71853711e-02,  3.03080474e-02, -1.31681389e-01,\n",
       "            -1.69103286e-02],\n",
       "           ...,\n",
       "           [-2.32011952e-01, -9.00024572e-02, -5.11729848e-02,\n",
       "             2.21032443e-02],\n",
       "           [ 3.00617755e-01, -5.48238274e-02,  3.32188639e-02,\n",
       "             1.88783515e-02],\n",
       "           [-1.47292408e-01, -5.05185160e-02,  1.00035611e-01,\n",
       "            -6.64211546e-02]],\n",
       "  \n",
       "          [[ 6.48885952e-02, -1.96767803e-01,  8.39768263e-02,\n",
       "            -2.18449957e-02],\n",
       "           [ 1.34906530e-01,  1.66000631e-01, -8.61358091e-02,\n",
       "             4.81573995e-02],\n",
       "           [-1.79565657e-02,  7.60982416e-02, -1.48758917e-01,\n",
       "            -1.97591173e-02],\n",
       "           ...,\n",
       "           [-4.46312007e-01,  1.77753978e-02, -8.25703769e-02,\n",
       "            -4.42466318e-02],\n",
       "           [ 2.12216371e-02,  5.63429525e-02, -1.43157633e-01,\n",
       "            -1.67067520e-02],\n",
       "           [-6.50488946e-02, -2.18872238e-01,  1.40279759e-02,\n",
       "            -1.32230799e-01]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.23613717e-01,  3.81731129e-02, -1.15666112e-01,\n",
       "            -1.31899408e-02],\n",
       "           [-3.49159433e-01, -1.87958981e-01, -6.75986852e-01,\n",
       "            -7.94217607e-02],\n",
       "           [-1.04123324e-01,  2.74934423e-03, -1.10058497e-01,\n",
       "            -3.94596596e-02],\n",
       "           ...,\n",
       "           [-2.82990980e-02,  1.36371410e-01,  1.52287721e-01,\n",
       "            -2.06520050e-01],\n",
       "           [-2.98058299e-01, -1.24499577e-01,  1.96933061e-01,\n",
       "             3.61361457e-02],\n",
       "           [ 9.30607558e-02,  5.33825567e-02,  4.97862143e-02,\n",
       "            -1.36154575e-01]],\n",
       "  \n",
       "          [[-7.31468834e-02,  8.55748223e-02, -2.00539889e-02,\n",
       "             1.09397224e-01],\n",
       "           [-1.15284363e-01, -1.26116183e-01, -3.84760695e-01,\n",
       "            -3.31347401e-02],\n",
       "           [-7.58113308e-02, -1.88524324e-02, -1.73155026e-01,\n",
       "             1.17700153e-02],\n",
       "           ...,\n",
       "           [-2.70010172e-02,  5.42398667e-02,  8.14384257e-02,\n",
       "            -6.88103935e-02],\n",
       "           [-2.46852935e-01, -4.30968643e-02,  1.44808297e-01,\n",
       "             7.73490522e-02],\n",
       "           [ 1.18295155e-01,  6.97514646e-02,  7.38184465e-02,\n",
       "            -1.05369174e-02]],\n",
       "  \n",
       "          [[-1.05776953e-01,  6.71696073e-02,  4.89026716e-03,\n",
       "             8.62156517e-02],\n",
       "           [-7.45409181e-02, -1.38560420e-01, -1.74543173e-01,\n",
       "             9.81974514e-03],\n",
       "           [-1.18767695e-02, -8.59960958e-02, -1.93275778e-01,\n",
       "             5.27005372e-02],\n",
       "           ...,\n",
       "           [-8.14156772e-02, -1.25439565e-03,  8.88674423e-02,\n",
       "             7.43811682e-02],\n",
       "           [-2.90695672e-02, -6.39357435e-02,  3.68974609e-02,\n",
       "             1.09815447e-01],\n",
       "           [ 1.00943033e-01,  5.86132527e-02,  7.80275402e-02,\n",
       "            -5.60135096e-02]],\n",
       "  \n",
       "          [[-1.16671760e-01,  7.31947223e-02,  1.46658205e-02,\n",
       "             8.07195320e-02],\n",
       "           [-9.69307837e-02,  3.65739329e-04, -3.07614396e-03,\n",
       "            -4.59798745e-02],\n",
       "           [-5.63562949e-02, -4.34717446e-02, -1.25435773e-01,\n",
       "             8.77785823e-02],\n",
       "           ...,\n",
       "           [-2.38343499e-01, -8.75010136e-03,  3.56116855e-02,\n",
       "             8.94634854e-02],\n",
       "           [ 9.91142520e-02,  1.40081438e-02, -6.59514968e-02,\n",
       "             8.76862047e-02],\n",
       "           [ 2.18436745e-02, -1.52822484e-02,  1.31585445e-02,\n",
       "            -7.37950271e-02]],\n",
       "  \n",
       "          [[-1.00280150e-01, -4.49257822e-02, -9.10889482e-02,\n",
       "             5.74638940e-02],\n",
       "           [-6.76729367e-02,  7.06455071e-02,  9.69864351e-02,\n",
       "            -8.95854736e-02],\n",
       "           [ 2.52519560e-02,  6.66268105e-02, -9.76576254e-02,\n",
       "             7.07056345e-02],\n",
       "           ...,\n",
       "           [-3.21938012e-01, -7.09636038e-04,  6.22141460e-03,\n",
       "            -3.41383868e-02],\n",
       "           [ 1.62832350e-01,  7.96652423e-02, -1.19590410e-01,\n",
       "            -1.29684181e-02],\n",
       "           [-1.37179722e-01, -1.07825737e-01, -1.14042868e-01,\n",
       "            -5.33265018e-02]],\n",
       "  \n",
       "          [[-1.19452989e-01, -6.26742987e-02, -9.32512637e-02,\n",
       "            -3.50293323e-02],\n",
       "           [-1.23924276e-03,  9.17649524e-02,  3.07486998e-01,\n",
       "            -1.42869608e-01],\n",
       "           [-2.13392145e-02, -1.28382694e-02,  3.37167382e-02,\n",
       "             1.94145914e-02],\n",
       "           ...,\n",
       "           [-4.53615929e-01,  1.08952149e-01, -8.49188523e-02,\n",
       "            -1.48972514e-01],\n",
       "           [-4.27866421e-02,  9.00856731e-02, -2.00950081e-01,\n",
       "            -1.12676245e-01],\n",
       "           [-1.91403377e-01, -1.66465353e-01, -1.94798766e-01,\n",
       "            -1.14792158e-01]]]]),\n",
       "  'conv2_b': array([0.09654416, 0.24599045, 0.1384285 , 0.34190513]),\n",
       "  'fc1_w': array([[ 0.1005355 ,  0.24354475,  0.03232333, ...,  0.18476575,\n",
       "           0.07322973,  0.01117934],\n",
       "         [ 0.02684572,  0.08507557,  0.06152143, ...,  0.11876235,\n",
       "          -0.07948164,  0.05944143],\n",
       "         [ 0.03326924,  0.13155976, -0.03489603, ...,  0.1249234 ,\n",
       "          -0.05141636,  0.06509975],\n",
       "         ...,\n",
       "         [ 0.13863754,  0.01483852,  0.03775994, ..., -0.0487478 ,\n",
       "           0.07227087, -0.10831526],\n",
       "         [ 0.01938628,  0.04784339, -0.12971275, ..., -0.05898967,\n",
       "          -0.00285208,  0.06984089],\n",
       "         [ 0.15296789,  0.07091693,  0.02768805, ...,  0.0190499 ,\n",
       "          -0.01988922,  0.03076079]]),\n",
       "  'fc1_b': array([ 0.32370393,  0.44575155,  0.04386294,  0.16398137, -0.01283738,\n",
       "         -0.19095992,  0.03575539,  0.27299779,  0.12256047,  0.08833665]),\n",
       "  'fc2_w': array([[ 0.10689063, -0.0562036 , -0.08276076, -0.17893346,  0.05719132,\n",
       "          -0.11261527,  0.26150965, -0.1460427 , -0.02420991, -0.06360796],\n",
       "         [ 0.20694022, -0.11340183, -0.15515496,  0.09593675, -0.01209345,\n",
       "           0.07680525, -0.16062533,  0.01906046, -0.08722861, -0.09047414],\n",
       "         [-0.08457699,  0.17432667, -0.01596281,  0.07942735, -0.12532113,\n",
       "          -0.08043225,  0.07203745,  0.12126994, -0.05256794, -0.22089145],\n",
       "         [ 0.07676203, -0.06181546,  0.15407748, -0.14882941, -0.18186604,\n",
       "           0.01449568,  0.01847544,  0.08024759, -0.20699692,  0.14603315],\n",
       "         [ 0.18361988, -0.26938287, -0.1467062 ,  0.12051664, -0.30951263,\n",
       "          -0.3489227 ,  0.05639624,  0.44127883,  0.37883545, -0.10486728],\n",
       "         [-0.20933898, -0.16174244, -0.00166563, -0.06870873,  0.15859322,\n",
       "           0.18075034, -0.08864399,  0.1279472 ,  0.10704888,  0.00510529],\n",
       "         [ 0.25453601, -0.13276044, -0.23128451,  0.12377979,  0.07264215,\n",
       "          -0.52412636, -0.05310472,  0.48231318,  0.09058507,  0.03900787],\n",
       "         [ 0.00658598, -0.06379087, -0.12349548,  0.20531637, -0.10739919,\n",
       "          -0.0042841 ,  0.06073455, -0.11951139,  0.04122653,  0.17955199],\n",
       "         [ 0.05879813, -0.07139666,  0.18078824,  0.124382  ,  0.11086293,\n",
       "          -0.28204966, -0.09094127, -0.17570447,  0.06608345, -0.19453876],\n",
       "         [ 0.0619287 ,  0.10164846,  0.00921243, -0.12699213, -0.1125076 ,\n",
       "          -0.1889022 , -0.19452064, -0.04524311,  0.18204878,  0.1933763 ]]),\n",
       "  'fc2_b': array([ 0.26457038, -0.02112293, -0.14940947, -0.04595456,  0.08319516,\n",
       "          0.00261493, -0.04688688, -0.06042848, -0.22027215,  0.07713415])},\n",
       " [2.3025736957897607,\n",
       "  2.302428759722166,\n",
       "  2.302507439535007,\n",
       "  2.3020575693218936,\n",
       "  2.302016538330099,\n",
       "  2.3015484571746136,\n",
       "  2.301448159651697,\n",
       "  2.3000856688435363,\n",
       "  2.299943015462472,\n",
       "  2.294329404502874,\n",
       "  2.2950843473085274,\n",
       "  2.2880848696287717,\n",
       "  2.2900703468530326,\n",
       "  2.2847235725745785,\n",
       "  2.2944702449418712,\n",
       "  2.2590218178591615,\n",
       "  2.249290430788168,\n",
       "  2.288917272432682,\n",
       "  2.2371513294599925,\n",
       "  2.309248647834952,\n",
       "  2.224289006456823,\n",
       "  2.2725222947634345,\n",
       "  2.20919735552847,\n",
       "  2.2346833094482754,\n",
       "  2.251685263285823,\n",
       "  2.2841322271352142,\n",
       "  2.300083387300709,\n",
       "  2.2436194684181756,\n",
       "  2.290936335891582,\n",
       "  2.2646452415211336,\n",
       "  2.217983532588001,\n",
       "  2.246337994119472,\n",
       "  2.2585640783543584,\n",
       "  2.24500939947966,\n",
       "  2.2089602639147836,\n",
       "  2.218152097124217,\n",
       "  2.28825553763226,\n",
       "  2.240491992471847,\n",
       "  2.244763387879176,\n",
       "  2.2081021362273363,\n",
       "  2.219311312538483,\n",
       "  2.193060737103585,\n",
       "  2.2611325576038004,\n",
       "  2.2429066934275848,\n",
       "  2.217358148331096,\n",
       "  2.235744317084532,\n",
       "  2.1864260271632516,\n",
       "  2.254427525684553,\n",
       "  2.206736302213012,\n",
       "  2.271086883446393,\n",
       "  2.232090773771891,\n",
       "  2.310864643591044,\n",
       "  2.214808537146127,\n",
       "  2.248871997160687,\n",
       "  2.2484556890394796,\n",
       "  2.2540042863313796,\n",
       "  2.263627259992556,\n",
       "  2.2479678293464747,\n",
       "  2.2221706762914124,\n",
       "  2.2372654285158355,\n",
       "  2.24777350255395,\n",
       "  2.1986975995590052,\n",
       "  2.2316943212217626,\n",
       "  2.2752934620200898,\n",
       "  2.1328293863311307,\n",
       "  2.207960346630843,\n",
       "  2.340594530047894,\n",
       "  2.22323711018806,\n",
       "  2.206320108832129,\n",
       "  2.136425778942374,\n",
       "  2.266219730214658,\n",
       "  2.205847492174149,\n",
       "  2.2273486672837883,\n",
       "  2.3300924294034906,\n",
       "  2.267919837809494,\n",
       "  2.224938050988165,\n",
       "  2.2397953209343457,\n",
       "  2.2314362347281205,\n",
       "  2.227205114040811,\n",
       "  2.2387891051596287,\n",
       "  2.223979705103693,\n",
       "  2.2207429633610487,\n",
       "  2.258603615027847,\n",
       "  2.2794623368193596,\n",
       "  2.1913417256505547,\n",
       "  2.222673930859347,\n",
       "  2.232912856845356,\n",
       "  2.332802095674462,\n",
       "  2.2654733246568775,\n",
       "  2.2439681279631216,\n",
       "  2.2197979951453255,\n",
       "  2.198733107563063,\n",
       "  2.21213381972492,\n",
       "  2.246268601998135,\n",
       "  2.17740154590509,\n",
       "  2.180393339426137,\n",
       "  2.179286730280623,\n",
       "  2.3189159621478987,\n",
       "  2.203553958206263,\n",
       "  2.2280437961001707,\n",
       "  2.2591803444014857,\n",
       "  2.227587756993406,\n",
       "  2.2209981427063825,\n",
       "  2.1903371980126307,\n",
       "  2.243344067892865,\n",
       "  2.275058780282649,\n",
       "  2.244246203190742,\n",
       "  2.225880181813304,\n",
       "  2.249029799003437,\n",
       "  2.254926312808309,\n",
       "  2.2227584560722247,\n",
       "  2.2234077681558144,\n",
       "  2.24111520382493,\n",
       "  2.2563212119985323,\n",
       "  2.2496427831213697,\n",
       "  2.2424986059425187,\n",
       "  2.2883392726821112,\n",
       "  2.2406006377724883,\n",
       "  2.223209741164953,\n",
       "  2.255973520451057,\n",
       "  2.2502353364240983,\n",
       "  2.228070380983671,\n",
       "  2.1901590527697032,\n",
       "  2.2398211362830502,\n",
       "  2.2257412876829306,\n",
       "  2.257009918362861,\n",
       "  2.2098297074488578,\n",
       "  2.213137499335682,\n",
       "  2.242770755629221,\n",
       "  2.21718050088494,\n",
       "  2.2078970110908953,\n",
       "  2.1891036996289235,\n",
       "  2.236566940116593,\n",
       "  2.2463552954036974,\n",
       "  2.211759970172385,\n",
       "  2.184270367628633,\n",
       "  2.2193141481506737,\n",
       "  2.217737176002992,\n",
       "  2.218111200718052,\n",
       "  2.2209096714257632,\n",
       "  2.2547803612666146,\n",
       "  2.1734562290494135,\n",
       "  2.226045360492654,\n",
       "  2.173177994603082,\n",
       "  2.2059566371726334,\n",
       "  2.228303529430201,\n",
       "  2.2088515071608725,\n",
       "  2.256579657692287,\n",
       "  2.2000963906895863,\n",
       "  2.1988630095953474,\n",
       "  2.25271662045363,\n",
       "  2.2326977310864775,\n",
       "  2.2713631928391913,\n",
       "  2.196910561889298,\n",
       "  2.226842150089308,\n",
       "  2.2463894800070245,\n",
       "  2.193490015248002,\n",
       "  2.2265904462653294,\n",
       "  2.210558660781273,\n",
       "  2.1611761661927025,\n",
       "  2.2225565963566165,\n",
       "  2.2307364975429027,\n",
       "  2.163763250021243,\n",
       "  2.192232129635938,\n",
       "  2.2218125210588333,\n",
       "  2.1921929154285373,\n",
       "  2.183283491726466,\n",
       "  2.172748618272366,\n",
       "  2.162502490741481,\n",
       "  2.2529622703872385,\n",
       "  2.146581871402931,\n",
       "  2.2332872362355265,\n",
       "  2.1211891600236186,\n",
       "  2.177043093428537,\n",
       "  2.216395216164567,\n",
       "  2.288175228573889,\n",
       "  2.204435629136435,\n",
       "  2.193055668447708,\n",
       "  2.2168501197387425,\n",
       "  2.212521309315868,\n",
       "  2.1700358996988967,\n",
       "  2.2399425501553423,\n",
       "  2.144639931298458,\n",
       "  2.2129463813877615,\n",
       "  2.2192575111793498,\n",
       "  2.200473653443497,\n",
       "  2.195929721611226,\n",
       "  2.1833651313911395,\n",
       "  2.1844901971474733,\n",
       "  2.1352400916856875,\n",
       "  2.2141059778949876,\n",
       "  2.17683507302153,\n",
       "  2.1744822131533623,\n",
       "  2.163432394164854,\n",
       "  2.2202448532553483,\n",
       "  2.1924521733504068,\n",
       "  2.1304417299870155,\n",
       "  2.1773561022920624,\n",
       "  2.1002028599257248,\n",
       "  2.1370462858542214,\n",
       "  2.205958347853379,\n",
       "  2.179749953057867,\n",
       "  2.146451461517864,\n",
       "  2.1512837368960733,\n",
       "  2.2364114144631877,\n",
       "  2.16565442495281,\n",
       "  2.169663153902919,\n",
       "  2.11411936820397,\n",
       "  2.167409473540719,\n",
       "  2.0871932662023958,\n",
       "  2.211106866695677,\n",
       "  2.0662619773840287,\n",
       "  2.0793429148122393,\n",
       "  2.132031562708768,\n",
       "  2.1577064209660204,\n",
       "  2.104888774825084,\n",
       "  2.1851419891990362,\n",
       "  2.155761172184875,\n",
       "  2.170546971459883,\n",
       "  2.1232295191595907,\n",
       "  2.1095175535338,\n",
       "  2.0668886360241268,\n",
       "  2.1366880154503347,\n",
       "  2.175980740650416,\n",
       "  2.1436711274124485,\n",
       "  2.1465657065439836,\n",
       "  2.111489477290325,\n",
       "  2.1057337510314404,\n",
       "  2.0883821922285657,\n",
       "  2.132032946995868,\n",
       "  2.0942024319893813,\n",
       "  2.112053453665947,\n",
       "  2.032965380128149,\n",
       "  2.163667702744571,\n",
       "  2.1349439967901978,\n",
       "  2.1229224977426266,\n",
       "  2.1140581944230825,\n",
       "  2.093447339028376,\n",
       "  2.1087546875678367,\n",
       "  2.0823272331506195,\n",
       "  2.1101148100585947,\n",
       "  2.0468595848622386,\n",
       "  2.101119461361313,\n",
       "  2.031394397100456,\n",
       "  2.118465205016932,\n",
       "  1.9508374802163482,\n",
       "  2.107139182772534,\n",
       "  2.1029117753475113,\n",
       "  2.0119543754555886,\n",
       "  2.1007100258935854,\n",
       "  1.9122273400480896,\n",
       "  2.0522599129942543,\n",
       "  2.008360426999878,\n",
       "  1.918526593605504,\n",
       "  1.9060940408647378,\n",
       "  2.0720148848312014,\n",
       "  1.978478793694796,\n",
       "  1.9199705059415713,\n",
       "  2.0073021814437166,\n",
       "  1.8873489857326071,\n",
       "  1.743325506611805,\n",
       "  1.8824548125814156,\n",
       "  1.8605887113885529,\n",
       "  1.9290414738135815,\n",
       "  2.0274249985393378,\n",
       "  2.063291554015632,\n",
       "  1.9474020360180826,\n",
       "  1.8077649649892966,\n",
       "  1.8289887470742654,\n",
       "  1.8955685593304445,\n",
       "  1.901478939691255,\n",
       "  1.9048018171809225,\n",
       "  1.9185053947137072,\n",
       "  1.9035354085663243,\n",
       "  1.7928399228945766,\n",
       "  1.7565871223867575,\n",
       "  1.7894497986401139,\n",
       "  2.043451719287519,\n",
       "  1.9039581419552203,\n",
       "  1.8252448286920595,\n",
       "  1.9464741564909802,\n",
       "  1.8098561819511811,\n",
       "  1.8918012998257483,\n",
       "  1.7053592425324842,\n",
       "  1.7491707835252603,\n",
       "  2.004477605784405,\n",
       "  1.8331441484464817,\n",
       "  1.796608156481366,\n",
       "  1.7757313359211533,\n",
       "  1.8940614220065162,\n",
       "  1.9151120315299424,\n",
       "  1.751651067353759,\n",
       "  1.8265336075235636,\n",
       "  1.6411045961443382,\n",
       "  1.7933334455393635,\n",
       "  1.7312337644579268,\n",
       "  1.864188724425431,\n",
       "  1.6975178242498064,\n",
       "  1.6269868728814227,\n",
       "  1.6741292483412453,\n",
       "  1.696692227506987,\n",
       "  1.768806267248039,\n",
       "  1.8551974591897782,\n",
       "  1.7013817270112377,\n",
       "  1.7250658669581522,\n",
       "  1.7137229242134544,\n",
       "  1.8362655986925802,\n",
       "  1.7366686202963064,\n",
       "  1.8952870311484356,\n",
       "  1.7714669149647244,\n",
       "  1.7551830628682017,\n",
       "  1.763783925279617,\n",
       "  1.5066641787676147,\n",
       "  1.532171612328917,\n",
       "  1.497324099500957,\n",
       "  1.5650411998672966,\n",
       "  1.6850184826814685,\n",
       "  1.7998658323651038,\n",
       "  1.7885673988651472,\n",
       "  1.644562726548003,\n",
       "  1.6733465854729193,\n",
       "  1.5240066145006155,\n",
       "  1.6853656800374768,\n",
       "  1.727133742408431,\n",
       "  1.586188431596636,\n",
       "  1.762442808856965,\n",
       "  1.7645808543192123,\n",
       "  1.8255750307715333,\n",
       "  1.7939463404346148,\n",
       "  1.6630884660126295,\n",
       "  1.5472368970155352,\n",
       "  1.6220095386469406,\n",
       "  1.5909957763803821,\n",
       "  1.660297771434939,\n",
       "  1.643155707586019,\n",
       "  1.734134448662936,\n",
       "  1.428210664361134,\n",
       "  1.5703724815521913,\n",
       "  1.532744110406907,\n",
       "  1.4116031083682368,\n",
       "  1.699254238734898,\n",
       "  1.5065719646338673,\n",
       "  1.5846306843567413,\n",
       "  1.9741284094014158,\n",
       "  1.4926551411202897,\n",
       "  1.5242634207951866,\n",
       "  1.5261574544381478,\n",
       "  1.5985595811509627,\n",
       "  1.5781687876810868,\n",
       "  1.4593661912056384,\n",
       "  1.5497349619954293,\n",
       "  1.66853072166497,\n",
       "  1.4320809105175947,\n",
       "  1.4544284869549997,\n",
       "  1.5262795715036066,\n",
       "  1.4871458665700619,\n",
       "  1.5082797809078698,\n",
       "  1.4406113258283648,\n",
       "  1.5850117484808501,\n",
       "  1.5356999224668149,\n",
       "  1.4584020520531245,\n",
       "  1.2904346233622026,\n",
       "  1.4169716312604577,\n",
       "  1.535462515140682,\n",
       "  1.4415482289710129,\n",
       "  1.4298441585111286,\n",
       "  1.4495961512123252,\n",
       "  1.3102722364710058,\n",
       "  1.4497573161704325,\n",
       "  1.5026693518503953,\n",
       "  1.644184140565154,\n",
       "  1.447634731432218,\n",
       "  1.359333491900468,\n",
       "  1.3902848654953126,\n",
       "  1.4326186424017031,\n",
       "  1.4680071047586445,\n",
       "  1.4334801686245375,\n",
       "  1.5361106951561174,\n",
       "  1.4590259742478005,\n",
       "  1.4194947608190942,\n",
       "  1.4950856236910344,\n",
       "  1.5044755649798678,\n",
       "  1.4216248519063213,\n",
       "  1.5570566792052027,\n",
       "  1.3305616912045342,\n",
       "  1.4398356374929098,\n",
       "  1.3464712722650451,\n",
       "  1.5840888796579529,\n",
       "  1.5484960732668904,\n",
       "  1.330976297000322,\n",
       "  1.2452112906496124,\n",
       "  1.5109579178148362,\n",
       "  1.3096590594307702,\n",
       "  1.3399098022010298,\n",
       "  1.4523020824254116,\n",
       "  1.353777177649959,\n",
       "  1.4629353748775764,\n",
       "  1.3983461927811986,\n",
       "  1.2801600761931657,\n",
       "  1.5049168507791697,\n",
       "  1.585874639311335,\n",
       "  1.7180845126601296,\n",
       "  1.1969526229405643,\n",
       "  1.3717079759064388,\n",
       "  1.1734849383617485,\n",
       "  1.4492183372478455,\n",
       "  1.3209638433820543,\n",
       "  1.379830790852256,\n",
       "  1.2244689942862639,\n",
       "  1.4336576602870488,\n",
       "  1.3968647173139326,\n",
       "  1.3741078385766063,\n",
       "  1.2388242123273199,\n",
       "  1.2391885151680329,\n",
       "  1.5153768832041858,\n",
       "  1.1447733479082045,\n",
       "  1.248020354073903,\n",
       "  1.385430836221883,\n",
       "  1.0429006036825499,\n",
       "  1.6584374355714744,\n",
       "  1.2994981502473568,\n",
       "  1.2284346137252466,\n",
       "  1.3517778216434109,\n",
       "  1.3301580572666334,\n",
       "  1.3809301197691068,\n",
       "  1.1866369781881199,\n",
       "  1.2117722969473634,\n",
       "  1.1720993897705778,\n",
       "  1.4606281246267088,\n",
       "  1.066472415934636,\n",
       "  1.1624018919129822,\n",
       "  1.241250731085,\n",
       "  1.396347500036369,\n",
       "  1.0484139371338803,\n",
       "  1.2030707082612282,\n",
       "  1.3882036456973141,\n",
       "  1.2672629641176316,\n",
       "  1.2186772534624892,\n",
       "  1.0744718522827328,\n",
       "  1.2318543491005527,\n",
       "  1.2575040326121112,\n",
       "  1.1404544113730983,\n",
       "  1.252058403864953,\n",
       "  1.216161241895523,\n",
       "  1.1274155815835871,\n",
       "  1.1994354987552032,\n",
       "  1.1809317809034485,\n",
       "  1.163784900116563,\n",
       "  1.050244920519677,\n",
       "  1.2138115443335091,\n",
       "  1.3081622806294868,\n",
       "  1.1985014459961538,\n",
       "  1.2285346089313152,\n",
       "  1.1366395907190423,\n",
       "  1.2132062323228057,\n",
       "  1.0478400269308679,\n",
       "  1.1911325484445077,\n",
       "  1.1172626768126344,\n",
       "  1.2125054460036053,\n",
       "  1.067687643836422,\n",
       "  1.144911308566439,\n",
       "  1.4290210000742753,\n",
       "  1.1261062865023754,\n",
       "  1.1594735800398548,\n",
       "  1.1927713701195177,\n",
       "  1.2262826943360747,\n",
       "  0.8296575384507708,\n",
       "  1.1428080035235755,\n",
       "  1.1543429433404302,\n",
       "  1.0928706861614155,\n",
       "  0.9757086499818464,\n",
       "  1.1860260710132613,\n",
       "  1.251577779681518,\n",
       "  1.1679876239830105,\n",
       "  1.0067621483241285,\n",
       "  1.0318130572804027,\n",
       "  1.2098307525807972,\n",
       "  1.215506259369439,\n",
       "  1.3161231000022013,\n",
       "  1.3849819108304195,\n",
       "  1.1101801909684514,\n",
       "  1.1177484091231618,\n",
       "  1.3779525704638298,\n",
       "  1.198086754282558,\n",
       "  1.0039905576408996,\n",
       "  1.1596918171279817,\n",
       "  1.0632727926320682,\n",
       "  1.204526201632173,\n",
       "  1.0246804162860417,\n",
       "  0.8820472302479347,\n",
       "  1.1158630908073714,\n",
       "  0.9264095485153179,\n",
       "  1.1288498459273377,\n",
       "  1.011415773512425,\n",
       "  0.9506646223684924,\n",
       "  1.0351765060310874,\n",
       "  1.2009138808991096,\n",
       "  1.1067330532008535,\n",
       "  1.1770774072262002,\n",
       "  0.8693925683048859,\n",
       "  1.1732460202422692,\n",
       "  1.2093932977565964,\n",
       "  0.9391376153999865,\n",
       "  0.9562576976520022,\n",
       "  1.3079809123021942,\n",
       "  1.2759849893037334,\n",
       "  1.0860535415851118,\n",
       "  1.2419635418705772,\n",
       "  1.037089942053876,\n",
       "  0.977079126594515,\n",
       "  1.0449164200681393,\n",
       "  1.1639642878880352,\n",
       "  1.1489848461428733,\n",
       "  0.9595589061087959,\n",
       "  1.0544665197441845,\n",
       "  1.1313343848808726,\n",
       "  1.0998970351473851,\n",
       "  0.8257847434801516,\n",
       "  0.9937407278277739,\n",
       "  1.2680803919645933,\n",
       "  1.1834607195514872,\n",
       "  0.855449499678926,\n",
       "  1.0126234484801737,\n",
       "  1.058138890476476,\n",
       "  0.9510792179918228,\n",
       "  0.9867911485589023,\n",
       "  0.7928284481095528,\n",
       "  0.8584707605528513,\n",
       "  0.9107292856601508,\n",
       "  0.9352587837659158,\n",
       "  1.025950025211976,\n",
       "  0.8817683835498157,\n",
       "  1.1485712315754428,\n",
       "  0.9362031426019811,\n",
       "  1.104095651890926,\n",
       "  0.9761988901832612,\n",
       "  1.0339443493941924,\n",
       "  0.9723954045097708,\n",
       "  0.9901928776974144,\n",
       "  0.8167676988373586,\n",
       "  0.9224540562449994,\n",
       "  1.009787083106503,\n",
       "  1.3389328820611546,\n",
       "  1.2258201016163908,\n",
       "  0.8999352190837983,\n",
       "  0.7987820608909106,\n",
       "  1.006291574431863,\n",
       "  1.1033119768536959,\n",
       "  1.1786777775940158,\n",
       "  0.9229550974440152,\n",
       "  0.8227956525085784,\n",
       "  0.9722330356098352,\n",
       "  0.8212189852486564,\n",
       "  0.7868606551372677,\n",
       "  1.0181163022648931,\n",
       "  1.0918870989620604,\n",
       "  0.8584871372373641,\n",
       "  0.9193029775132672,\n",
       "  0.9351324612299635,\n",
       "  0.8927765730813435,\n",
       "  0.7916120347381919,\n",
       "  1.019924786051094,\n",
       "  0.8784072923701838,\n",
       "  0.9778834436729416,\n",
       "  0.9447488691665226,\n",
       "  0.946891455315706,\n",
       "  1.1266857118452498,\n",
       "  1.1288804590195594,\n",
       "  0.9628178874965763,\n",
       "  0.9706918745176815,\n",
       "  1.170023169269955,\n",
       "  1.10318210597135,\n",
       "  0.7247079252655261,\n",
       "  0.9036924077279017,\n",
       "  0.7553076940393006,\n",
       "  0.9832011119363191,\n",
       "  0.8489881151387262,\n",
       "  0.9213711286149053,\n",
       "  0.9787872081254693,\n",
       "  0.7716897607800149,\n",
       "  0.7428894807950148,\n",
       "  0.9072889593606289,\n",
       "  0.9284666061963699,\n",
       "  1.0172951466407885,\n",
       "  0.7405729458763176,\n",
       "  0.9896890255944021,\n",
       "  0.9912981809690451,\n",
       "  0.82353545498329,\n",
       "  0.7764953302638704,\n",
       "  0.8891264355107081,\n",
       "  1.0098205627567505,\n",
       "  0.9104608073947044,\n",
       "  0.9620291387275296,\n",
       "  0.9923435918961848,\n",
       "  0.7536766730960546,\n",
       "  0.7581918294652433,\n",
       "  0.7409934701248393,\n",
       "  0.9150490214646806,\n",
       "  0.9272203573897717,\n",
       "  0.9585388026757607,\n",
       "  0.9067702846900861,\n",
       "  0.905672554135947,\n",
       "  0.7165555887108335,\n",
       "  0.9249206987402773,\n",
       "  1.0724908884092077,\n",
       "  0.8908411201627396,\n",
       "  0.7758602069350707,\n",
       "  0.8747946024484352,\n",
       "  0.9244758281208177,\n",
       "  0.7230933243375514,\n",
       "  1.0464728444086042,\n",
       "  0.8543866159112147,\n",
       "  0.9393297634418344,\n",
       "  0.9866752757162941,\n",
       "  1.2464504234982263,\n",
       "  0.8996713978544666,\n",
       "  0.850866517848067,\n",
       "  1.0727363858636345,\n",
       "  0.947563538711876,\n",
       "  0.6903433164141523,\n",
       "  0.9674233013583391,\n",
       "  1.0443509789793284,\n",
       "  0.9681940829310623,\n",
       "  1.0330739663239632,\n",
       "  0.8464528234826008,\n",
       "  0.9346185873610949,\n",
       "  0.9545850762868405,\n",
       "  0.7806700518184858,\n",
       "  0.9019263526801653,\n",
       "  0.9614297748121055,\n",
       "  0.9584284491490833,\n",
       "  1.00953792799839,\n",
       "  0.8882138209431152,\n",
       "  1.04868984066281,\n",
       "  0.8741621473695784,\n",
       "  0.7438685919204685,\n",
       "  0.8872311050711646,\n",
       "  0.986863698944297,\n",
       "  0.8203721224984855,\n",
       "  0.9321094111827373,\n",
       "  0.763436950607714,\n",
       "  0.93431690456229,\n",
       "  0.9439620469324898,\n",
       "  0.7141860054511019,\n",
       "  0.7262934612357558,\n",
       "  0.7547534079454623,\n",
       "  0.9119215829074265,\n",
       "  0.9574723540344319,\n",
       "  0.9112878269330499,\n",
       "  0.8711442050089903,\n",
       "  0.9178654520263378,\n",
       "  0.7197973754997912,\n",
       "  1.0139427819927895,\n",
       "  0.8938733250793974,\n",
       "  0.9520243553295586,\n",
       "  0.7663855250505569,\n",
       "  0.9358153306135558,\n",
       "  0.7689181348758667,\n",
       "  0.8360465358419147,\n",
       "  0.9637500524499253,\n",
       "  0.7458740434413429,\n",
       "  1.309501174044302,\n",
       "  0.9397883539790667,\n",
       "  0.7691715942259298,\n",
       "  0.7383720197248567,\n",
       "  0.7610861547771247,\n",
       "  0.8164484428241566,\n",
       "  0.6844768261396664,\n",
       "  0.9215124282438616,\n",
       "  0.8715961809861217,\n",
       "  0.8090309067600194,\n",
       "  0.9726798173077439,\n",
       "  0.73498641677398,\n",
       "  0.6751312224560438,\n",
       "  1.2597899060297477,\n",
       "  1.0347442169148373,\n",
       "  1.008974128398251,\n",
       "  0.536386104945513,\n",
       "  0.93979956249656,\n",
       "  0.8965411314937226,\n",
       "  0.7002562793175564,\n",
       "  0.8964822706648569,\n",
       "  0.8576594833762556,\n",
       "  1.0044680813369313,\n",
       "  0.9486161894479535,\n",
       "  0.9733246675760089,\n",
       "  0.8720087779441088,\n",
       "  1.0049775677438144,\n",
       "  0.9304915346912933,\n",
       "  0.8744184560328119,\n",
       "  0.8796822110191148,\n",
       "  0.7650033793984895,\n",
       "  0.9708343497005403,\n",
       "  0.8024626901123336,\n",
       "  0.9147012575661845,\n",
       "  0.8365821655005162,\n",
       "  0.9429828303722309,\n",
       "  0.9334889842883006,\n",
       "  0.8725942579610968,\n",
       "  0.6557942186076056,\n",
       "  0.8581504522006463,\n",
       "  0.9561580191852924,\n",
       "  0.849837997411073,\n",
       "  0.734308610991075,\n",
       "  0.7091055497778416,\n",
       "  0.6496678950995446,\n",
       "  0.8915731605880725,\n",
       "  0.7491681574630343,\n",
       "  0.8501308845579105,\n",
       "  0.7343559079677803,\n",
       "  0.9383285120740257,\n",
       "  0.7444158200013803,\n",
       "  0.846752426282457,\n",
       "  0.851369979860071,\n",
       "  0.7906510683953785,\n",
       "  0.6638117879741952,\n",
       "  0.9460496188115078,\n",
       "  0.8975430708895902,\n",
       "  1.0060705301903912,\n",
       "  0.8729674320950788,\n",
       "  0.845681024380688,\n",
       "  0.7140058964502877,\n",
       "  0.9790313097883553,\n",
       "  0.7714576883759975,\n",
       "  0.9139352437242492,\n",
       "  0.9477694656478378,\n",
       "  0.8813861940241356,\n",
       "  0.8543224199106029,\n",
       "  0.8355848549942241,\n",
       "  0.7830740795754181,\n",
       "  0.8621977943479264,\n",
       "  0.828209542002883,\n",
       "  0.805999219463896,\n",
       "  0.9498787395646284,\n",
       "  0.5357850037064888,\n",
       "  0.7592271672618877,\n",
       "  0.7253979829926508,\n",
       "  0.9684620160055175,\n",
       "  0.8983443542049465,\n",
       "  0.9139025654633515,\n",
       "  0.8011476799065974,\n",
       "  1.1708856025846923,\n",
       "  0.7709833125172733,\n",
       "  0.7729622745238733,\n",
       "  0.836714076179978,\n",
       "  0.778424772026802,\n",
       "  0.8968937699485129,\n",
       "  0.8974182494850731,\n",
       "  0.8246051216226595,\n",
       "  0.5992339811091897,\n",
       "  0.8494472294476595,\n",
       "  0.9704995044592115,\n",
       "  0.8524071182536338,\n",
       "  0.7511712991104544,\n",
       "  1.044089635255482,\n",
       "  0.8890009114958333,\n",
       "  0.8390681973329067,\n",
       "  0.8901035215195177,\n",
       "  0.6746584808920628,\n",
       "  0.8207443970745492,\n",
       "  0.8517183506185296,\n",
       "  0.5931025836761742,\n",
       "  0.9012955546862772,\n",
       "  1.0565698423172898,\n",
       "  0.7784205378978284,\n",
       "  0.984431643387702,\n",
       "  1.2393099576606466,\n",
       "  0.816922647034943,\n",
       "  0.7211723107052482,\n",
       "  0.6981951738476659,\n",
       "  0.7660462106279623,\n",
       "  0.9328765423351297,\n",
       "  0.813477040569244,\n",
       "  0.7565110688256058,\n",
       "  0.7843459283307119,\n",
       "  0.9741599198553891,\n",
       "  0.8536517212156849,\n",
       "  0.9224594673816071,\n",
       "  0.7612404793775114,\n",
       "  0.9092574336263121,\n",
       "  0.7598429564758519,\n",
       "  0.7538812927613822,\n",
       "  0.7091898965807268,\n",
       "  0.740417849111864,\n",
       "  0.7782665604457266,\n",
       "  0.7551995628084613,\n",
       "  0.9020894511098602,\n",
       "  0.8161955068093404,\n",
       "  0.8963244552070411,\n",
       "  0.7368034679285488,\n",
       "  1.0420465863373882,\n",
       "  0.8575571459764526,\n",
       "  0.8470206247124145,\n",
       "  0.8398455704864684,\n",
       "  0.9298183024665828,\n",
       "  0.7384937912578251,\n",
       "  0.9140162918117793,\n",
       "  0.9489224524345186,\n",
       "  0.7409361909818446,\n",
       "  0.8489543366328554,\n",
       "  0.8141147996311852,\n",
       "  0.5756234584699773,\n",
       "  0.8965955167134393,\n",
       "  0.8613687802266651,\n",
       "  0.6637489545172518,\n",
       "  0.7925512981363365,\n",
       "  0.6669157538596775,\n",
       "  0.8472916608765337,\n",
       "  0.7486137400168866,\n",
       "  0.881116627404077,\n",
       "  0.885474487183881,\n",
       "  0.9276143123985694,\n",
       "  0.7601815752126588,\n",
       "  0.850750426002543,\n",
       "  0.6692676204454283,\n",
       "  0.8452315974438902,\n",
       "  0.8965183155359071,\n",
       "  0.81235796760258,\n",
       "  0.9673525706331351,\n",
       "  0.8714311341355034,\n",
       "  0.751237589600147,\n",
       "  0.7141505293322663,\n",
       "  0.7678056518080334,\n",
       "  0.8923848902462613,\n",
       "  0.7641196546402166,\n",
       "  0.8456220979501415,\n",
       "  0.6579317037931367,\n",
       "  0.8537507094227234,\n",
       "  0.841241583630444,\n",
       "  0.6850571559502606,\n",
       "  0.7751977358832338,\n",
       "  0.7310085857422803,\n",
       "  0.8659517565534781,\n",
       "  0.810470291551246,\n",
       "  0.9931370200988567,\n",
       "  0.7249761954514713,\n",
       "  0.6890246257102207,\n",
       "  0.6041892385591037,\n",
       "  0.8142406751992944,\n",
       "  0.693762380237343,\n",
       "  0.7246439538258518,\n",
       "  0.6934176347553922,\n",
       "  0.9995952037225327,\n",
       "  0.70405226063846,\n",
       "  0.9111263074752236,\n",
       "  0.6388313262788369,\n",
       "  0.6997527531619486,\n",
       "  0.893105372822211,\n",
       "  0.6188941370943154,\n",
       "  0.8231426032323444,\n",
       "  0.7737172896953483,\n",
       "  0.9373650574168116,\n",
       "  0.8074876852928449,\n",
       "  0.8010743221668715,\n",
       "  0.8756334281062026,\n",
       "  0.8660562440911916,\n",
       "  0.6864762599161169,\n",
       "  0.7708874907871828,\n",
       "  0.8633709947627414,\n",
       "  0.72486315017873,\n",
       "  0.8674132707866641,\n",
       "  1.1147483487194962,\n",
       "  0.9172429533502496,\n",
       "  0.7899983564334604,\n",
       "  1.0194745741688716,\n",
       "  0.8243506833384674,\n",
       "  0.8358994724838259,\n",
       "  0.9839857595566616,\n",
       "  0.8904153491401192,\n",
       "  0.6731426211401391,\n",
       "  0.7581060095324869,\n",
       "  0.6888540590036909,\n",
       "  0.6280141992888151,\n",
       "  0.9061874970373885,\n",
       "  0.8428850784999314,\n",
       "  0.8267223270269508,\n",
       "  0.8772461515725697,\n",
       "  0.8224713470478304,\n",
       "  0.8623869573065533,\n",
       "  0.8066367587528559,\n",
       "  0.7857029190361855,\n",
       "  0.8009784485807011,\n",
       "  0.7633407840508463,\n",
       "  0.9973194276101813,\n",
       "  0.6518664758396711,\n",
       "  0.843110222890433,\n",
       "  0.9616596051303857,\n",
       "  0.679584740323521,\n",
       "  0.7382170459106104,\n",
       "  0.7217940158746154,\n",
       "  0.7982917966388297,\n",
       "  0.7313623151019435,\n",
       "  0.652427204201127,\n",
       "  0.8638418651675815,\n",
       "  0.8456883651287787,\n",
       "  0.6787711461261497,\n",
       "  0.7382718126347524,\n",
       "  0.5988330777559776,\n",
       "  0.7556128338950195,\n",
       "  0.7930562495468599,\n",
       "  0.7086537658894622,\n",
       "  0.820810301857739,\n",
       "  0.6782774216761429,\n",
       "  0.9183283984597386,\n",
       "  0.7913441555675199,\n",
       "  0.7720660409691318,\n",
       "  0.6374171897348887,\n",
       "  0.7873535411797999,\n",
       "  0.6639606601194826,\n",
       "  0.7644724449851457,\n",
       "  0.8694958213119124,\n",
       "  0.9223877497939917,\n",
       "  0.7600946541692221,\n",
       "  0.6473520053505432,\n",
       "  0.6707521347740317,\n",
       "  0.729199500647204,\n",
       "  0.8476778866204558,\n",
       "  0.7234478724466187,\n",
       "  0.8185804573728211,\n",
       "  0.6784097263991824,\n",
       "  0.6581520078488238,\n",
       "  0.8083872832923542,\n",
       "  0.8262797373135313,\n",
       "  0.8159253609802404,\n",
       "  0.8377688262387775,\n",
       "  0.7299575467511646,\n",
       "  0.5611643158403703,\n",
       "  0.7346614519642989,\n",
       "  0.7759599868406685,\n",
       "  0.5781531335397316,\n",
       "  0.8122818699824765,\n",
       "  0.6932648881769081,\n",
       "  0.7627650016358936,\n",
       "  1.0019452601479633,\n",
       "  0.7802468856330415,\n",
       "  0.6156115028385859,\n",
       "  0.501280150438185,\n",
       "  0.9097388863668696,\n",
       "  0.696570322808302,\n",
       "  0.7126809351352065,\n",
       "  1.0013163377772787,\n",
       "  0.7678801305154246,\n",
       "  0.7016225320777403,\n",
       "  0.8108669684979111,\n",
       "  0.7891914469381575,\n",
       "  0.7528794874869691,\n",
       "  0.9733300429748472,\n",
       "  0.723609436430618,\n",
       "  0.6805215238094209,\n",
       "  0.7287861314016131,\n",
       "  0.9011431868332891,\n",
       "  0.6969317236612188,\n",
       "  0.6582476601888746,\n",
       "  0.8626903485236735,\n",
       "  0.8154256280231991,\n",
       "  0.9218392375511668,\n",
       "  0.6682711047324524,\n",
       "  0.6981455198480075,\n",
       "  0.7431586474914815,\n",
       "  0.7268190146054839,\n",
       "  0.9192256958420263,\n",
       "  0.8878976621154374,\n",
       "  0.6609915834553082,\n",
       "  0.6042983885557762,\n",
       "  0.6442961982898792,\n",
       "  0.7612937819989696,\n",
       "  0.8179798247478244,\n",
       "  0.6991805587772845,\n",
       "  0.8003686119497045,\n",
       "  0.6886554542106023,\n",
       "  0.9169614159465133,\n",
       "  0.7066054261922077,\n",
       "  0.6824715345223896,\n",
       "  0.680779291706397,\n",
       "  0.7469966451194546,\n",
       "  0.7863245142804987,\n",
       "  0.729535333004462,\n",
       "  0.700819440812465,\n",
       "  0.5456031729436264,\n",
       "  0.6993121352801792,\n",
       "  0.6555097231288667,\n",
       "  0.7088570486582505,\n",
       "  0.5097869873768893,\n",
       "  0.8411870964475615,\n",
       "  0.5484432019474716,\n",
       "  0.8854453968993069,\n",
       "  0.6303629538803459,\n",
       "  0.9844932228329635,\n",
       "  0.8474354277362074,\n",
       "  0.7956653807767788,\n",
       "  0.7999157041247974,\n",
       "  0.6380362362654375,\n",
       "  0.8445114644210634,\n",
       "  0.7393516764168945,\n",
       "  0.8723767528906456,\n",
       "  0.7680439988855581,\n",
       "  0.7761489085656064,\n",
       "  0.8343237254988138,\n",
       "  0.6234933618071226,\n",
       "  0.6550653709588459,\n",
       "  ...],\n",
       " [0.6985857142857143,\n",
       "  0.7880571428571429,\n",
       "  0.8079857142857143,\n",
       "  0.8172285714285714,\n",
       "  0.8238285714285715,\n",
       "  0.8272857142857143,\n",
       "  0.8285285714285714,\n",
       "  0.8375,\n",
       "  0.8409857142857143,\n",
       "  0.8434142857142857,\n",
       "  0.8430571428571428,\n",
       "  0.8460714285714286,\n",
       "  0.8454571428571429,\n",
       "  0.8507857142857143,\n",
       "  0.8532571428571428,\n",
       "  0.854],\n",
       " [0.6911268038071845,\n",
       "  0.7817009517961314,\n",
       "  0.8013509364445809,\n",
       "  0.8087196806877495,\n",
       "  0.8114829597789377,\n",
       "  0.8151673319005219,\n",
       "  0.8206938900828984,\n",
       "  0.8271415412956709,\n",
       "  0.8256063862450107,\n",
       "  0.828062634326067,\n",
       "  0.829290758366595,\n",
       "  0.8338962235185754,\n",
       "  0.8314399754375192,\n",
       "  0.8348173165489714,\n",
       "  0.8375805956401596,\n",
       "  0.8403438747313479])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "import pickle\n",
    "results_s = None\n",
    "with open(\"save_new.pkl\", \"rb\") as result:\n",
    "  results_s = pickle.load(result)\n",
    "results_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Params: conv1_w Shape: (5, 5, 3, 8)\n",
      "Loading Params: conv1_b Shape: (8,)\n",
      "Loading Params: conv2_w Shape: (6, 6, 8, 4)\n",
      "Loading Params: conv2_b Shape: (4,)\n",
      "Loading Params: fc1_w Shape: (2500, 10)\n",
      "Loading Params: fc1_b Shape: (10,)\n",
      "Loading Params: fc2_w Shape: (10, 10)\n",
      "Loading Params: fc2_b Shape: (10,)\n",
      "(Iteration 1 / 2730) loss: 0.5114457496456871\n",
      "(Iteration 101 / 2730) loss: 0.48602731272052563\n",
      "(Iteration 201 / 2730) loss: 0.32383455603011685\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "model = SmallConvolutionalNetwork()\n",
    "loss_f = cross_entropy()\n",
    "\n",
    "\n",
    "n_results = None\n",
    "#############################################################################\n",
    "# TODO: Use the train_net function you completed to train a network         #\n",
    "#############################################################################\n",
    "optimizer =  Adam(model.net, 0.0004995)\n",
    "\n",
    "model.net.load(opt_params)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "lr_decay = .999\n",
    "lr_decay_every = 10\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "n_results = train_net(data_dict, model, loss_f, optimizer, batch_size, epochs, \n",
    "                    lr_decay, lr_decay_every, show_every=100, verbose=True)\n",
    "n_opt_params, n_loss_hist, n_train_acc_hist, n_val_acc_hist = n_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to generate the training plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "opt_params, loss_hist, train_acc_hist, val_acc_hist = results\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "loss_hist_ = loss_hist[1::100]  # sparse the curve a bit\n",
    "plt.plot(loss_hist_, '-o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(train_acc_hist, '-o', label='Training')\n",
    "plt.plot(val_acc_hist, '-o', label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Layers [5pts]\n",
    "\n",
    "An interesting finding from early research in convolutional networks was that the learned convolutions resembled filters used for things like edge detection. Complete the code below to visualize the filters in the first convolutional layer of your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im_array = None\n",
    "nrows, ncols = None, None\n",
    "\n",
    "###################################################\n",
    "# TODO: read the weights in the convolutional     #\n",
    "# layer and reshape them to a grid of images to   #\n",
    "# view with matplotlib.                           #\n",
    "###################################################\n",
    "filters = model.net.get_params(\"conv1_w\")\n",
    "filters = np.sum(filters, axis=2) * 255\n",
    "filters = filters.astype(np.uint8)\n",
    "filters_shaped = np.moveaxis(filters, -1, 0).tolist()\n",
    "\n",
    "_, axs = plt.subplots(2, 4, figsize = (16, 16))\n",
    "axs = axs.flatten()\n",
    "for img, ax in zip(filters_shaped, axs):\n",
    "    ax.imshow(img)\n",
    "plt.show()\n",
    "###################################################\n",
    "#                END OF YOUR CODE                 #\n",
    "###################################################\n",
    "\n",
    "# plt.imshow(im_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inline Question: Comment below on what kinds of filters you see. Include your response in your submission [5pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the darker areas corresponding to background/noise while whiter represents the edges and greyish representing some kind of noise, below is my interpretation of the 8 filters from the 1st convolutional layer (going from left to right, row by row)\n",
    "\n",
    "1. The first filter looks like it is highlighting a slight curve which might correspond to the curved areas of 6, 8, 9 or 0.\n",
    "2. The filter looks like to have captured more noise than the others with a single dot denoted by the white pixel. It can be either a noise or some information captured from the dataset.\n",
    "3. It seems like the L-shaped area is corresponding to a edge of the digit 5\n",
    "4. The bright parts of the filter looks like a small curving edge which might be corresponding to regions in the digit 6.\n",
    "5. The bright vertical pixels seems to be representing a straight vertical line. It might be corresponding to the same in digits - 1, 5, 7, 9.\n",
    "6. The bright horizontal line seems to be corresponding to an horizontal edge. Like the top line of 5. or 7\n",
    "7. The curve looking area seems to be corresponding to a downward curve or a small curve like in the ending of digit 5.\n",
    "8. The kind of C shaped bright pixels looks like edges with a bit of sides coming out of it. Like in the middle part of 5.\n",
    "\n",
    "Note: I have used digits in the explanation to aid the visualization of the reader. It might not correspond to that actual digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "Please prepare a PDF document `problem_2_solution.pdf` in the root directory of this repository with all plots and inline answers of your solution. Concretely, the document should contain the following items in strict order:\n",
    "1. Training loss / accuracy curves for CNN training\n",
    "2. Visualization of convolutional filters\n",
    "3. Answers to inline questions about convolutional filters\n",
    "\n",
    "Note that you still need to submit the jupyter notebook with all generated solutions. We will randomly pick submissions and check that the plots in the PDF and in the notebook are equivalent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
